{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import csv\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import SimpleRNN, Input, Embedding, Dropout, Dense, Activation, LSTM\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21520</th>\n",
       "      <td>Tho 35 years old, Groove Tube looks a lot like...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20883</th>\n",
       "      <td>Having heard quite positive reviews and having...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15487</th>\n",
       "      <td>***SPOILERS*** When undercover Brooklyn North ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>This is not a profound movie; most of the plot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15619</th>\n",
       "      <td>I loved this episode. It is so great that all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "21520  Tho 35 years old, Groove Tube looks a lot like...      1\n",
       "20883  Having heard quite positive reviews and having...      1\n",
       "15487  ***SPOILERS*** When undercover Brooklyn North ...      1\n",
       "15872  This is not a profound movie; most of the plot...      1\n",
       "15619  I loved this episode. It is so great that all ...      1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/reviews_train.csv').sample(frac=1)\n",
    "test = pd.read_csv('data/reviews_test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24987, 2)\n",
      "12490\n",
      "(24989, 2)\n",
      "12495\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train.label.sum())\n",
    "\n",
    "print(test.shape)\n",
    "print(test.label.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize_data(df, lemmatize=False):\n",
    "    df2 = df.copy(deep=True)\n",
    "    df2[\"text\"] = df2['text'].apply(lambda x:  re.sub(r\"\\'.+?\", '', x))\n",
    "    pattern = r'[\\d.,]+|[A-Z][.A-Z]+\\b\\.*|\\w+|\\S'\n",
    "    tokenizer = RegexpTokenizer(pattern)\n",
    "    df2[\"text\"] = df2[\"text\"].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        df2['text'] = df2['text'].apply(lambda x: [lemmatizer.lemmatize(item) for item in x])\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21520</th>\n",
       "      <td>[tho, 35, years, old, ,, groove, tube, looks, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20883</th>\n",
       "      <td>[having, heard, quite, positive, reviews, and,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15487</th>\n",
       "      <td>[*, *, *, spoilers, *, *, *, when, undercover,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15872</th>\n",
       "      <td>[this, is, not, a, profound, movie, ;, most, o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15619</th>\n",
       "      <td>[i, loved, this, episode, ., it, is, so, great...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "21520  [tho, 35, years, old, ,, groove, tube, looks, ...      1\n",
       "20883  [having, heard, quite, positive, reviews, and,...      1\n",
       "15487  [*, *, *, spoilers, *, *, *, when, undercover,...      1\n",
       "15872  [this, is, not, a, profound, movie, ;, most, o...      1\n",
       "15619  [i, loved, this, episode, ., it, is, so, great...      1"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word_list = tokenize_lemmatize_data(train)\n",
    "test_word_list = tokenize_lemmatize_data(test)\n",
    "train_word_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fb_embeddings(dict_dir, max_dict_lenght):\n",
    "    dict_df = pd.read_csv(dict_dir, sep=';', nrows=max_dict_lenght, skiprows=1, encoding='utf8', quoting=csv.QUOTE_NONE,\n",
    "                          header=None)\n",
    "    embeddings_word_index = dict_df.iloc[:, 0]\n",
    "    embeddings_word_index = pd.Series(embeddings_word_index.index, index=embeddings_word_index)\n",
    "    embeddings_word_index = embeddings_word_index.to_dict()\n",
    "    # throw out the first column (with words) and last one (with nans)\n",
    "    embeddings_matrix = np.array(dict_df.iloc[:, 1:-1])\n",
    "    return embeddings_word_index, embeddings_matrix\n",
    "\n",
    "def get_text_indeces(word_list, emb_index):\n",
    "    return [emb_index.get(word, 0) for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_word_index, embedding_matrix = load_fb_embeddings('data/wiki10k.csv', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = train_word_list.text.apply(get_text_indeces, args=(embeddings_word_index,))\n",
    "test_tokens = test_word_list.text.apply(get_text_indeces, args=(embeddings_word_index,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_train_tokens = pad_sequences(train_tokens, maxlen=100, dtype='int32', padding='post', value=0.0)\n",
    "pad_test_tokens = pad_sequences(test_tokens, maxlen=100, dtype='int32', padding='post', value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, emb_matrix):\n",
    "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
    "    \n",
    "    # make an embedding layer\n",
    "    embedding_layer = Embedding(10000, 300, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    embs = embedding_layer(sentence_indices)\n",
    "    X = SimpleRNN(100, activation='tanh', return_sequences=True)(embs)\n",
    "    X = SimpleRNN(100, activation='tanh', return_sequences=False)(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_25 (Embedding)     (None, 100, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_30 (SimpleRNN)    (None, 100, 100)          40100     \n",
      "_________________________________________________________________\n",
      "simple_rnn_31 (SimpleRNN)    (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 3,060,301\n",
      "Trainable params: 60,301\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_rnn_model((100,), embedding_matrix)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6760 - acc: 0.5789\n",
      "Epoch 2/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6488 - acc: 0.6137\n",
      "Epoch 3/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6467 - acc: 0.6178\n",
      "Epoch 4/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6465 - acc: 0.6180\n",
      "Epoch 5/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6550 - acc: 0.6049\n",
      "Epoch 6/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6437 - acc: 0.6150\n",
      "Epoch 7/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6369 - acc: 0.6292\n",
      "Epoch 8/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6552 - acc: 0.6004\n",
      "Epoch 9/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6371 - acc: 0.6319\n",
      "Epoch 10/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6526 - acc: 0.6019\n",
      "Epoch 11/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6564 - acc: 0.5980\n",
      "Epoch 12/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6513 - acc: 0.6066\n",
      "Epoch 13/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6519 - acc: 0.6142\n",
      "Epoch 14/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6510 - acc: 0.6150\n",
      "Epoch 15/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6488 - acc: 0.6123\n",
      "Epoch 16/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6374 - acc: 0.6314\n",
      "Epoch 17/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6306 - acc: 0.6429\n",
      "Epoch 18/20\n",
      "24987/24987 [==============================] - 50s 2ms/step - loss: 0.6308 - acc: 0.6382\n",
      "Epoch 19/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6333 - acc: 0.6411\n",
      "Epoch 20/20\n",
      "24987/24987 [==============================] - 49s 2ms/step - loss: 0.6202 - acc: 0.6598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97abcbc9b0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pad_train_tokens, train.label, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24987/24987 [==============================] - 34s 1ms/step\n",
      "24989/24989 [==============================] - 34s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6587067715541298, 0.5992636760269886]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(pad_train_tokens, train.label)\n",
    "model.evaluate(pad_test_tokens, test.label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
