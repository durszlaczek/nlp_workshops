{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kevinmariogerard/tmdbmovies/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10866, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>original_title</th>\n",
       "      <th>cast</th>\n",
       "      <th>homepage</th>\n",
       "      <th>director</th>\n",
       "      <th>tagline</th>\n",
       "      <th>...</th>\n",
       "      <th>overview</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>release_date</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>release_year</th>\n",
       "      <th>budget_adj</th>\n",
       "      <th>revenue_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135397</td>\n",
       "      <td>tt0369610</td>\n",
       "      <td>32.985763</td>\n",
       "      <td>150000000</td>\n",
       "      <td>1513528810</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Chris Pratt|Bryce Dallas Howard|Irrfan Khan|Vi...</td>\n",
       "      <td>http://www.jurassicworld.com/</td>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>The park is open.</td>\n",
       "      <td>...</td>\n",
       "      <td>Twenty-two years after the events of Jurassic ...</td>\n",
       "      <td>124</td>\n",
       "      <td>Action|Adventure|Science Fiction|Thriller</td>\n",
       "      <td>Universal Studios|Amblin Entertainment|Legenda...</td>\n",
       "      <td>6/9/15</td>\n",
       "      <td>5562</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.379999e+08</td>\n",
       "      <td>1.392446e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76341</td>\n",
       "      <td>tt1392190</td>\n",
       "      <td>28.419936</td>\n",
       "      <td>150000000</td>\n",
       "      <td>378436354</td>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>Tom Hardy|Charlize Theron|Hugh Keays-Byrne|Nic...</td>\n",
       "      <td>http://www.madmaxmovie.com/</td>\n",
       "      <td>George Miller</td>\n",
       "      <td>What a Lovely Day.</td>\n",
       "      <td>...</td>\n",
       "      <td>An apocalyptic story set in the furthest reach...</td>\n",
       "      <td>120</td>\n",
       "      <td>Action|Adventure|Science Fiction|Thriller</td>\n",
       "      <td>Village Roadshow Pictures|Kennedy Miller Produ...</td>\n",
       "      <td>5/13/15</td>\n",
       "      <td>6185</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.379999e+08</td>\n",
       "      <td>3.481613e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262500</td>\n",
       "      <td>tt2908446</td>\n",
       "      <td>13.112507</td>\n",
       "      <td>110000000</td>\n",
       "      <td>295238201</td>\n",
       "      <td>Insurgent</td>\n",
       "      <td>Shailene Woodley|Theo James|Kate Winslet|Ansel...</td>\n",
       "      <td>http://www.thedivergentseries.movie/#insurgent</td>\n",
       "      <td>Robert Schwentke</td>\n",
       "      <td>One Choice Can Destroy You</td>\n",
       "      <td>...</td>\n",
       "      <td>Beatrice Prior must confront her inner demons ...</td>\n",
       "      <td>119</td>\n",
       "      <td>Adventure|Science Fiction|Thriller</td>\n",
       "      <td>Summit Entertainment|Mandeville Films|Red Wago...</td>\n",
       "      <td>3/18/15</td>\n",
       "      <td>2480</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.012000e+08</td>\n",
       "      <td>2.716190e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140607</td>\n",
       "      <td>tt2488496</td>\n",
       "      <td>11.173104</td>\n",
       "      <td>200000000</td>\n",
       "      <td>2068178225</td>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>Harrison Ford|Mark Hamill|Carrie Fisher|Adam D...</td>\n",
       "      <td>http://www.starwars.com/films/star-wars-episod...</td>\n",
       "      <td>J.J. Abrams</td>\n",
       "      <td>Every generation has a story.</td>\n",
       "      <td>...</td>\n",
       "      <td>Thirty years after defeating the Galactic Empi...</td>\n",
       "      <td>136</td>\n",
       "      <td>Action|Adventure|Science Fiction|Fantasy</td>\n",
       "      <td>Lucasfilm|Truenorth Productions|Bad Robot</td>\n",
       "      <td>12/15/15</td>\n",
       "      <td>5292</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.839999e+08</td>\n",
       "      <td>1.902723e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168259</td>\n",
       "      <td>tt2820852</td>\n",
       "      <td>9.335014</td>\n",
       "      <td>190000000</td>\n",
       "      <td>1506249360</td>\n",
       "      <td>Furious 7</td>\n",
       "      <td>Vin Diesel|Paul Walker|Jason Statham|Michelle ...</td>\n",
       "      <td>http://www.furious7.com/</td>\n",
       "      <td>James Wan</td>\n",
       "      <td>Vengeance Hits Home</td>\n",
       "      <td>...</td>\n",
       "      <td>Deckard Shaw seeks revenge against Dominic Tor...</td>\n",
       "      <td>137</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>Universal Pictures|Original Film|Media Rights ...</td>\n",
       "      <td>4/1/15</td>\n",
       "      <td>2947</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.747999e+08</td>\n",
       "      <td>1.385749e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    imdb_id  popularity     budget     revenue  \\\n",
       "0  135397  tt0369610   32.985763  150000000  1513528810   \n",
       "1   76341  tt1392190   28.419936  150000000   378436354   \n",
       "2  262500  tt2908446   13.112507  110000000   295238201   \n",
       "3  140607  tt2488496   11.173104  200000000  2068178225   \n",
       "4  168259  tt2820852    9.335014  190000000  1506249360   \n",
       "\n",
       "                 original_title  \\\n",
       "0                Jurassic World   \n",
       "1            Mad Max: Fury Road   \n",
       "2                     Insurgent   \n",
       "3  Star Wars: The Force Awakens   \n",
       "4                     Furious 7   \n",
       "\n",
       "                                                cast  \\\n",
       "0  Chris Pratt|Bryce Dallas Howard|Irrfan Khan|Vi...   \n",
       "1  Tom Hardy|Charlize Theron|Hugh Keays-Byrne|Nic...   \n",
       "2  Shailene Woodley|Theo James|Kate Winslet|Ansel...   \n",
       "3  Harrison Ford|Mark Hamill|Carrie Fisher|Adam D...   \n",
       "4  Vin Diesel|Paul Walker|Jason Statham|Michelle ...   \n",
       "\n",
       "                                            homepage          director  \\\n",
       "0                      http://www.jurassicworld.com/   Colin Trevorrow   \n",
       "1                        http://www.madmaxmovie.com/     George Miller   \n",
       "2     http://www.thedivergentseries.movie/#insurgent  Robert Schwentke   \n",
       "3  http://www.starwars.com/films/star-wars-episod...       J.J. Abrams   \n",
       "4                           http://www.furious7.com/         James Wan   \n",
       "\n",
       "                         tagline      ...       \\\n",
       "0              The park is open.      ...        \n",
       "1             What a Lovely Day.      ...        \n",
       "2     One Choice Can Destroy You      ...        \n",
       "3  Every generation has a story.      ...        \n",
       "4            Vengeance Hits Home      ...        \n",
       "\n",
       "                                            overview runtime  \\\n",
       "0  Twenty-two years after the events of Jurassic ...     124   \n",
       "1  An apocalyptic story set in the furthest reach...     120   \n",
       "2  Beatrice Prior must confront her inner demons ...     119   \n",
       "3  Thirty years after defeating the Galactic Empi...     136   \n",
       "4  Deckard Shaw seeks revenge against Dominic Tor...     137   \n",
       "\n",
       "                                      genres  \\\n",
       "0  Action|Adventure|Science Fiction|Thriller   \n",
       "1  Action|Adventure|Science Fiction|Thriller   \n",
       "2         Adventure|Science Fiction|Thriller   \n",
       "3   Action|Adventure|Science Fiction|Fantasy   \n",
       "4                      Action|Crime|Thriller   \n",
       "\n",
       "                                production_companies release_date vote_count  \\\n",
       "0  Universal Studios|Amblin Entertainment|Legenda...       6/9/15       5562   \n",
       "1  Village Roadshow Pictures|Kennedy Miller Produ...      5/13/15       6185   \n",
       "2  Summit Entertainment|Mandeville Films|Red Wago...      3/18/15       2480   \n",
       "3          Lucasfilm|Truenorth Productions|Bad Robot     12/15/15       5292   \n",
       "4  Universal Pictures|Original Film|Media Rights ...       4/1/15       2947   \n",
       "\n",
       "   vote_average  release_year    budget_adj   revenue_adj  \n",
       "0           6.5          2015  1.379999e+08  1.392446e+09  \n",
       "1           7.1          2015  1.379999e+08  3.481613e+08  \n",
       "2           6.3          2015  1.012000e+08  2.716190e+08  \n",
       "3           7.5          2015  1.839999e+08  1.902723e+09  \n",
       "4           7.3          2015  1.747999e+08  1.385749e+09  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'imdb_id', 'popularity', 'budget', 'revenue', 'original_title',\n",
       "       'cast', 'homepage', 'director', 'tagline', 'keywords', 'overview',\n",
       "       'runtime', 'genres', 'production_companies', 'release_date',\n",
       "       'vote_count', 'vote_average', 'release_year', 'budget_adj',\n",
       "       'revenue_adj'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_possible_values(column):\n",
    "    value_set = set()\n",
    "    for movie_values in movies[column]:\n",
    "        try:\n",
    "            value_list = movie_values.split('|')\n",
    "            for value in value_list:\n",
    "                value_set.add(value)\n",
    "        except:\n",
    "            pass\n",
    "    return value_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_set = find_possible_values('genres')\n",
    "prod_set = find_possible_values('production_companies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genre_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7879"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prod_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "TV Movie\n",
      "Music\n",
      "Crime\n",
      "Thriller\n",
      "War\n",
      "History\n",
      "Horror\n",
      "Science Fiction\n",
      "Fantasy\n",
      "Romance\n",
      "Adventure\n",
      "Animation\n",
      "Documentary\n",
      "Foreign\n",
      "Action\n",
      "Mystery\n",
      "Drama\n",
      "Comedy\n",
      "Western\n"
     ]
    }
   ],
   "source": [
    "for genre in genre_set:\n",
    "    print(genre)\n",
    "    movies[genre] = movies['genres'].\\\n",
    "        apply(lambda x: type(x) is str and genre in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>original_title</th>\n",
       "      <th>cast</th>\n",
       "      <th>homepage</th>\n",
       "      <th>director</th>\n",
       "      <th>tagline</th>\n",
       "      <th>...</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>Action</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135397</td>\n",
       "      <td>tt0369610</td>\n",
       "      <td>32.985763</td>\n",
       "      <td>150000000</td>\n",
       "      <td>1513528810</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Chris Pratt|Bryce Dallas Howard|Irrfan Khan|Vi...</td>\n",
       "      <td>http://www.jurassicworld.com/</td>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>The park is open.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76341</td>\n",
       "      <td>tt1392190</td>\n",
       "      <td>28.419936</td>\n",
       "      <td>150000000</td>\n",
       "      <td>378436354</td>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>Tom Hardy|Charlize Theron|Hugh Keays-Byrne|Nic...</td>\n",
       "      <td>http://www.madmaxmovie.com/</td>\n",
       "      <td>George Miller</td>\n",
       "      <td>What a Lovely Day.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262500</td>\n",
       "      <td>tt2908446</td>\n",
       "      <td>13.112507</td>\n",
       "      <td>110000000</td>\n",
       "      <td>295238201</td>\n",
       "      <td>Insurgent</td>\n",
       "      <td>Shailene Woodley|Theo James|Kate Winslet|Ansel...</td>\n",
       "      <td>http://www.thedivergentseries.movie/#insurgent</td>\n",
       "      <td>Robert Schwentke</td>\n",
       "      <td>One Choice Can Destroy You</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140607</td>\n",
       "      <td>tt2488496</td>\n",
       "      <td>11.173104</td>\n",
       "      <td>200000000</td>\n",
       "      <td>2068178225</td>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>Harrison Ford|Mark Hamill|Carrie Fisher|Adam D...</td>\n",
       "      <td>http://www.starwars.com/films/star-wars-episod...</td>\n",
       "      <td>J.J. Abrams</td>\n",
       "      <td>Every generation has a story.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168259</td>\n",
       "      <td>tt2820852</td>\n",
       "      <td>9.335014</td>\n",
       "      <td>190000000</td>\n",
       "      <td>1506249360</td>\n",
       "      <td>Furious 7</td>\n",
       "      <td>Vin Diesel|Paul Walker|Jason Statham|Michelle ...</td>\n",
       "      <td>http://www.furious7.com/</td>\n",
       "      <td>James Wan</td>\n",
       "      <td>Vengeance Hits Home</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    imdb_id  popularity     budget     revenue  \\\n",
       "0  135397  tt0369610   32.985763  150000000  1513528810   \n",
       "1   76341  tt1392190   28.419936  150000000   378436354   \n",
       "2  262500  tt2908446   13.112507  110000000   295238201   \n",
       "3  140607  tt2488496   11.173104  200000000  2068178225   \n",
       "4  168259  tt2820852    9.335014  190000000  1506249360   \n",
       "\n",
       "                 original_title  \\\n",
       "0                Jurassic World   \n",
       "1            Mad Max: Fury Road   \n",
       "2                     Insurgent   \n",
       "3  Star Wars: The Force Awakens   \n",
       "4                     Furious 7   \n",
       "\n",
       "                                                cast  \\\n",
       "0  Chris Pratt|Bryce Dallas Howard|Irrfan Khan|Vi...   \n",
       "1  Tom Hardy|Charlize Theron|Hugh Keays-Byrne|Nic...   \n",
       "2  Shailene Woodley|Theo James|Kate Winslet|Ansel...   \n",
       "3  Harrison Ford|Mark Hamill|Carrie Fisher|Adam D...   \n",
       "4  Vin Diesel|Paul Walker|Jason Statham|Michelle ...   \n",
       "\n",
       "                                            homepage          director  \\\n",
       "0                      http://www.jurassicworld.com/   Colin Trevorrow   \n",
       "1                        http://www.madmaxmovie.com/     George Miller   \n",
       "2     http://www.thedivergentseries.movie/#insurgent  Robert Schwentke   \n",
       "3  http://www.starwars.com/films/star-wars-episod...       J.J. Abrams   \n",
       "4                           http://www.furious7.com/         James Wan   \n",
       "\n",
       "                         tagline   ...    Romance Adventure  Animation  \\\n",
       "0              The park is open.   ...      False      True      False   \n",
       "1             What a Lovely Day.   ...      False      True      False   \n",
       "2     One Choice Can Destroy You   ...      False      True      False   \n",
       "3  Every generation has a story.   ...      False      True      False   \n",
       "4            Vengeance Hits Home   ...      False     False      False   \n",
       "\n",
       "  Documentary Foreign Action  Mystery  Drama  Comedy  Western  \n",
       "0       False   False   True    False  False   False    False  \n",
       "1       False   False   True    False  False   False    False  \n",
       "2       False   False  False    False  False   False    False  \n",
       "3       False   False   True    False  False   False    False  \n",
       "4       False   False   True    False  False   False    False  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'imdb_id', 'popularity', 'budget', 'revenue', 'original_title',\n",
       "       'cast', 'homepage', 'director', 'tagline', 'keywords', 'overview',\n",
       "       'runtime', 'genres', 'production_companies', 'release_date',\n",
       "       'vote_count', 'vote_average', 'release_year', 'budget_adj',\n",
       "       'revenue_adj', 'Family', 'TV Movie', 'Music', 'Crime', 'Thriller',\n",
       "       'War', 'History', 'Horror', 'Science Fiction', 'Fantasy', 'Romance',\n",
       "       'Adventure', 'Animation', 'Documentary', 'Foreign', 'Action', 'Mystery',\n",
       "       'Drama', 'Comedy', 'Western'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['budget', 'runtime', 'release_year', 'popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.extend(genre_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movies[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = movies['vote_average']\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vote_hist = plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_binary = labels > 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = \\\n",
    "    train_test_split(data, labels_binary, \n",
    "                     test_size = 0.2, \n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### A. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8692 samples, validate on 2174 samples\n",
      "Epoch 1/5\n",
      "8692/8692 [==============================] - 1s 93us/step - loss: 4.7821 - acc: 0.5316 - val_loss: 3.9909 - val_acc: 0.5193\n",
      "Epoch 2/5\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9553 - acc: 0.5330 - val_loss: 3.9903 - val_acc: 0.5193\n",
      "Epoch 3/5\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9548 - acc: 0.5309 - val_loss: 3.9923 - val_acc: 0.4706\n",
      "Epoch 4/5\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.9536 - acc: 0.5422 - val_loss: 3.9907 - val_acc: 0.5225\n",
      "Epoch 5/5\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9508 - acc: 0.5419 - val_loss: 3.9890 - val_acc: 0.5262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10f2ab320>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, \n",
    "          epochs=5, batch_size=32, \n",
    "          validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Visualize model with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8692 samples, validate on 2174 samples\n",
      "Epoch 1/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9497 - acc: 0.5513 - val_loss: 3.9870 - val_acc: 0.5382\n",
      "Epoch 2/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9487 - acc: 0.5537 - val_loss: 3.9862 - val_acc: 0.5584\n",
      "Epoch 3/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9478 - acc: 0.5533 - val_loss: 3.9866 - val_acc: 0.5308\n",
      "Epoch 4/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9465 - acc: 0.5557 - val_loss: 3.9837 - val_acc: 0.5423\n",
      "Epoch 5/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9458 - acc: 0.5589 - val_loss: 3.9825 - val_acc: 0.5451\n",
      "Epoch 6/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9446 - acc: 0.5574 - val_loss: 3.9831 - val_acc: 0.5336\n",
      "Epoch 7/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9446 - acc: 0.5556 - val_loss: 3.9807 - val_acc: 0.5557\n",
      "Epoch 8/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9434 - acc: 0.5578 - val_loss: 3.9806 - val_acc: 0.5409\n",
      "Epoch 9/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9431 - acc: 0.5587 - val_loss: 3.9821 - val_acc: 0.5308\n",
      "Epoch 10/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9406 - acc: 0.5685 - val_loss: 3.9791 - val_acc: 0.5580\n",
      "Epoch 11/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9404 - acc: 0.5672 - val_loss: 3.9787 - val_acc: 0.5409\n",
      "Epoch 12/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9406 - acc: 0.5620 - val_loss: 3.9766 - val_acc: 0.5727\n",
      "Epoch 13/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9389 - acc: 0.5696 - val_loss: 3.9769 - val_acc: 0.5442\n",
      "Epoch 14/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9394 - acc: 0.5695 - val_loss: 3.9769 - val_acc: 0.5506\n",
      "Epoch 15/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9376 - acc: 0.5675 - val_loss: 3.9778 - val_acc: 0.5373\n",
      "Epoch 16/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9379 - acc: 0.5705 - val_loss: 3.9735 - val_acc: 0.5759\n",
      "Epoch 17/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9364 - acc: 0.5749 - val_loss: 3.9771 - val_acc: 0.5354\n",
      "Epoch 18/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9359 - acc: 0.5720 - val_loss: 3.9726 - val_acc: 0.5626\n",
      "Epoch 19/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9343 - acc: 0.5775 - val_loss: 3.9721 - val_acc: 0.5644\n",
      "Epoch 20/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9342 - acc: 0.5763 - val_loss: 3.9845 - val_acc: 0.5340\n",
      "Epoch 21/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9329 - acc: 0.5770 - val_loss: 3.9757 - val_acc: 0.5662\n",
      "Epoch 22/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9324 - acc: 0.5789 - val_loss: 3.9759 - val_acc: 0.5405\n",
      "Epoch 23/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9322 - acc: 0.5771 - val_loss: 3.9707 - val_acc: 0.5966\n",
      "Epoch 24/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9292 - acc: 0.5885 - val_loss: 3.9683 - val_acc: 0.5658\n",
      "Epoch 25/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9308 - acc: 0.5794 - val_loss: 3.9724 - val_acc: 0.5423\n",
      "Epoch 26/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9283 - acc: 0.5878 - val_loss: 3.9660 - val_acc: 0.5851\n",
      "Epoch 27/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9280 - acc: 0.5821 - val_loss: 3.9654 - val_acc: 0.5787\n",
      "Epoch 28/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9281 - acc: 0.5850 - val_loss: 3.9664 - val_acc: 0.5856\n",
      "Epoch 29/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9255 - acc: 0.5905 - val_loss: 3.9722 - val_acc: 0.5446\n",
      "Epoch 30/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9269 - acc: 0.5892 - val_loss: 3.9691 - val_acc: 0.5915\n",
      "Epoch 31/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9261 - acc: 0.5836 - val_loss: 3.9630 - val_acc: 0.5851\n",
      "Epoch 32/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9248 - acc: 0.5863 - val_loss: 3.9627 - val_acc: 0.5800\n",
      "Epoch 33/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9231 - acc: 0.5963 - val_loss: 3.9618 - val_acc: 0.5869\n",
      "Epoch 34/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9223 - acc: 0.5897 - val_loss: 3.9617 - val_acc: 0.5883\n",
      "Epoch 35/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9248 - acc: 0.5877 - val_loss: 3.9608 - val_acc: 0.5860\n",
      "Epoch 36/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9230 - acc: 0.5895 - val_loss: 3.9620 - val_acc: 0.5708\n",
      "Epoch 37/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9212 - acc: 0.5908 - val_loss: 3.9604 - val_acc: 0.5814\n",
      "Epoch 38/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9194 - acc: 0.5970 - val_loss: 3.9701 - val_acc: 0.5672\n",
      "Epoch 39/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9199 - acc: 0.5945 - val_loss: 3.9741 - val_acc: 0.5672\n",
      "Epoch 40/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9206 - acc: 0.5946 - val_loss: 3.9596 - val_acc: 0.5787\n",
      "Epoch 41/5000\n",
      "8692/8692 [==============================] - 1s 80us/step - loss: 3.9201 - acc: 0.5948 - val_loss: 3.9580 - val_acc: 0.5897\n",
      "Epoch 42/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.9198 - acc: 0.5946 - val_loss: 3.9576 - val_acc: 0.5869\n",
      "Epoch 43/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.9179 - acc: 0.5954 - val_loss: 3.9569 - val_acc: 0.5892\n",
      "Epoch 44/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.9196 - acc: 0.5941 - val_loss: 3.9572 - val_acc: 0.5846\n",
      "Epoch 45/5000\n",
      "8692/8692 [==============================] - 1s 85us/step - loss: 3.9180 - acc: 0.5946 - val_loss: 3.9572 - val_acc: 0.5782\n",
      "Epoch 46/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.9182 - acc: 0.5942 - val_loss: 3.9559 - val_acc: 0.5819\n",
      "Epoch 47/5000\n",
      "8692/8692 [==============================] - 1s 86us/step - loss: 3.9170 - acc: 0.5989 - val_loss: 3.9572 - val_acc: 0.5842\n",
      "Epoch 48/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.9148 - acc: 0.5987 - val_loss: 3.9553 - val_acc: 0.5869\n",
      "Epoch 49/5000\n",
      "8692/8692 [==============================] - 1s 81us/step - loss: 3.9147 - acc: 0.6001 - val_loss: 3.9609 - val_acc: 0.5695\n",
      "Epoch 50/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.9150 - acc: 0.5974 - val_loss: 3.9543 - val_acc: 0.5869\n",
      "Epoch 51/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.9148 - acc: 0.5961 - val_loss: 3.9545 - val_acc: 0.5915\n",
      "Epoch 52/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 3.9137 - acc: 0.5972 - val_loss: 3.9583 - val_acc: 0.5957\n",
      "Epoch 53/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.9138 - acc: 0.6007 - val_loss: 3.9571 - val_acc: 0.5745\n",
      "Epoch 54/5000\n",
      "8692/8692 [==============================] - 1s 73us/step - loss: 3.9128 - acc: 0.5988 - val_loss: 3.9531 - val_acc: 0.5869\n",
      "Epoch 55/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.9133 - acc: 0.5983 - val_loss: 3.9548 - val_acc: 0.5842\n",
      "Epoch 56/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.9124 - acc: 0.5973 - val_loss: 3.9538 - val_acc: 0.5814\n",
      "Epoch 57/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9132 - acc: 0.5973 - val_loss: 3.9536 - val_acc: 0.5948\n",
      "Epoch 58/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9122 - acc: 0.6015 - val_loss: 3.9564 - val_acc: 0.5731\n",
      "Epoch 59/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9130 - acc: 0.5972 - val_loss: 3.9535 - val_acc: 0.5984\n",
      "Epoch 60/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.9125 - acc: 0.5957 - val_loss: 3.9561 - val_acc: 0.5943\n",
      "Epoch 61/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9132 - acc: 0.5994 - val_loss: 3.9539 - val_acc: 0.5957\n",
      "Epoch 62/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9133 - acc: 0.5947 - val_loss: 3.9517 - val_acc: 0.5842\n",
      "Epoch 63/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9107 - acc: 0.5963 - val_loss: 3.9534 - val_acc: 0.5833\n",
      "Epoch 64/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9105 - acc: 0.6001 - val_loss: 3.9512 - val_acc: 0.5833\n",
      "Epoch 65/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9112 - acc: 0.5997 - val_loss: 3.9511 - val_acc: 0.5837\n",
      "Epoch 66/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9095 - acc: 0.6001 - val_loss: 3.9533 - val_acc: 0.5842\n",
      "Epoch 67/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9109 - acc: 0.6007 - val_loss: 3.9571 - val_acc: 0.5892\n",
      "Epoch 68/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9111 - acc: 0.5994 - val_loss: 3.9509 - val_acc: 0.5911\n",
      "Epoch 69/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9106 - acc: 0.6004 - val_loss: 3.9502 - val_acc: 0.5892\n",
      "Epoch 70/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9111 - acc: 0.5993 - val_loss: 3.9514 - val_acc: 0.5823\n",
      "Epoch 71/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9087 - acc: 0.5997 - val_loss: 3.9513 - val_acc: 0.5819\n",
      "Epoch 72/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9090 - acc: 0.6006 - val_loss: 3.9507 - val_acc: 0.5837\n",
      "Epoch 73/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9101 - acc: 0.5972 - val_loss: 3.9499 - val_acc: 0.5911\n",
      "Epoch 74/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9086 - acc: 0.6009 - val_loss: 3.9601 - val_acc: 0.5718\n",
      "Epoch 75/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9101 - acc: 0.6014 - val_loss: 3.9495 - val_acc: 0.5943\n",
      "Epoch 76/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9088 - acc: 0.5988 - val_loss: 3.9511 - val_acc: 0.5961\n",
      "Epoch 77/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9104 - acc: 0.5948 - val_loss: 3.9592 - val_acc: 0.5713\n",
      "Epoch 78/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9100 - acc: 0.5984 - val_loss: 3.9567 - val_acc: 0.5745\n",
      "Epoch 79/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9088 - acc: 0.5997 - val_loss: 3.9543 - val_acc: 0.5777\n",
      "Epoch 80/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9092 - acc: 0.5987 - val_loss: 3.9489 - val_acc: 0.5952\n",
      "Epoch 81/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9072 - acc: 0.6007 - val_loss: 3.9546 - val_acc: 0.5764\n",
      "Epoch 82/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9073 - acc: 0.6009 - val_loss: 3.9482 - val_acc: 0.5883\n",
      "Epoch 83/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9073 - acc: 0.6052 - val_loss: 3.9490 - val_acc: 0.5934\n",
      "Epoch 84/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9087 - acc: 0.5999 - val_loss: 3.9550 - val_acc: 0.5865\n",
      "Epoch 85/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9081 - acc: 0.6007 - val_loss: 3.9489 - val_acc: 0.5948\n",
      "Epoch 86/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9080 - acc: 0.6003 - val_loss: 3.9616 - val_acc: 0.5805\n",
      "Epoch 87/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9080 - acc: 0.5994 - val_loss: 3.9505 - val_acc: 0.5814\n",
      "Epoch 88/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9082 - acc: 0.6001 - val_loss: 3.9487 - val_acc: 0.5934\n",
      "Epoch 89/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9071 - acc: 0.6032 - val_loss: 3.9481 - val_acc: 0.5961\n",
      "Epoch 90/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9062 - acc: 0.6019 - val_loss: 3.9549 - val_acc: 0.5773\n",
      "Epoch 91/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.9087 - acc: 0.6030 - val_loss: 3.9480 - val_acc: 0.5920\n",
      "Epoch 92/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9062 - acc: 0.6022 - val_loss: 3.9524 - val_acc: 0.5782\n",
      "Epoch 93/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9067 - acc: 0.6018 - val_loss: 3.9485 - val_acc: 0.5989\n",
      "Epoch 94/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9066 - acc: 0.6057 - val_loss: 3.9478 - val_acc: 0.5860\n",
      "Epoch 95/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9070 - acc: 0.6037 - val_loss: 3.9523 - val_acc: 0.5902\n",
      "Epoch 96/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9063 - acc: 0.6031 - val_loss: 3.9536 - val_acc: 0.5934\n",
      "Epoch 97/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9077 - acc: 0.6016 - val_loss: 3.9493 - val_acc: 0.5842\n",
      "Epoch 98/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9047 - acc: 0.6014 - val_loss: 3.9473 - val_acc: 0.5879\n",
      "Epoch 99/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9070 - acc: 0.5995 - val_loss: 3.9479 - val_acc: 0.5952\n",
      "Epoch 100/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9075 - acc: 0.6020 - val_loss: 3.9471 - val_acc: 0.5925\n",
      "Epoch 101/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9063 - acc: 0.6032 - val_loss: 3.9501 - val_acc: 0.5989\n",
      "Epoch 102/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9069 - acc: 0.6029 - val_loss: 3.9473 - val_acc: 0.5911\n",
      "Epoch 103/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9053 - acc: 0.6063 - val_loss: 3.9539 - val_acc: 0.5906\n",
      "Epoch 104/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9063 - acc: 0.6016 - val_loss: 3.9550 - val_acc: 0.5736\n",
      "Epoch 105/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.9052 - acc: 0.6068 - val_loss: 3.9468 - val_acc: 0.5888\n",
      "Epoch 106/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9061 - acc: 0.6027 - val_loss: 3.9500 - val_acc: 0.5966\n",
      "Epoch 107/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9046 - acc: 0.6058 - val_loss: 3.9468 - val_acc: 0.5943\n",
      "Epoch 108/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9063 - acc: 0.6043 - val_loss: 3.9485 - val_acc: 0.5989\n",
      "Epoch 109/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9062 - acc: 0.6014 - val_loss: 3.9486 - val_acc: 0.5888\n",
      "Epoch 110/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9067 - acc: 0.6054 - val_loss: 3.9477 - val_acc: 0.5842\n",
      "Epoch 111/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9059 - acc: 0.6033 - val_loss: 3.9466 - val_acc: 0.5888\n",
      "Epoch 112/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9067 - acc: 0.6016 - val_loss: 3.9459 - val_acc: 0.5920\n",
      "Epoch 113/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.9038 - acc: 0.6073 - val_loss: 3.9511 - val_acc: 0.5915\n",
      "Epoch 114/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.9056 - acc: 0.6035 - val_loss: 3.9474 - val_acc: 0.5846\n",
      "Epoch 115/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9052 - acc: 0.6034 - val_loss: 3.9482 - val_acc: 0.5833\n",
      "Epoch 116/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9065 - acc: 0.6002 - val_loss: 3.9465 - val_acc: 0.5989\n",
      "Epoch 117/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9048 - acc: 0.6035 - val_loss: 3.9462 - val_acc: 0.5938\n",
      "Epoch 118/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.9044 - acc: 0.6037 - val_loss: 3.9469 - val_acc: 0.5851\n",
      "Epoch 119/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9063 - acc: 0.6056 - val_loss: 3.9459 - val_acc: 0.5975\n",
      "Epoch 120/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9041 - acc: 0.6040 - val_loss: 3.9468 - val_acc: 0.5851\n",
      "Epoch 121/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9039 - acc: 0.6030 - val_loss: 3.9531 - val_acc: 0.5906\n",
      "Epoch 122/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9070 - acc: 0.6029 - val_loss: 3.9461 - val_acc: 0.5915\n",
      "Epoch 123/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9043 - acc: 0.6034 - val_loss: 3.9457 - val_acc: 0.5925\n",
      "Epoch 124/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9055 - acc: 0.6024 - val_loss: 3.9478 - val_acc: 0.5998\n",
      "Epoch 125/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9061 - acc: 0.6046 - val_loss: 3.9457 - val_acc: 0.5911\n",
      "Epoch 126/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9048 - acc: 0.6071 - val_loss: 3.9469 - val_acc: 0.6003\n",
      "Epoch 127/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9066 - acc: 0.6020 - val_loss: 3.9457 - val_acc: 0.5966\n",
      "Epoch 128/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9057 - acc: 0.6012 - val_loss: 3.9455 - val_acc: 0.5952\n",
      "Epoch 129/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9050 - acc: 0.6047 - val_loss: 3.9511 - val_acc: 0.5810\n",
      "Epoch 130/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.9054 - acc: 0.6040 - val_loss: 3.9456 - val_acc: 0.5952\n",
      "Epoch 131/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9050 - acc: 0.6058 - val_loss: 3.9484 - val_acc: 0.5819\n",
      "Epoch 132/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9056 - acc: 0.6034 - val_loss: 3.9500 - val_acc: 0.6012\n",
      "Epoch 133/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9038 - acc: 0.6057 - val_loss: 3.9453 - val_acc: 0.5897\n",
      "Epoch 134/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9045 - acc: 0.6071 - val_loss: 3.9464 - val_acc: 0.5998\n",
      "Epoch 135/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9041 - acc: 0.6050 - val_loss: 3.9450 - val_acc: 0.5966\n",
      "Epoch 136/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9042 - acc: 0.6047 - val_loss: 3.9520 - val_acc: 0.5823\n",
      "Epoch 137/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9053 - acc: 0.6025 - val_loss: 3.9646 - val_acc: 0.5713\n",
      "Epoch 138/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9059 - acc: 0.6038 - val_loss: 3.9471 - val_acc: 0.6007\n",
      "Epoch 139/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9058 - acc: 0.6060 - val_loss: 3.9449 - val_acc: 0.5952\n",
      "Epoch 140/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9056 - acc: 0.6032 - val_loss: 3.9543 - val_acc: 0.5787\n",
      "Epoch 141/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9051 - acc: 0.6054 - val_loss: 3.9511 - val_acc: 0.5846\n",
      "Epoch 142/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9054 - acc: 0.6048 - val_loss: 3.9536 - val_acc: 0.5938\n",
      "Epoch 143/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.9041 - acc: 0.6066 - val_loss: 3.9481 - val_acc: 0.5851\n",
      "Epoch 144/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9061 - acc: 0.5999 - val_loss: 3.9534 - val_acc: 0.5938\n",
      "Epoch 145/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9031 - acc: 0.6058 - val_loss: 3.9480 - val_acc: 0.5842\n",
      "Epoch 146/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9074 - acc: 0.6026 - val_loss: 3.9452 - val_acc: 0.5943\n",
      "Epoch 147/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9071 - acc: 0.5999 - val_loss: 3.9495 - val_acc: 0.5814\n",
      "Epoch 148/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9030 - acc: 0.6060 - val_loss: 3.9577 - val_acc: 0.5722\n",
      "Epoch 149/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9041 - acc: 0.6031 - val_loss: 3.9517 - val_acc: 0.5782\n",
      "Epoch 150/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9038 - acc: 0.6041 - val_loss: 3.9495 - val_acc: 0.5938\n",
      "Epoch 151/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9046 - acc: 0.6058 - val_loss: 3.9475 - val_acc: 0.6026\n",
      "Epoch 152/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9043 - acc: 0.6034 - val_loss: 3.9473 - val_acc: 0.5860\n",
      "Epoch 153/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9057 - acc: 0.6038 - val_loss: 3.9547 - val_acc: 0.5773\n",
      "Epoch 154/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9037 - acc: 0.6064 - val_loss: 3.9452 - val_acc: 0.5957\n",
      "Epoch 155/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9036 - acc: 0.6049 - val_loss: 3.9448 - val_acc: 0.5948\n",
      "Epoch 156/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9040 - acc: 0.6020 - val_loss: 3.9445 - val_acc: 0.5915\n",
      "Epoch 157/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9033 - acc: 0.6064 - val_loss: 3.9555 - val_acc: 0.5764\n",
      "Epoch 158/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9037 - acc: 0.6060 - val_loss: 3.9460 - val_acc: 0.5897\n",
      "Epoch 159/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9036 - acc: 0.6030 - val_loss: 3.9444 - val_acc: 0.5994\n",
      "Epoch 160/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9040 - acc: 0.6043 - val_loss: 3.9453 - val_acc: 0.5980\n",
      "Epoch 161/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9048 - acc: 0.6033 - val_loss: 3.9541 - val_acc: 0.5805\n",
      "Epoch 162/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9057 - acc: 0.6039 - val_loss: 3.9609 - val_acc: 0.5727\n",
      "Epoch 163/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9044 - acc: 0.6054 - val_loss: 3.9472 - val_acc: 0.6017\n",
      "Epoch 164/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9043 - acc: 0.6053 - val_loss: 3.9461 - val_acc: 0.5846\n",
      "Epoch 165/5000\n",
      "8692/8692 [==============================] - 1s 81us/step - loss: 3.9041 - acc: 0.6063 - val_loss: 3.9453 - val_acc: 0.5879\n",
      "Epoch 166/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.9047 - acc: 0.6070 - val_loss: 3.9442 - val_acc: 0.5975\n",
      "Epoch 167/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.9019 - acc: 0.6109 - val_loss: 3.9495 - val_acc: 0.5989\n",
      "Epoch 168/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9044 - acc: 0.6053 - val_loss: 3.9659 - val_acc: 0.5690\n",
      "Epoch 169/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9047 - acc: 0.6076 - val_loss: 3.9476 - val_acc: 0.5883\n",
      "Epoch 170/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9029 - acc: 0.6088 - val_loss: 3.9462 - val_acc: 0.5994\n",
      "Epoch 171/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9040 - acc: 0.6025 - val_loss: 3.9464 - val_acc: 0.5833\n",
      "Epoch 172/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9036 - acc: 0.6068 - val_loss: 3.9453 - val_acc: 0.5971\n",
      "Epoch 173/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9047 - acc: 0.6063 - val_loss: 3.9447 - val_acc: 0.5971\n",
      "Epoch 174/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9044 - acc: 0.6015 - val_loss: 3.9449 - val_acc: 0.5938\n",
      "Epoch 175/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9036 - acc: 0.6043 - val_loss: 3.9444 - val_acc: 0.5938\n",
      "Epoch 176/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9032 - acc: 0.6083 - val_loss: 3.9481 - val_acc: 0.6003\n",
      "Epoch 177/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9039 - acc: 0.6031 - val_loss: 3.9445 - val_acc: 0.5989\n",
      "Epoch 178/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9029 - acc: 0.6045 - val_loss: 3.9445 - val_acc: 0.5980\n",
      "Epoch 179/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9040 - acc: 0.6034 - val_loss: 3.9470 - val_acc: 0.6017\n",
      "Epoch 180/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9028 - acc: 0.6053 - val_loss: 3.9494 - val_acc: 0.5823\n",
      "Epoch 181/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9037 - acc: 0.6045 - val_loss: 3.9518 - val_acc: 0.5957\n",
      "Epoch 182/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9034 - acc: 0.6069 - val_loss: 3.9619 - val_acc: 0.5722\n",
      "Epoch 183/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9048 - acc: 0.6088 - val_loss: 3.9446 - val_acc: 0.5943\n",
      "Epoch 184/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9046 - acc: 0.6048 - val_loss: 3.9504 - val_acc: 0.5975\n",
      "Epoch 185/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9031 - acc: 0.6068 - val_loss: 3.9553 - val_acc: 0.5764\n",
      "Epoch 186/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.9033 - acc: 0.6035 - val_loss: 3.9438 - val_acc: 0.5925\n",
      "Epoch 187/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9040 - acc: 0.6052 - val_loss: 3.9613 - val_acc: 0.5718\n",
      "Epoch 188/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.9038 - acc: 0.6050 - val_loss: 3.9440 - val_acc: 0.5975\n",
      "Epoch 189/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.9030 - acc: 0.6071 - val_loss: 3.9440 - val_acc: 0.5943\n",
      "Epoch 190/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9034 - acc: 0.6062 - val_loss: 3.9607 - val_acc: 0.5713\n",
      "Epoch 191/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9043 - acc: 0.6034 - val_loss: 3.9447 - val_acc: 0.5966\n",
      "Epoch 192/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9026 - acc: 0.6083 - val_loss: 3.9439 - val_acc: 0.5975\n",
      "Epoch 193/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9032 - acc: 0.6049 - val_loss: 3.9442 - val_acc: 0.5897\n",
      "Epoch 194/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9032 - acc: 0.6046 - val_loss: 3.9546 - val_acc: 0.5805\n",
      "Epoch 195/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9037 - acc: 0.6049 - val_loss: 3.9458 - val_acc: 0.5975\n",
      "Epoch 196/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9039 - acc: 0.6060 - val_loss: 3.9441 - val_acc: 0.5994\n",
      "Epoch 197/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9033 - acc: 0.6041 - val_loss: 3.9446 - val_acc: 0.5989\n",
      "Epoch 198/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9031 - acc: 0.6045 - val_loss: 3.9445 - val_acc: 0.5957\n",
      "Epoch 199/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9018 - acc: 0.6072 - val_loss: 3.9461 - val_acc: 0.5865\n",
      "Epoch 200/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9045 - acc: 0.6048 - val_loss: 3.9444 - val_acc: 0.5980\n",
      "Epoch 201/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9037 - acc: 0.6027 - val_loss: 3.9518 - val_acc: 0.5856\n",
      "Epoch 202/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9035 - acc: 0.6068 - val_loss: 3.9436 - val_acc: 0.5998\n",
      "Epoch 203/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9028 - acc: 0.6073 - val_loss: 3.9471 - val_acc: 0.5883\n",
      "Epoch 204/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9038 - acc: 0.6061 - val_loss: 3.9437 - val_acc: 0.5915\n",
      "Epoch 205/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9035 - acc: 0.6064 - val_loss: 3.9705 - val_acc: 0.5695\n",
      "Epoch 206/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9040 - acc: 0.6078 - val_loss: 3.9498 - val_acc: 0.5819\n",
      "Epoch 207/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9032 - acc: 0.6049 - val_loss: 3.9462 - val_acc: 0.5828\n",
      "Epoch 208/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9034 - acc: 0.6083 - val_loss: 3.9445 - val_acc: 0.6007\n",
      "Epoch 209/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9022 - acc: 0.6068 - val_loss: 3.9460 - val_acc: 0.5984\n",
      "Epoch 210/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9040 - acc: 0.6019 - val_loss: 3.9436 - val_acc: 0.5975\n",
      "Epoch 211/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9025 - acc: 0.6075 - val_loss: 3.9446 - val_acc: 0.5925\n",
      "Epoch 212/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9032 - acc: 0.6049 - val_loss: 3.9440 - val_acc: 0.5929\n",
      "Epoch 213/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9050 - acc: 0.6045 - val_loss: 3.9441 - val_acc: 0.5943\n",
      "Epoch 214/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9028 - acc: 0.6060 - val_loss: 3.9454 - val_acc: 0.6003\n",
      "Epoch 215/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9035 - acc: 0.6045 - val_loss: 3.9450 - val_acc: 0.5869\n",
      "Epoch 216/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9049 - acc: 0.6043 - val_loss: 3.9472 - val_acc: 0.5883\n",
      "Epoch 217/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9022 - acc: 0.6058 - val_loss: 3.9466 - val_acc: 0.5998\n",
      "Epoch 218/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9031 - acc: 0.6056 - val_loss: 3.9458 - val_acc: 0.5879\n",
      "Epoch 219/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9041 - acc: 0.6055 - val_loss: 3.9440 - val_acc: 0.6012\n",
      "Epoch 220/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9020 - acc: 0.6090 - val_loss: 3.9438 - val_acc: 0.5938\n",
      "Epoch 221/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.9027 - acc: 0.6072 - val_loss: 3.9491 - val_acc: 0.5828\n",
      "Epoch 222/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9052 - acc: 0.6019 - val_loss: 3.9486 - val_acc: 0.5851\n",
      "Epoch 223/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9031 - acc: 0.6068 - val_loss: 3.9463 - val_acc: 0.5911\n",
      "Epoch 224/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9038 - acc: 0.6062 - val_loss: 3.9446 - val_acc: 0.5920\n",
      "Epoch 225/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9025 - acc: 0.6055 - val_loss: 3.9441 - val_acc: 0.5994\n",
      "Epoch 226/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9029 - acc: 0.6073 - val_loss: 3.9450 - val_acc: 0.5994\n",
      "Epoch 227/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9044 - acc: 0.6032 - val_loss: 3.9474 - val_acc: 0.5879\n",
      "Epoch 228/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9056 - acc: 0.6049 - val_loss: 3.9465 - val_acc: 0.5897\n",
      "Epoch 229/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9030 - acc: 0.6056 - val_loss: 3.9438 - val_acc: 0.6012\n",
      "Epoch 230/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9042 - acc: 0.6040 - val_loss: 3.9461 - val_acc: 0.5989\n",
      "Epoch 231/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9033 - acc: 0.6063 - val_loss: 3.9436 - val_acc: 0.6012\n",
      "Epoch 232/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9029 - acc: 0.6052 - val_loss: 3.9435 - val_acc: 0.5966\n",
      "Epoch 233/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9029 - acc: 0.6058 - val_loss: 3.9535 - val_acc: 0.5943\n",
      "Epoch 234/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9021 - acc: 0.6054 - val_loss: 3.9445 - val_acc: 0.5943\n",
      "Epoch 235/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9028 - acc: 0.6071 - val_loss: 3.9574 - val_acc: 0.5874\n",
      "Epoch 236/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9038 - acc: 0.6064 - val_loss: 3.9432 - val_acc: 0.6003\n",
      "Epoch 237/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9040 - acc: 0.6084 - val_loss: 3.9455 - val_acc: 0.5929\n",
      "Epoch 238/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9035 - acc: 0.6054 - val_loss: 3.9604 - val_acc: 0.5764\n",
      "Epoch 239/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9015 - acc: 0.6080 - val_loss: 3.9442 - val_acc: 0.5957\n",
      "Epoch 240/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9032 - acc: 0.6083 - val_loss: 3.9436 - val_acc: 0.5989\n",
      "Epoch 241/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9043 - acc: 0.6062 - val_loss: 3.9435 - val_acc: 0.5998\n",
      "Epoch 242/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9046 - acc: 0.6034 - val_loss: 3.9453 - val_acc: 0.5879\n",
      "Epoch 243/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9027 - acc: 0.6062 - val_loss: 3.9495 - val_acc: 0.5961\n",
      "Epoch 244/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9011 - acc: 0.6056 - val_loss: 3.9458 - val_acc: 0.5998\n",
      "Epoch 245/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9017 - acc: 0.6104 - val_loss: 3.9438 - val_acc: 0.5934\n",
      "Epoch 246/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9024 - acc: 0.6061 - val_loss: 3.9445 - val_acc: 0.5943\n",
      "Epoch 247/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9027 - acc: 0.6072 - val_loss: 3.9475 - val_acc: 0.5846\n",
      "Epoch 248/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9017 - acc: 0.6075 - val_loss: 3.9460 - val_acc: 0.5929\n",
      "Epoch 249/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9025 - acc: 0.6041 - val_loss: 3.9498 - val_acc: 0.5980\n",
      "Epoch 250/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9034 - acc: 0.6038 - val_loss: 3.9443 - val_acc: 0.5934\n",
      "Epoch 251/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9041 - acc: 0.6043 - val_loss: 3.9442 - val_acc: 0.5906\n",
      "Epoch 252/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9019 - acc: 0.6075 - val_loss: 3.9552 - val_acc: 0.5800\n",
      "Epoch 253/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9054 - acc: 0.6056 - val_loss: 3.9557 - val_acc: 0.5957\n",
      "Epoch 254/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9019 - acc: 0.6070 - val_loss: 3.9432 - val_acc: 0.5980\n",
      "Epoch 255/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9011 - acc: 0.6072 - val_loss: 3.9455 - val_acc: 0.5842\n",
      "Epoch 256/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.9044 - acc: 0.6063 - val_loss: 3.9524 - val_acc: 0.5800\n",
      "Epoch 257/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9028 - acc: 0.6053 - val_loss: 3.9441 - val_acc: 0.6026\n",
      "Epoch 258/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9019 - acc: 0.6070 - val_loss: 3.9439 - val_acc: 0.6012\n",
      "Epoch 259/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9017 - acc: 0.6071 - val_loss: 3.9431 - val_acc: 0.5980\n",
      "Epoch 260/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9015 - acc: 0.6050 - val_loss: 3.9441 - val_acc: 0.6003\n",
      "Epoch 261/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9043 - acc: 0.6030 - val_loss: 3.9442 - val_acc: 0.5966\n",
      "Epoch 262/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.9017 - acc: 0.6069 - val_loss: 3.9477 - val_acc: 0.5971\n",
      "Epoch 263/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9012 - acc: 0.6078 - val_loss: 3.9436 - val_acc: 0.6012\n",
      "Epoch 264/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9038 - acc: 0.6069 - val_loss: 3.9442 - val_acc: 0.6007\n",
      "Epoch 265/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9018 - acc: 0.6071 - val_loss: 3.9434 - val_acc: 0.5957\n",
      "Epoch 266/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9014 - acc: 0.6093 - val_loss: 3.9433 - val_acc: 0.6003\n",
      "Epoch 267/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9025 - acc: 0.6043 - val_loss: 3.9437 - val_acc: 0.6007\n",
      "Epoch 268/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9023 - acc: 0.6053 - val_loss: 3.9513 - val_acc: 0.5814\n",
      "Epoch 269/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9021 - acc: 0.6061 - val_loss: 3.9444 - val_acc: 0.5966\n",
      "Epoch 270/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9025 - acc: 0.6088 - val_loss: 3.9455 - val_acc: 0.5902\n",
      "Epoch 271/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9019 - acc: 0.6062 - val_loss: 3.9491 - val_acc: 0.5814\n",
      "Epoch 272/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9027 - acc: 0.6087 - val_loss: 3.9630 - val_acc: 0.5731\n",
      "Epoch 273/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9017 - acc: 0.6054 - val_loss: 3.9451 - val_acc: 0.5888\n",
      "Epoch 274/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9013 - acc: 0.6072 - val_loss: 3.9707 - val_acc: 0.5764\n",
      "Epoch 275/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9026 - acc: 0.6088 - val_loss: 3.9434 - val_acc: 0.5998\n",
      "Epoch 276/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9031 - acc: 0.6078 - val_loss: 3.9433 - val_acc: 0.5948\n",
      "Epoch 277/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9021 - acc: 0.6068 - val_loss: 3.9443 - val_acc: 0.6007\n",
      "Epoch 278/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9033 - acc: 0.6052 - val_loss: 3.9473 - val_acc: 0.5851\n",
      "Epoch 279/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9026 - acc: 0.6056 - val_loss: 3.9434 - val_acc: 0.5980\n",
      "Epoch 280/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9022 - acc: 0.6087 - val_loss: 3.9463 - val_acc: 0.5984\n",
      "Epoch 281/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9016 - acc: 0.6080 - val_loss: 3.9534 - val_acc: 0.5791\n",
      "Epoch 282/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9025 - acc: 0.6071 - val_loss: 3.9435 - val_acc: 0.5938\n",
      "Epoch 283/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9026 - acc: 0.6107 - val_loss: 3.9435 - val_acc: 0.5943\n",
      "Epoch 284/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9019 - acc: 0.6083 - val_loss: 3.9433 - val_acc: 0.5952\n",
      "Epoch 285/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9029 - acc: 0.6065 - val_loss: 3.9689 - val_acc: 0.5685\n",
      "Epoch 286/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9041 - acc: 0.6102 - val_loss: 3.9487 - val_acc: 0.5837\n",
      "Epoch 287/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9019 - acc: 0.6065 - val_loss: 3.9434 - val_acc: 0.5966\n",
      "Epoch 288/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9037 - acc: 0.6062 - val_loss: 3.9444 - val_acc: 0.5883\n",
      "Epoch 289/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9011 - acc: 0.6093 - val_loss: 3.9506 - val_acc: 0.5787\n",
      "Epoch 290/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9036 - acc: 0.6025 - val_loss: 3.9479 - val_acc: 0.5975\n",
      "Epoch 291/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9028 - acc: 0.6070 - val_loss: 3.9442 - val_acc: 0.5938\n",
      "Epoch 292/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9023 - acc: 0.6062 - val_loss: 3.9559 - val_acc: 0.5888\n",
      "Epoch 293/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9035 - acc: 0.6043 - val_loss: 3.9439 - val_acc: 0.5980\n",
      "Epoch 294/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9035 - acc: 0.6077 - val_loss: 3.9453 - val_acc: 0.5911\n",
      "Epoch 295/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9018 - acc: 0.6088 - val_loss: 3.9482 - val_acc: 0.5865\n",
      "Epoch 296/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9040 - acc: 0.6020 - val_loss: 3.9455 - val_acc: 0.5938\n",
      "Epoch 297/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9018 - acc: 0.6060 - val_loss: 3.9473 - val_acc: 0.5842\n",
      "Epoch 298/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9019 - acc: 0.6075 - val_loss: 3.9462 - val_acc: 0.5984\n",
      "Epoch 299/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9044 - acc: 0.6032 - val_loss: 3.9445 - val_acc: 0.5911\n",
      "Epoch 300/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9028 - acc: 0.6056 - val_loss: 3.9433 - val_acc: 0.5980\n",
      "Epoch 301/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9019 - acc: 0.6080 - val_loss: 3.9435 - val_acc: 0.5952\n",
      "Epoch 302/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9028 - acc: 0.6025 - val_loss: 3.9513 - val_acc: 0.5810\n",
      "Epoch 303/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9014 - acc: 0.6075 - val_loss: 3.9430 - val_acc: 0.6007\n",
      "Epoch 304/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9008 - acc: 0.6090 - val_loss: 3.9439 - val_acc: 0.5952\n",
      "Epoch 305/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9012 - acc: 0.6063 - val_loss: 3.9464 - val_acc: 0.5888\n",
      "Epoch 306/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9025 - acc: 0.6052 - val_loss: 3.9581 - val_acc: 0.5791\n",
      "Epoch 307/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9015 - acc: 0.6084 - val_loss: 3.9451 - val_acc: 0.5998\n",
      "Epoch 308/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9018 - acc: 0.6070 - val_loss: 3.9517 - val_acc: 0.5929\n",
      "Epoch 309/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.9066 - acc: 0.6019 - val_loss: 3.9450 - val_acc: 0.5915\n",
      "Epoch 310/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9012 - acc: 0.6077 - val_loss: 3.9455 - val_acc: 0.5998\n",
      "Epoch 311/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9012 - acc: 0.6078 - val_loss: 3.9575 - val_acc: 0.5764\n",
      "Epoch 312/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9022 - acc: 0.6068 - val_loss: 3.9506 - val_acc: 0.5810\n",
      "Epoch 313/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9015 - acc: 0.6062 - val_loss: 3.9471 - val_acc: 0.5879\n",
      "Epoch 314/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.9026 - acc: 0.6079 - val_loss: 3.9450 - val_acc: 0.5883\n",
      "Epoch 315/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9020 - acc: 0.6053 - val_loss: 3.9436 - val_acc: 0.6021\n",
      "Epoch 316/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9036 - acc: 0.6024 - val_loss: 3.9461 - val_acc: 0.5879\n",
      "Epoch 317/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9028 - acc: 0.6043 - val_loss: 3.9440 - val_acc: 0.5998\n",
      "Epoch 318/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9019 - acc: 0.6088 - val_loss: 3.9436 - val_acc: 0.5998\n",
      "Epoch 319/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9014 - acc: 0.6068 - val_loss: 3.9437 - val_acc: 0.5966\n",
      "Epoch 320/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9023 - acc: 0.6041 - val_loss: 3.9435 - val_acc: 0.5934\n",
      "Epoch 321/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9030 - acc: 0.6058 - val_loss: 3.9444 - val_acc: 0.5925\n",
      "Epoch 322/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9013 - acc: 0.6083 - val_loss: 3.9450 - val_acc: 0.5892\n",
      "Epoch 323/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9026 - acc: 0.6037 - val_loss: 3.9438 - val_acc: 0.5892\n",
      "Epoch 324/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9039 - acc: 0.6072 - val_loss: 3.9429 - val_acc: 0.5971\n",
      "Epoch 325/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9014 - acc: 0.6091 - val_loss: 3.9628 - val_acc: 0.5718\n",
      "Epoch 326/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9023 - acc: 0.6061 - val_loss: 3.9432 - val_acc: 0.5938\n",
      "Epoch 327/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9048 - acc: 0.6065 - val_loss: 3.9440 - val_acc: 0.5998\n",
      "Epoch 328/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9016 - acc: 0.6072 - val_loss: 3.9434 - val_acc: 0.5998\n",
      "Epoch 329/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9016 - acc: 0.6072 - val_loss: 3.9437 - val_acc: 0.5920\n",
      "Epoch 330/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9022 - acc: 0.6056 - val_loss: 3.9433 - val_acc: 0.6026\n",
      "Epoch 331/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9028 - acc: 0.6104 - val_loss: 3.9473 - val_acc: 0.5892\n",
      "Epoch 332/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9020 - acc: 0.6075 - val_loss: 3.9428 - val_acc: 0.5966\n",
      "Epoch 333/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9008 - acc: 0.6091 - val_loss: 3.9430 - val_acc: 0.5966\n",
      "Epoch 334/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9012 - acc: 0.6079 - val_loss: 3.9434 - val_acc: 0.5915\n",
      "Epoch 335/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9028 - acc: 0.6064 - val_loss: 3.9436 - val_acc: 0.5906\n",
      "Epoch 336/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9027 - acc: 0.6064 - val_loss: 3.9443 - val_acc: 0.5994\n",
      "Epoch 337/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9010 - acc: 0.6100 - val_loss: 3.9431 - val_acc: 0.5984\n",
      "Epoch 338/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9021 - acc: 0.6070 - val_loss: 3.9533 - val_acc: 0.5782\n",
      "Epoch 339/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9046 - acc: 0.6010 - val_loss: 3.9477 - val_acc: 0.5833\n",
      "Epoch 340/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9022 - acc: 0.6066 - val_loss: 3.9495 - val_acc: 0.5920\n",
      "Epoch 341/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9008 - acc: 0.6079 - val_loss: 3.9458 - val_acc: 0.5911\n",
      "Epoch 342/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9027 - acc: 0.6075 - val_loss: 3.9443 - val_acc: 0.5911\n",
      "Epoch 343/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9012 - acc: 0.6107 - val_loss: 3.9480 - val_acc: 0.5989\n",
      "Epoch 344/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.9012 - acc: 0.6072 - val_loss: 3.9465 - val_acc: 0.6003\n",
      "Epoch 345/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9016 - acc: 0.6071 - val_loss: 3.9445 - val_acc: 0.5998\n",
      "Epoch 346/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9020 - acc: 0.6084 - val_loss: 3.9430 - val_acc: 0.5961\n",
      "Epoch 347/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9022 - acc: 0.6063 - val_loss: 3.9497 - val_acc: 0.5823\n",
      "Epoch 348/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9024 - acc: 0.6086 - val_loss: 3.9441 - val_acc: 0.6003\n",
      "Epoch 349/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9015 - acc: 0.6047 - val_loss: 3.9554 - val_acc: 0.5777\n",
      "Epoch 350/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9024 - acc: 0.6064 - val_loss: 3.9471 - val_acc: 0.5865\n",
      "Epoch 351/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9031 - acc: 0.6065 - val_loss: 3.9598 - val_acc: 0.5759\n",
      "Epoch 352/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9020 - acc: 0.6095 - val_loss: 3.9567 - val_acc: 0.5920\n",
      "Epoch 353/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9024 - acc: 0.6058 - val_loss: 3.9432 - val_acc: 0.5934\n",
      "Epoch 354/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9017 - acc: 0.6068 - val_loss: 3.9434 - val_acc: 0.6012\n",
      "Epoch 355/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9014 - acc: 0.6080 - val_loss: 3.9431 - val_acc: 0.5948\n",
      "Epoch 356/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9032 - acc: 0.6069 - val_loss: 3.9443 - val_acc: 0.6040\n",
      "Epoch 357/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9031 - acc: 0.6034 - val_loss: 3.9454 - val_acc: 0.5906\n",
      "Epoch 358/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9036 - acc: 0.6057 - val_loss: 3.9425 - val_acc: 0.5994\n",
      "Epoch 359/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9024 - acc: 0.6068 - val_loss: 3.9542 - val_acc: 0.5773\n",
      "Epoch 360/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9009 - acc: 0.6071 - val_loss: 3.9558 - val_acc: 0.5883\n",
      "Epoch 361/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9019 - acc: 0.6077 - val_loss: 3.9449 - val_acc: 0.6003\n",
      "Epoch 362/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9020 - acc: 0.6073 - val_loss: 3.9559 - val_acc: 0.5727\n",
      "Epoch 363/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9018 - acc: 0.6060 - val_loss: 3.9441 - val_acc: 0.5998\n",
      "Epoch 364/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9012 - acc: 0.6094 - val_loss: 3.9467 - val_acc: 0.5984\n",
      "Epoch 365/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9017 - acc: 0.6080 - val_loss: 3.9450 - val_acc: 0.5957\n",
      "Epoch 366/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9022 - acc: 0.6077 - val_loss: 3.9455 - val_acc: 0.5971\n",
      "Epoch 367/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9030 - acc: 0.6060 - val_loss: 3.9446 - val_acc: 0.5938\n",
      "Epoch 368/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9027 - acc: 0.6093 - val_loss: 3.9472 - val_acc: 0.5874\n",
      "Epoch 369/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9017 - acc: 0.6081 - val_loss: 3.9427 - val_acc: 0.5980\n",
      "Epoch 370/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9014 - acc: 0.6046 - val_loss: 3.9429 - val_acc: 0.5980\n",
      "Epoch 371/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9011 - acc: 0.6065 - val_loss: 3.9424 - val_acc: 0.5966\n",
      "Epoch 372/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9033 - acc: 0.6055 - val_loss: 3.9431 - val_acc: 0.5966\n",
      "Epoch 373/5000\n",
      "8692/8692 [==============================] - 1s 83us/step - loss: 3.9018 - acc: 0.6078 - val_loss: 3.9575 - val_acc: 0.5768\n",
      "Epoch 374/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9015 - acc: 0.6063 - val_loss: 3.9429 - val_acc: 0.5925\n",
      "Epoch 375/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.9022 - acc: 0.6047 - val_loss: 3.9466 - val_acc: 0.5860\n",
      "Epoch 376/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9018 - acc: 0.6061 - val_loss: 3.9428 - val_acc: 0.5975\n",
      "Epoch 377/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9009 - acc: 0.6073 - val_loss: 3.9440 - val_acc: 0.5902\n",
      "Epoch 378/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9003 - acc: 0.6079 - val_loss: 3.9516 - val_acc: 0.5929\n",
      "Epoch 379/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9023 - acc: 0.6084 - val_loss: 3.9433 - val_acc: 0.6003\n",
      "Epoch 380/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9022 - acc: 0.6057 - val_loss: 3.9452 - val_acc: 0.5920\n",
      "Epoch 381/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9012 - acc: 0.6099 - val_loss: 3.9473 - val_acc: 0.5888\n",
      "Epoch 382/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9005 - acc: 0.6071 - val_loss: 3.9425 - val_acc: 0.5989\n",
      "Epoch 383/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9025 - acc: 0.6063 - val_loss: 3.9426 - val_acc: 0.5957\n",
      "Epoch 384/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9022 - acc: 0.6055 - val_loss: 3.9473 - val_acc: 0.5860\n",
      "Epoch 385/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9022 - acc: 0.6064 - val_loss: 3.9446 - val_acc: 0.5998\n",
      "Epoch 386/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9007 - acc: 0.6122 - val_loss: 3.9426 - val_acc: 0.5929\n",
      "Epoch 387/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.9018 - acc: 0.6088 - val_loss: 3.9425 - val_acc: 0.5975\n",
      "Epoch 388/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.9014 - acc: 0.6048 - val_loss: 3.9425 - val_acc: 0.5971\n",
      "Epoch 389/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.9018 - acc: 0.6054 - val_loss: 3.9429 - val_acc: 0.6007\n",
      "Epoch 390/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.9032 - acc: 0.6043 - val_loss: 3.9518 - val_acc: 0.5961\n",
      "Epoch 391/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.9027 - acc: 0.6070 - val_loss: 3.9433 - val_acc: 0.5911\n",
      "Epoch 392/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9019 - acc: 0.6063 - val_loss: 3.9442 - val_acc: 0.5915\n",
      "Epoch 393/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9015 - acc: 0.6086 - val_loss: 3.9446 - val_acc: 0.6003\n",
      "Epoch 394/5000\n",
      "8692/8692 [==============================] - 1s 84us/step - loss: 3.9003 - acc: 0.6081 - val_loss: 3.9457 - val_acc: 0.5920\n",
      "Epoch 395/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9038 - acc: 0.6041 - val_loss: 3.9466 - val_acc: 0.5994\n",
      "Epoch 396/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9004 - acc: 0.6101 - val_loss: 3.9467 - val_acc: 0.5856\n",
      "Epoch 397/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9017 - acc: 0.6070 - val_loss: 3.9518 - val_acc: 0.5805\n",
      "Epoch 398/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9013 - acc: 0.6096 - val_loss: 3.9430 - val_acc: 0.5952\n",
      "Epoch 399/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9013 - acc: 0.6085 - val_loss: 3.9428 - val_acc: 0.5966\n",
      "Epoch 400/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9025 - acc: 0.6055 - val_loss: 3.9436 - val_acc: 0.5989\n",
      "Epoch 401/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9017 - acc: 0.6058 - val_loss: 3.9430 - val_acc: 0.5952\n",
      "Epoch 402/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9011 - acc: 0.6050 - val_loss: 3.9542 - val_acc: 0.5782\n",
      "Epoch 403/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9009 - acc: 0.6109 - val_loss: 3.9467 - val_acc: 0.6003\n",
      "Epoch 404/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9020 - acc: 0.6020 - val_loss: 3.9446 - val_acc: 0.5929\n",
      "Epoch 405/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9013 - acc: 0.6050 - val_loss: 3.9477 - val_acc: 0.5814\n",
      "Epoch 406/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9003 - acc: 0.6043 - val_loss: 3.9437 - val_acc: 0.5888\n",
      "Epoch 407/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9007 - acc: 0.6079 - val_loss: 3.9428 - val_acc: 0.5957\n",
      "Epoch 408/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9022 - acc: 0.6081 - val_loss: 3.9435 - val_acc: 0.5998\n",
      "Epoch 409/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9019 - acc: 0.6058 - val_loss: 3.9475 - val_acc: 0.5888\n",
      "Epoch 410/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9003 - acc: 0.6064 - val_loss: 3.9430 - val_acc: 0.5980\n",
      "Epoch 411/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9011 - acc: 0.6077 - val_loss: 3.9426 - val_acc: 0.5989\n",
      "Epoch 412/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9010 - acc: 0.6091 - val_loss: 3.9443 - val_acc: 0.5879\n",
      "Epoch 413/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9013 - acc: 0.6058 - val_loss: 3.9434 - val_acc: 0.5984\n",
      "Epoch 414/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9019 - acc: 0.6073 - val_loss: 3.9438 - val_acc: 0.5911\n",
      "Epoch 415/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9021 - acc: 0.6061 - val_loss: 3.9480 - val_acc: 0.5948\n",
      "Epoch 416/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9021 - acc: 0.6065 - val_loss: 3.9438 - val_acc: 0.5938\n",
      "Epoch 417/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9012 - acc: 0.6081 - val_loss: 3.9436 - val_acc: 0.5925\n",
      "Epoch 418/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9004 - acc: 0.6087 - val_loss: 3.9488 - val_acc: 0.5856\n",
      "Epoch 419/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.9034 - acc: 0.6081 - val_loss: 3.9429 - val_acc: 0.5934\n",
      "Epoch 420/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9009 - acc: 0.6070 - val_loss: 3.9479 - val_acc: 0.5961\n",
      "Epoch 421/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9002 - acc: 0.6096 - val_loss: 3.9596 - val_acc: 0.5759\n",
      "Epoch 422/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9005 - acc: 0.6053 - val_loss: 3.9650 - val_acc: 0.5699\n",
      "Epoch 423/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9026 - acc: 0.6060 - val_loss: 3.9540 - val_acc: 0.5915\n",
      "Epoch 424/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.9006 - acc: 0.6088 - val_loss: 3.9452 - val_acc: 0.5929\n",
      "Epoch 425/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9001 - acc: 0.6092 - val_loss: 3.9430 - val_acc: 0.5998\n",
      "Epoch 426/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9002 - acc: 0.6083 - val_loss: 3.9436 - val_acc: 0.5929\n",
      "Epoch 427/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9016 - acc: 0.6077 - val_loss: 3.9562 - val_acc: 0.5925\n",
      "Epoch 428/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9012 - acc: 0.6100 - val_loss: 3.9486 - val_acc: 0.5865\n",
      "Epoch 429/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.9000 - acc: 0.6104 - val_loss: 3.9426 - val_acc: 0.5957\n",
      "Epoch 430/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.9005 - acc: 0.6103 - val_loss: 3.9547 - val_acc: 0.5888\n",
      "Epoch 431/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9007 - acc: 0.6091 - val_loss: 3.9429 - val_acc: 0.5929\n",
      "Epoch 432/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9003 - acc: 0.6085 - val_loss: 3.9430 - val_acc: 0.5952\n",
      "Epoch 433/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9020 - acc: 0.6075 - val_loss: 3.9442 - val_acc: 0.5998\n",
      "Epoch 434/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9002 - acc: 0.6054 - val_loss: 3.9430 - val_acc: 0.5994\n",
      "Epoch 435/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9020 - acc: 0.6086 - val_loss: 3.9468 - val_acc: 0.5998\n",
      "Epoch 436/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9016 - acc: 0.6078 - val_loss: 3.9426 - val_acc: 0.5984\n",
      "Epoch 437/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9019 - acc: 0.6088 - val_loss: 3.9438 - val_acc: 0.5902\n",
      "Epoch 438/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9000 - acc: 0.6121 - val_loss: 3.9432 - val_acc: 0.5938\n",
      "Epoch 439/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9005 - acc: 0.6091 - val_loss: 3.9520 - val_acc: 0.5800\n",
      "Epoch 440/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9009 - acc: 0.6073 - val_loss: 3.9465 - val_acc: 0.5975\n",
      "Epoch 441/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9007 - acc: 0.6090 - val_loss: 3.9673 - val_acc: 0.5731\n",
      "Epoch 442/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9031 - acc: 0.6075 - val_loss: 3.9435 - val_acc: 0.5952\n",
      "Epoch 443/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9028 - acc: 0.6087 - val_loss: 3.9463 - val_acc: 0.5902\n",
      "Epoch 444/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9027 - acc: 0.6060 - val_loss: 3.9442 - val_acc: 0.6007\n",
      "Epoch 445/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9015 - acc: 0.6079 - val_loss: 3.9439 - val_acc: 0.6003\n",
      "Epoch 446/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9014 - acc: 0.6100 - val_loss: 3.9459 - val_acc: 0.5888\n",
      "Epoch 447/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9016 - acc: 0.6104 - val_loss: 3.9457 - val_acc: 0.5998\n",
      "Epoch 448/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9012 - acc: 0.6063 - val_loss: 3.9436 - val_acc: 0.6007\n",
      "Epoch 449/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9000 - acc: 0.6115 - val_loss: 3.9422 - val_acc: 0.5957\n",
      "Epoch 450/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.9008 - acc: 0.6117 - val_loss: 3.9426 - val_acc: 0.5998\n",
      "Epoch 451/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9002 - acc: 0.6086 - val_loss: 3.9438 - val_acc: 0.5920\n",
      "Epoch 452/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9005 - acc: 0.6101 - val_loss: 3.9484 - val_acc: 0.5943\n",
      "Epoch 453/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9024 - acc: 0.6056 - val_loss: 3.9432 - val_acc: 0.5998\n",
      "Epoch 454/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9018 - acc: 0.6071 - val_loss: 3.9483 - val_acc: 0.5814\n",
      "Epoch 455/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9012 - acc: 0.6061 - val_loss: 3.9449 - val_acc: 0.5925\n",
      "Epoch 456/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9018 - acc: 0.6052 - val_loss: 3.9424 - val_acc: 0.5957\n",
      "Epoch 457/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9005 - acc: 0.6095 - val_loss: 3.9468 - val_acc: 0.5989\n",
      "Epoch 458/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9006 - acc: 0.6064 - val_loss: 3.9531 - val_acc: 0.5805\n",
      "Epoch 459/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9009 - acc: 0.6080 - val_loss: 3.9427 - val_acc: 0.6003\n",
      "Epoch 460/5000\n",
      "8692/8692 [==============================] - 1s 73us/step - loss: 3.9016 - acc: 0.6077 - val_loss: 3.9445 - val_acc: 0.5906\n",
      "Epoch 461/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.9001 - acc: 0.6069 - val_loss: 3.9434 - val_acc: 0.6003\n",
      "Epoch 462/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.9036 - acc: 0.6041 - val_loss: 3.9429 - val_acc: 0.5989\n",
      "Epoch 463/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9010 - acc: 0.6088 - val_loss: 3.9425 - val_acc: 0.5966\n",
      "Epoch 464/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9008 - acc: 0.6090 - val_loss: 3.9465 - val_acc: 0.5975\n",
      "Epoch 465/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9007 - acc: 0.6043 - val_loss: 3.9425 - val_acc: 0.6012\n",
      "Epoch 466/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9004 - acc: 0.6075 - val_loss: 3.9528 - val_acc: 0.5938\n",
      "Epoch 467/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9002 - acc: 0.6085 - val_loss: 3.9535 - val_acc: 0.5897\n",
      "Epoch 468/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9027 - acc: 0.6102 - val_loss: 3.9444 - val_acc: 0.5998\n",
      "Epoch 469/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9019 - acc: 0.6062 - val_loss: 3.9462 - val_acc: 0.5897\n",
      "Epoch 470/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9015 - acc: 0.6093 - val_loss: 3.9424 - val_acc: 0.5975\n",
      "Epoch 471/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9003 - acc: 0.6094 - val_loss: 3.9429 - val_acc: 0.5989\n",
      "Epoch 472/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9000 - acc: 0.6092 - val_loss: 3.9433 - val_acc: 0.5929\n",
      "Epoch 473/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9027 - acc: 0.6049 - val_loss: 3.9433 - val_acc: 0.5980\n",
      "Epoch 474/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9011 - acc: 0.6073 - val_loss: 3.9509 - val_acc: 0.5814\n",
      "Epoch 475/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.9013 - acc: 0.6084 - val_loss: 3.9459 - val_acc: 0.5911\n",
      "Epoch 476/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9004 - acc: 0.6073 - val_loss: 3.9425 - val_acc: 0.5980\n",
      "Epoch 477/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9021 - acc: 0.6061 - val_loss: 3.9438 - val_acc: 0.6003\n",
      "Epoch 478/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9020 - acc: 0.6081 - val_loss: 3.9436 - val_acc: 0.5920\n",
      "Epoch 479/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8999 - acc: 0.6124 - val_loss: 3.9428 - val_acc: 0.5966\n",
      "Epoch 480/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9013 - acc: 0.6106 - val_loss: 3.9506 - val_acc: 0.5819\n",
      "Epoch 481/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9020 - acc: 0.6050 - val_loss: 3.9448 - val_acc: 0.5948\n",
      "Epoch 482/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9030 - acc: 0.6073 - val_loss: 3.9443 - val_acc: 0.5984\n",
      "Epoch 483/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9004 - acc: 0.6108 - val_loss: 3.9462 - val_acc: 0.5989\n",
      "Epoch 484/5000\n",
      "8692/8692 [==============================] - 1s 99us/step - loss: 3.9003 - acc: 0.6086 - val_loss: 3.9428 - val_acc: 0.5975\n",
      "Epoch 485/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8997 - acc: 0.6104 - val_loss: 3.9441 - val_acc: 0.5925\n",
      "Epoch 486/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9005 - acc: 0.6081 - val_loss: 3.9456 - val_acc: 0.5911\n",
      "Epoch 487/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8999 - acc: 0.6060 - val_loss: 3.9440 - val_acc: 0.5975\n",
      "Epoch 488/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.9011 - acc: 0.6083 - val_loss: 3.9428 - val_acc: 0.5975\n",
      "Epoch 489/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9022 - acc: 0.6019 - val_loss: 3.9494 - val_acc: 0.5934\n",
      "Epoch 490/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.9030 - acc: 0.6056 - val_loss: 3.9447 - val_acc: 0.5934\n",
      "Epoch 491/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9016 - acc: 0.6077 - val_loss: 3.9481 - val_acc: 0.5980\n",
      "Epoch 492/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9018 - acc: 0.6055 - val_loss: 3.9485 - val_acc: 0.5833\n",
      "Epoch 493/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9014 - acc: 0.6042 - val_loss: 3.9473 - val_acc: 0.5879\n",
      "Epoch 494/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9006 - acc: 0.6096 - val_loss: 3.9459 - val_acc: 0.5925\n",
      "Epoch 495/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9011 - acc: 0.6060 - val_loss: 3.9462 - val_acc: 0.5902\n",
      "Epoch 496/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9005 - acc: 0.6083 - val_loss: 3.9437 - val_acc: 0.5952\n",
      "Epoch 497/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9004 - acc: 0.6069 - val_loss: 3.9429 - val_acc: 0.5948\n",
      "Epoch 498/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.9002 - acc: 0.6117 - val_loss: 3.9445 - val_acc: 0.6007\n",
      "Epoch 499/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9019 - acc: 0.6073 - val_loss: 3.9431 - val_acc: 0.5966\n",
      "Epoch 500/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9020 - acc: 0.6085 - val_loss: 3.9428 - val_acc: 0.5952\n",
      "Epoch 501/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9001 - acc: 0.6076 - val_loss: 3.9462 - val_acc: 0.5994\n",
      "Epoch 502/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9001 - acc: 0.6090 - val_loss: 3.9444 - val_acc: 0.6012\n",
      "Epoch 503/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9017 - acc: 0.6083 - val_loss: 3.9436 - val_acc: 0.6017\n",
      "Epoch 504/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.8993 - acc: 0.6093 - val_loss: 3.9436 - val_acc: 0.6007\n",
      "Epoch 505/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 3.9006 - acc: 0.6102 - val_loss: 3.9446 - val_acc: 0.5920\n",
      "Epoch 506/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9015 - acc: 0.6077 - val_loss: 3.9438 - val_acc: 0.6007\n",
      "Epoch 507/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.9007 - acc: 0.6062 - val_loss: 3.9476 - val_acc: 0.5874\n",
      "Epoch 508/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.9007 - acc: 0.6070 - val_loss: 3.9450 - val_acc: 0.5934\n",
      "Epoch 509/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9014 - acc: 0.6079 - val_loss: 3.9470 - val_acc: 0.5902\n",
      "Epoch 510/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9015 - acc: 0.6047 - val_loss: 3.9473 - val_acc: 0.5966\n",
      "Epoch 511/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.9019 - acc: 0.6061 - val_loss: 3.9535 - val_acc: 0.5810\n",
      "Epoch 512/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.8995 - acc: 0.6078 - val_loss: 3.9431 - val_acc: 0.5920\n",
      "Epoch 513/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9023 - acc: 0.6068 - val_loss: 3.9430 - val_acc: 0.6007\n",
      "Epoch 514/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8997 - acc: 0.6072 - val_loss: 3.9471 - val_acc: 0.5902\n",
      "Epoch 515/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9011 - acc: 0.6098 - val_loss: 3.9485 - val_acc: 0.5897\n",
      "Epoch 516/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9026 - acc: 0.6091 - val_loss: 3.9629 - val_acc: 0.5833\n",
      "Epoch 517/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.9013 - acc: 0.6077 - val_loss: 3.9470 - val_acc: 0.5888\n",
      "Epoch 518/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.9014 - acc: 0.6078 - val_loss: 3.9445 - val_acc: 0.5920\n",
      "Epoch 519/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.9029 - acc: 0.6081 - val_loss: 3.9474 - val_acc: 0.6007\n",
      "Epoch 520/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9012 - acc: 0.6058 - val_loss: 3.9445 - val_acc: 0.5929\n",
      "Epoch 521/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9004 - acc: 0.6091 - val_loss: 3.9460 - val_acc: 0.5897\n",
      "Epoch 522/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9011 - acc: 0.6122 - val_loss: 3.9430 - val_acc: 0.6003\n",
      "Epoch 523/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8999 - acc: 0.6080 - val_loss: 3.9439 - val_acc: 0.5938\n",
      "Epoch 524/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9003 - acc: 0.6080 - val_loss: 3.9737 - val_acc: 0.5676\n",
      "Epoch 525/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9021 - acc: 0.6088 - val_loss: 3.9482 - val_acc: 0.5892\n",
      "Epoch 526/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9005 - acc: 0.6070 - val_loss: 3.9432 - val_acc: 0.5952\n",
      "Epoch 527/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9002 - acc: 0.6080 - val_loss: 3.9428 - val_acc: 0.5984\n",
      "Epoch 528/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.9006 - acc: 0.6092 - val_loss: 3.9430 - val_acc: 0.5948\n",
      "Epoch 529/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9012 - acc: 0.6090 - val_loss: 3.9510 - val_acc: 0.5828\n",
      "Epoch 530/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9024 - acc: 0.6070 - val_loss: 3.9426 - val_acc: 0.5980\n",
      "Epoch 531/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9034 - acc: 0.6070 - val_loss: 3.9424 - val_acc: 0.5989\n",
      "Epoch 532/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9008 - acc: 0.6081 - val_loss: 3.9567 - val_acc: 0.5925\n",
      "Epoch 533/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9018 - acc: 0.6057 - val_loss: 3.9458 - val_acc: 0.5920\n",
      "Epoch 534/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9006 - acc: 0.6117 - val_loss: 3.9475 - val_acc: 0.5883\n",
      "Epoch 535/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8995 - acc: 0.6118 - val_loss: 3.9505 - val_acc: 0.6012\n",
      "Epoch 536/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9025 - acc: 0.6084 - val_loss: 3.9427 - val_acc: 0.5989\n",
      "Epoch 537/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.9021 - acc: 0.6055 - val_loss: 3.9445 - val_acc: 0.5998\n",
      "Epoch 538/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.9011 - acc: 0.6070 - val_loss: 3.9510 - val_acc: 0.5925\n",
      "Epoch 539/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8998 - acc: 0.6093 - val_loss: 3.9471 - val_acc: 0.5975\n",
      "Epoch 540/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9013 - acc: 0.6076 - val_loss: 3.9456 - val_acc: 0.5994\n",
      "Epoch 541/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9004 - acc: 0.6091 - val_loss: 3.9424 - val_acc: 0.5980\n",
      "Epoch 542/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8999 - acc: 0.6084 - val_loss: 3.9427 - val_acc: 0.6007\n",
      "Epoch 543/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9013 - acc: 0.6076 - val_loss: 3.9452 - val_acc: 0.6007\n",
      "Epoch 544/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9005 - acc: 0.6073 - val_loss: 3.9497 - val_acc: 0.5787\n",
      "Epoch 545/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8991 - acc: 0.6069 - val_loss: 3.9469 - val_acc: 0.5879\n",
      "Epoch 546/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8999 - acc: 0.6084 - val_loss: 3.9441 - val_acc: 0.6007\n",
      "Epoch 547/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9000 - acc: 0.6080 - val_loss: 3.9439 - val_acc: 0.5980\n",
      "Epoch 548/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9010 - acc: 0.6095 - val_loss: 3.9449 - val_acc: 0.5952\n",
      "Epoch 549/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9025 - acc: 0.6038 - val_loss: 3.9467 - val_acc: 0.5888\n",
      "Epoch 550/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9008 - acc: 0.6102 - val_loss: 3.9448 - val_acc: 0.5952\n",
      "Epoch 551/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9018 - acc: 0.6077 - val_loss: 3.9428 - val_acc: 0.5984\n",
      "Epoch 552/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9000 - acc: 0.6094 - val_loss: 3.9488 - val_acc: 0.5925\n",
      "Epoch 553/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9005 - acc: 0.6118 - val_loss: 3.9434 - val_acc: 0.5998\n",
      "Epoch 554/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9005 - acc: 0.6098 - val_loss: 3.9435 - val_acc: 0.6017\n",
      "Epoch 555/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9007 - acc: 0.6076 - val_loss: 3.9536 - val_acc: 0.5906\n",
      "Epoch 556/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9004 - acc: 0.6081 - val_loss: 3.9459 - val_acc: 0.5998\n",
      "Epoch 557/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.9005 - acc: 0.6081 - val_loss: 3.9542 - val_acc: 0.5805\n",
      "Epoch 558/5000\n",
      "8692/8692 [==============================] - 1s 93us/step - loss: 3.9001 - acc: 0.6092 - val_loss: 3.9427 - val_acc: 0.5980\n",
      "Epoch 559/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9006 - acc: 0.6109 - val_loss: 3.9434 - val_acc: 0.5989\n",
      "Epoch 560/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8996 - acc: 0.6099 - val_loss: 3.9527 - val_acc: 0.5814\n",
      "Epoch 561/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8995 - acc: 0.6110 - val_loss: 3.9430 - val_acc: 0.5961\n",
      "Epoch 562/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9017 - acc: 0.6057 - val_loss: 3.9461 - val_acc: 0.5897\n",
      "Epoch 563/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8998 - acc: 0.6083 - val_loss: 3.9544 - val_acc: 0.5773\n",
      "Epoch 564/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9009 - acc: 0.6057 - val_loss: 3.9446 - val_acc: 0.5943\n",
      "Epoch 565/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8999 - acc: 0.6124 - val_loss: 3.9437 - val_acc: 0.5998\n",
      "Epoch 566/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8994 - acc: 0.6108 - val_loss: 3.9547 - val_acc: 0.5888\n",
      "Epoch 567/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9000 - acc: 0.6080 - val_loss: 3.9427 - val_acc: 0.5980\n",
      "Epoch 568/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8999 - acc: 0.6111 - val_loss: 3.9512 - val_acc: 0.5828\n",
      "Epoch 569/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9001 - acc: 0.6103 - val_loss: 3.9526 - val_acc: 0.5823\n",
      "Epoch 570/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9017 - acc: 0.6060 - val_loss: 3.9435 - val_acc: 0.6007\n",
      "Epoch 571/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9002 - acc: 0.6077 - val_loss: 3.9452 - val_acc: 0.5952\n",
      "Epoch 572/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9009 - acc: 0.6093 - val_loss: 3.9467 - val_acc: 0.5906\n",
      "Epoch 573/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9001 - acc: 0.6096 - val_loss: 3.9512 - val_acc: 0.5948\n",
      "Epoch 574/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9014 - acc: 0.6083 - val_loss: 3.9476 - val_acc: 0.6007\n",
      "Epoch 575/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9008 - acc: 0.6083 - val_loss: 3.9473 - val_acc: 0.5879\n",
      "Epoch 576/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9003 - acc: 0.6050 - val_loss: 3.9503 - val_acc: 0.5846\n",
      "Epoch 577/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9035 - acc: 0.6049 - val_loss: 3.9434 - val_acc: 0.5998\n",
      "Epoch 578/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9004 - acc: 0.6101 - val_loss: 3.9426 - val_acc: 0.5975\n",
      "Epoch 579/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8995 - acc: 0.6100 - val_loss: 3.9438 - val_acc: 0.6026\n",
      "Epoch 580/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9015 - acc: 0.6063 - val_loss: 3.9488 - val_acc: 0.5975\n",
      "Epoch 581/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9010 - acc: 0.6069 - val_loss: 3.9433 - val_acc: 0.5929\n",
      "Epoch 582/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9003 - acc: 0.6079 - val_loss: 3.9431 - val_acc: 0.5971\n",
      "Epoch 583/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9005 - acc: 0.6071 - val_loss: 3.9441 - val_acc: 0.5994\n",
      "Epoch 584/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8994 - acc: 0.6109 - val_loss: 3.9445 - val_acc: 0.5994\n",
      "Epoch 585/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9007 - acc: 0.6055 - val_loss: 3.9477 - val_acc: 0.5994\n",
      "Epoch 586/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9016 - acc: 0.6073 - val_loss: 3.9430 - val_acc: 0.5957\n",
      "Epoch 587/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9000 - acc: 0.6101 - val_loss: 3.9437 - val_acc: 0.5984\n",
      "Epoch 588/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9009 - acc: 0.6096 - val_loss: 3.9499 - val_acc: 0.5869\n",
      "Epoch 589/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9012 - acc: 0.6073 - val_loss: 3.9432 - val_acc: 0.5984\n",
      "Epoch 590/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9002 - acc: 0.6070 - val_loss: 3.9447 - val_acc: 0.5902\n",
      "Epoch 591/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8999 - acc: 0.6090 - val_loss: 3.9450 - val_acc: 0.5989\n",
      "Epoch 592/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9009 - acc: 0.6075 - val_loss: 3.9429 - val_acc: 0.5994\n",
      "Epoch 593/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9000 - acc: 0.6094 - val_loss: 3.9447 - val_acc: 0.5948\n",
      "Epoch 594/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9003 - acc: 0.6096 - val_loss: 3.9435 - val_acc: 0.5961\n",
      "Epoch 595/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9023 - acc: 0.6078 - val_loss: 3.9460 - val_acc: 0.5994\n",
      "Epoch 596/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9000 - acc: 0.6110 - val_loss: 3.9584 - val_acc: 0.5741\n",
      "Epoch 597/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9005 - acc: 0.6086 - val_loss: 3.9526 - val_acc: 0.5828\n",
      "Epoch 598/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.9006 - acc: 0.6077 - val_loss: 3.9457 - val_acc: 0.6003\n",
      "Epoch 599/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9001 - acc: 0.6077 - val_loss: 3.9518 - val_acc: 0.5851\n",
      "Epoch 600/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9010 - acc: 0.6083 - val_loss: 3.9430 - val_acc: 0.5980\n",
      "Epoch 601/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9000 - acc: 0.6095 - val_loss: 3.9539 - val_acc: 0.5782\n",
      "Epoch 602/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8994 - acc: 0.6106 - val_loss: 3.9436 - val_acc: 0.5984\n",
      "Epoch 603/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9007 - acc: 0.6116 - val_loss: 3.9456 - val_acc: 0.6021\n",
      "Epoch 604/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8996 - acc: 0.6122 - val_loss: 3.9435 - val_acc: 0.5994\n",
      "Epoch 605/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8995 - acc: 0.6086 - val_loss: 3.9430 - val_acc: 0.5971\n",
      "Epoch 606/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9013 - acc: 0.6095 - val_loss: 3.9457 - val_acc: 0.5998\n",
      "Epoch 607/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9018 - acc: 0.6072 - val_loss: 3.9476 - val_acc: 0.6030\n",
      "Epoch 608/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9005 - acc: 0.6100 - val_loss: 3.9446 - val_acc: 0.5920\n",
      "Epoch 609/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8997 - acc: 0.6058 - val_loss: 3.9437 - val_acc: 0.6021\n",
      "Epoch 610/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9000 - acc: 0.6066 - val_loss: 3.9568 - val_acc: 0.5906\n",
      "Epoch 611/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9017 - acc: 0.6056 - val_loss: 3.9438 - val_acc: 0.5948\n",
      "Epoch 612/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8996 - acc: 0.6121 - val_loss: 3.9504 - val_acc: 0.5925\n",
      "Epoch 613/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9009 - acc: 0.6047 - val_loss: 3.9446 - val_acc: 0.5948\n",
      "Epoch 614/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8993 - acc: 0.6095 - val_loss: 3.9617 - val_acc: 0.5883\n",
      "Epoch 615/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8996 - acc: 0.6088 - val_loss: 3.9501 - val_acc: 0.5911\n",
      "Epoch 616/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8994 - acc: 0.6092 - val_loss: 3.9505 - val_acc: 0.5874\n",
      "Epoch 617/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9000 - acc: 0.6071 - val_loss: 3.9451 - val_acc: 0.5915\n",
      "Epoch 618/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9008 - acc: 0.6081 - val_loss: 3.9439 - val_acc: 0.5943\n",
      "Epoch 619/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8999 - acc: 0.6057 - val_loss: 3.9593 - val_acc: 0.5897\n",
      "Epoch 620/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9012 - acc: 0.6055 - val_loss: 3.9441 - val_acc: 0.6012\n",
      "Epoch 621/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9000 - acc: 0.6081 - val_loss: 3.9492 - val_acc: 0.5879\n",
      "Epoch 622/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9009 - acc: 0.6106 - val_loss: 3.9436 - val_acc: 0.5948\n",
      "Epoch 623/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8993 - acc: 0.6118 - val_loss: 3.9509 - val_acc: 0.5837\n",
      "Epoch 624/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8993 - acc: 0.6110 - val_loss: 3.9444 - val_acc: 0.5952\n",
      "Epoch 625/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8999 - acc: 0.6064 - val_loss: 3.9478 - val_acc: 0.5874\n",
      "Epoch 626/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8995 - acc: 0.6117 - val_loss: 3.9431 - val_acc: 0.5971\n",
      "Epoch 627/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8999 - acc: 0.6068 - val_loss: 3.9446 - val_acc: 0.5943\n",
      "Epoch 628/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9003 - acc: 0.6096 - val_loss: 3.9461 - val_acc: 0.5925\n",
      "Epoch 629/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9003 - acc: 0.6080 - val_loss: 3.9456 - val_acc: 0.5920\n",
      "Epoch 630/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8990 - acc: 0.6114 - val_loss: 3.9481 - val_acc: 0.5966\n",
      "Epoch 631/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9020 - acc: 0.6073 - val_loss: 3.9455 - val_acc: 0.5948\n",
      "Epoch 632/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8998 - acc: 0.6072 - val_loss: 3.9433 - val_acc: 0.5980\n",
      "Epoch 633/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9007 - acc: 0.6071 - val_loss: 3.9434 - val_acc: 0.6003\n",
      "Epoch 634/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9062 - acc: 0.6042 - val_loss: 3.9478 - val_acc: 0.5902\n",
      "Epoch 635/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9001 - acc: 0.6077 - val_loss: 3.9437 - val_acc: 0.6017\n",
      "Epoch 636/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9001 - acc: 0.6087 - val_loss: 3.9458 - val_acc: 0.5911\n",
      "Epoch 637/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8998 - acc: 0.6102 - val_loss: 3.9450 - val_acc: 0.5994\n",
      "Epoch 638/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8995 - acc: 0.6096 - val_loss: 3.9496 - val_acc: 0.5952\n",
      "Epoch 639/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8996 - acc: 0.6100 - val_loss: 3.9464 - val_acc: 0.5883\n",
      "Epoch 640/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8998 - acc: 0.6115 - val_loss: 3.9450 - val_acc: 0.6035\n",
      "Epoch 641/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8998 - acc: 0.6096 - val_loss: 3.9441 - val_acc: 0.5984\n",
      "Epoch 642/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.9017 - acc: 0.6060 - val_loss: 3.9453 - val_acc: 0.6012\n",
      "Epoch 643/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8998 - acc: 0.6095 - val_loss: 3.9518 - val_acc: 0.5823\n",
      "Epoch 644/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9000 - acc: 0.6088 - val_loss: 3.9443 - val_acc: 0.6003\n",
      "Epoch 645/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9007 - acc: 0.6071 - val_loss: 3.9458 - val_acc: 0.5994\n",
      "Epoch 646/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8999 - acc: 0.6077 - val_loss: 3.9456 - val_acc: 0.5906\n",
      "Epoch 647/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8996 - acc: 0.6076 - val_loss: 3.9440 - val_acc: 0.5929\n",
      "Epoch 648/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9007 - acc: 0.6108 - val_loss: 3.9443 - val_acc: 0.6003\n",
      "Epoch 649/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.8994 - acc: 0.6098 - val_loss: 3.9444 - val_acc: 0.5934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8994 - acc: 0.6076 - val_loss: 3.9470 - val_acc: 0.5892\n",
      "Epoch 651/5000\n",
      "8692/8692 [==============================] - 1s 89us/step - loss: 3.9009 - acc: 0.6090 - val_loss: 3.9427 - val_acc: 0.6007\n",
      "Epoch 652/5000\n",
      "8692/8692 [==============================] - 1s 81us/step - loss: 3.8991 - acc: 0.6096 - val_loss: 3.9470 - val_acc: 0.5998\n",
      "Epoch 653/5000\n",
      "8692/8692 [==============================] - 1s 75us/step - loss: 3.8985 - acc: 0.6084 - val_loss: 3.9444 - val_acc: 0.6003\n",
      "Epoch 654/5000\n",
      "8692/8692 [==============================] - 1s 97us/step - loss: 3.9004 - acc: 0.6106 - val_loss: 3.9445 - val_acc: 0.5915\n",
      "Epoch 655/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 3.9002 - acc: 0.6098 - val_loss: 3.9436 - val_acc: 0.5920\n",
      "Epoch 656/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.8996 - acc: 0.6066 - val_loss: 3.9440 - val_acc: 0.5952\n",
      "Epoch 657/5000\n",
      "8692/8692 [==============================] - 1s 101us/step - loss: 3.8998 - acc: 0.6086 - val_loss: 3.9467 - val_acc: 0.5911\n",
      "Epoch 658/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.8993 - acc: 0.6123 - val_loss: 3.9427 - val_acc: 0.6007\n",
      "Epoch 659/5000\n",
      "8692/8692 [==============================] - 1s 86us/step - loss: 3.8997 - acc: 0.6108 - val_loss: 3.9451 - val_acc: 0.6035\n",
      "Epoch 660/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.9020 - acc: 0.6064 - val_loss: 3.9432 - val_acc: 0.5961\n",
      "Epoch 661/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.8988 - acc: 0.6098 - val_loss: 3.9467 - val_acc: 0.5883\n",
      "Epoch 662/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8991 - acc: 0.6078 - val_loss: 3.9442 - val_acc: 0.6003\n",
      "Epoch 663/5000\n",
      "8692/8692 [==============================] - 1s 89us/step - loss: 3.9030 - acc: 0.6068 - val_loss: 3.9427 - val_acc: 0.5980\n",
      "Epoch 664/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8989 - acc: 0.6107 - val_loss: 3.9433 - val_acc: 0.5961\n",
      "Epoch 665/5000\n",
      "8692/8692 [==============================] - 1s 80us/step - loss: 3.8978 - acc: 0.6114 - val_loss: 3.9439 - val_acc: 0.5938\n",
      "Epoch 666/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.8992 - acc: 0.6099 - val_loss: 3.9436 - val_acc: 0.5966\n",
      "Epoch 667/5000\n",
      "8692/8692 [==============================] - 1s 80us/step - loss: 3.9001 - acc: 0.6080 - val_loss: 3.9608 - val_acc: 0.5741\n",
      "Epoch 668/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9008 - acc: 0.6081 - val_loss: 3.9430 - val_acc: 0.5984\n",
      "Epoch 669/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9023 - acc: 0.6057 - val_loss: 3.9552 - val_acc: 0.5814\n",
      "Epoch 670/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8993 - acc: 0.6118 - val_loss: 3.9467 - val_acc: 0.5998\n",
      "Epoch 671/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8986 - acc: 0.6077 - val_loss: 3.9472 - val_acc: 0.5957\n",
      "Epoch 672/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.9014 - acc: 0.6076 - val_loss: 3.9461 - val_acc: 0.5994\n",
      "Epoch 673/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8991 - acc: 0.6098 - val_loss: 3.9436 - val_acc: 0.5948\n",
      "Epoch 674/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.9000 - acc: 0.6071 - val_loss: 3.9439 - val_acc: 0.5961\n",
      "Epoch 675/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.9003 - acc: 0.6096 - val_loss: 3.9488 - val_acc: 0.5819\n",
      "Epoch 676/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.8997 - acc: 0.6093 - val_loss: 3.9451 - val_acc: 0.5902\n",
      "Epoch 677/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.9006 - acc: 0.6084 - val_loss: 3.9432 - val_acc: 0.5980\n",
      "Epoch 678/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8975 - acc: 0.6110 - val_loss: 3.9438 - val_acc: 0.5975\n",
      "Epoch 679/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8986 - acc: 0.6104 - val_loss: 3.9439 - val_acc: 0.6007\n",
      "Epoch 680/5000\n",
      "8692/8692 [==============================] - 1s 73us/step - loss: 3.9001 - acc: 0.6092 - val_loss: 3.9432 - val_acc: 0.5984\n",
      "Epoch 681/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.9003 - acc: 0.6107 - val_loss: 3.9445 - val_acc: 0.5952\n",
      "Epoch 682/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8991 - acc: 0.6078 - val_loss: 3.9443 - val_acc: 0.6003\n",
      "Epoch 683/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9016 - acc: 0.6096 - val_loss: 3.9459 - val_acc: 0.5938\n",
      "Epoch 684/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8996 - acc: 0.6072 - val_loss: 3.9443 - val_acc: 0.6021\n",
      "Epoch 685/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8995 - acc: 0.6113 - val_loss: 3.9433 - val_acc: 0.5966\n",
      "Epoch 686/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9015 - acc: 0.6069 - val_loss: 3.9489 - val_acc: 0.5980\n",
      "Epoch 687/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9010 - acc: 0.6079 - val_loss: 3.9445 - val_acc: 0.5980\n",
      "Epoch 688/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8997 - acc: 0.6083 - val_loss: 3.9459 - val_acc: 0.5934\n",
      "Epoch 689/5000\n",
      "8692/8692 [==============================] - 1s 86us/step - loss: 3.8997 - acc: 0.6071 - val_loss: 3.9432 - val_acc: 0.5998\n",
      "Epoch 690/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.8992 - acc: 0.6103 - val_loss: 3.9456 - val_acc: 0.5938\n",
      "Epoch 691/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8995 - acc: 0.6070 - val_loss: 3.9435 - val_acc: 0.5984\n",
      "Epoch 692/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.9006 - acc: 0.6077 - val_loss: 3.9433 - val_acc: 0.5971\n",
      "Epoch 693/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.8997 - acc: 0.6090 - val_loss: 3.9440 - val_acc: 0.5925\n",
      "Epoch 694/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8981 - acc: 0.6087 - val_loss: 3.9434 - val_acc: 0.5934\n",
      "Epoch 695/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8991 - acc: 0.6096 - val_loss: 3.9556 - val_acc: 0.5759\n",
      "Epoch 696/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8996 - acc: 0.6116 - val_loss: 3.9470 - val_acc: 0.5897\n",
      "Epoch 697/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.8989 - acc: 0.6093 - val_loss: 3.9450 - val_acc: 0.6017\n",
      "Epoch 698/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.9011 - acc: 0.6049 - val_loss: 3.9443 - val_acc: 0.5957\n",
      "Epoch 699/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8982 - acc: 0.6107 - val_loss: 3.9431 - val_acc: 0.5989\n",
      "Epoch 700/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9002 - acc: 0.6084 - val_loss: 3.9521 - val_acc: 0.5957\n",
      "Epoch 701/5000\n",
      "8692/8692 [==============================] - 1s 75us/step - loss: 3.8996 - acc: 0.6033 - val_loss: 3.9516 - val_acc: 0.5869\n",
      "Epoch 702/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8986 - acc: 0.6092 - val_loss: 3.9447 - val_acc: 0.5915\n",
      "Epoch 703/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8995 - acc: 0.6094 - val_loss: 3.9483 - val_acc: 0.5883\n",
      "Epoch 704/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.9008 - acc: 0.6061 - val_loss: 3.9514 - val_acc: 0.5952\n",
      "Epoch 705/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8985 - acc: 0.6118 - val_loss: 3.9435 - val_acc: 0.5929\n",
      "Epoch 706/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8993 - acc: 0.6081 - val_loss: 3.9574 - val_acc: 0.5800\n",
      "Epoch 707/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8995 - acc: 0.6077 - val_loss: 3.9498 - val_acc: 0.5911\n",
      "Epoch 708/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8996 - acc: 0.6075 - val_loss: 3.9434 - val_acc: 0.5961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 3.8993 - acc: 0.6107 - val_loss: 3.9475 - val_acc: 0.5984\n",
      "Epoch 710/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.9007 - acc: 0.6061 - val_loss: 3.9457 - val_acc: 0.5998\n",
      "Epoch 711/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8991 - acc: 0.6079 - val_loss: 3.9457 - val_acc: 0.5975\n",
      "Epoch 712/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8984 - acc: 0.6124 - val_loss: 3.9577 - val_acc: 0.5708\n",
      "Epoch 713/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9029 - acc: 0.6061 - val_loss: 3.9495 - val_acc: 0.5911\n",
      "Epoch 714/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9005 - acc: 0.6110 - val_loss: 3.9470 - val_acc: 0.5883\n",
      "Epoch 715/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8989 - acc: 0.6095 - val_loss: 3.9439 - val_acc: 0.5952\n",
      "Epoch 716/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.9002 - acc: 0.6114 - val_loss: 3.9461 - val_acc: 0.5929\n",
      "Epoch 717/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.9000 - acc: 0.6088 - val_loss: 3.9450 - val_acc: 0.5938\n",
      "Epoch 718/5000\n",
      "8692/8692 [==============================] - 1s 77us/step - loss: 3.8986 - acc: 0.6116 - val_loss: 3.9475 - val_acc: 0.5975\n",
      "Epoch 719/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9000 - acc: 0.6085 - val_loss: 3.9433 - val_acc: 0.6012\n",
      "Epoch 720/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.9005 - acc: 0.6081 - val_loss: 3.9436 - val_acc: 0.5975\n",
      "Epoch 721/5000\n",
      "8692/8692 [==============================] - 1s 94us/step - loss: 3.9002 - acc: 0.6079 - val_loss: 3.9448 - val_acc: 0.5994\n",
      "Epoch 722/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8979 - acc: 0.6132 - val_loss: 3.9541 - val_acc: 0.5819\n",
      "Epoch 723/5000\n",
      "8692/8692 [==============================] - 1s 75us/step - loss: 3.9005 - acc: 0.6081 - val_loss: 3.9461 - val_acc: 0.6012\n",
      "Epoch 724/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.8991 - acc: 0.6107 - val_loss: 3.9432 - val_acc: 0.5971\n",
      "Epoch 725/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.9010 - acc: 0.6076 - val_loss: 3.9481 - val_acc: 0.5879\n",
      "Epoch 726/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8984 - acc: 0.6101 - val_loss: 3.9477 - val_acc: 0.5920\n",
      "Epoch 727/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8992 - acc: 0.6080 - val_loss: 3.9448 - val_acc: 0.5948\n",
      "Epoch 728/5000\n",
      "8692/8692 [==============================] - 1s 89us/step - loss: 3.8997 - acc: 0.6084 - val_loss: 3.9434 - val_acc: 0.5980\n",
      "Epoch 729/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8986 - acc: 0.6077 - val_loss: 3.9509 - val_acc: 0.5879\n",
      "Epoch 730/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.8987 - acc: 0.6081 - val_loss: 3.9502 - val_acc: 0.5856\n",
      "Epoch 731/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8991 - acc: 0.6104 - val_loss: 3.9462 - val_acc: 0.6017\n",
      "Epoch 732/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.9005 - acc: 0.6121 - val_loss: 3.9649 - val_acc: 0.5722\n",
      "Epoch 733/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.8985 - acc: 0.6111 - val_loss: 3.9437 - val_acc: 0.5966\n",
      "Epoch 734/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8990 - acc: 0.6119 - val_loss: 3.9430 - val_acc: 0.5980\n",
      "Epoch 735/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.8984 - acc: 0.6111 - val_loss: 3.9494 - val_acc: 0.5892\n",
      "Epoch 736/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8984 - acc: 0.6081 - val_loss: 3.9463 - val_acc: 0.5897\n",
      "Epoch 737/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8997 - acc: 0.6090 - val_loss: 3.9438 - val_acc: 0.5980\n",
      "Epoch 738/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9000 - acc: 0.6072 - val_loss: 3.9429 - val_acc: 0.5961\n",
      "Epoch 739/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8986 - acc: 0.6099 - val_loss: 3.9439 - val_acc: 0.5943\n",
      "Epoch 740/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.9000 - acc: 0.6079 - val_loss: 3.9449 - val_acc: 0.5943\n",
      "Epoch 741/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8987 - acc: 0.6126 - val_loss: 3.9503 - val_acc: 0.5961\n",
      "Epoch 742/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.9002 - acc: 0.6088 - val_loss: 3.9439 - val_acc: 0.5943\n",
      "Epoch 743/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.8996 - acc: 0.6056 - val_loss: 3.9437 - val_acc: 0.5934\n",
      "Epoch 744/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8992 - acc: 0.6096 - val_loss: 3.9448 - val_acc: 0.5938\n",
      "Epoch 745/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.9001 - acc: 0.6092 - val_loss: 3.9437 - val_acc: 0.5984\n",
      "Epoch 746/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8984 - acc: 0.6106 - val_loss: 3.9534 - val_acc: 0.5828\n",
      "Epoch 747/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8997 - acc: 0.6081 - val_loss: 3.9459 - val_acc: 0.5943\n",
      "Epoch 748/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8992 - acc: 0.6091 - val_loss: 3.9450 - val_acc: 0.5929\n",
      "Epoch 749/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8986 - acc: 0.6124 - val_loss: 3.9436 - val_acc: 0.5966\n",
      "Epoch 750/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8997 - acc: 0.6079 - val_loss: 3.9479 - val_acc: 0.5911\n",
      "Epoch 751/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.9002 - acc: 0.6083 - val_loss: 3.9435 - val_acc: 0.5971\n",
      "Epoch 752/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8995 - acc: 0.6095 - val_loss: 3.9429 - val_acc: 0.6012\n",
      "Epoch 753/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8989 - acc: 0.6071 - val_loss: 3.9448 - val_acc: 0.5925\n",
      "Epoch 754/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.9003 - acc: 0.6084 - val_loss: 3.9446 - val_acc: 0.5906\n",
      "Epoch 755/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8991 - acc: 0.6109 - val_loss: 3.9668 - val_acc: 0.5699\n",
      "Epoch 756/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8996 - acc: 0.6096 - val_loss: 3.9447 - val_acc: 0.6026\n",
      "Epoch 757/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8987 - acc: 0.6090 - val_loss: 3.9435 - val_acc: 0.5980\n",
      "Epoch 758/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8981 - acc: 0.6108 - val_loss: 3.9436 - val_acc: 0.5961\n",
      "Epoch 759/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8998 - acc: 0.6075 - val_loss: 3.9432 - val_acc: 0.5980\n",
      "Epoch 760/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8996 - acc: 0.6095 - val_loss: 3.9440 - val_acc: 0.5975\n",
      "Epoch 761/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8995 - acc: 0.6115 - val_loss: 3.9464 - val_acc: 0.5929\n",
      "Epoch 762/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8995 - acc: 0.6099 - val_loss: 3.9457 - val_acc: 0.5975\n",
      "Epoch 763/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8988 - acc: 0.6106 - val_loss: 3.9449 - val_acc: 0.5906\n",
      "Epoch 764/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9003 - acc: 0.6094 - val_loss: 3.9447 - val_acc: 0.5943\n",
      "Epoch 765/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8985 - acc: 0.6104 - val_loss: 3.9459 - val_acc: 0.6007\n",
      "Epoch 766/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8993 - acc: 0.6107 - val_loss: 3.9448 - val_acc: 0.6021\n",
      "Epoch 767/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8984 - acc: 0.6086 - val_loss: 3.9650 - val_acc: 0.5699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/5000\n",
      "8692/8692 [==============================] - 1s 83us/step - loss: 3.8995 - acc: 0.6114 - val_loss: 3.9451 - val_acc: 0.6017\n",
      "Epoch 769/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.8988 - acc: 0.6092 - val_loss: 3.9452 - val_acc: 0.6017\n",
      "Epoch 770/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.8993 - acc: 0.6083 - val_loss: 3.9504 - val_acc: 0.5989\n",
      "Epoch 771/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8995 - acc: 0.6069 - val_loss: 3.9449 - val_acc: 0.5943\n",
      "Epoch 772/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8991 - acc: 0.6081 - val_loss: 3.9463 - val_acc: 0.5989\n",
      "Epoch 773/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8984 - acc: 0.6115 - val_loss: 3.9441 - val_acc: 0.5994\n",
      "Epoch 774/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.8979 - acc: 0.6115 - val_loss: 3.9436 - val_acc: 0.5984\n",
      "Epoch 775/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.8998 - acc: 0.6106 - val_loss: 3.9439 - val_acc: 0.5966\n",
      "Epoch 776/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.8987 - acc: 0.6107 - val_loss: 3.9438 - val_acc: 0.5966\n",
      "Epoch 777/5000\n",
      "8692/8692 [==============================] - 1s 92us/step - loss: 3.8983 - acc: 0.6107 - val_loss: 3.9434 - val_acc: 0.5975\n",
      "Epoch 778/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8985 - acc: 0.6106 - val_loss: 3.9446 - val_acc: 0.5975\n",
      "Epoch 779/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.9000 - acc: 0.6091 - val_loss: 3.9446 - val_acc: 0.5984\n",
      "Epoch 780/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8990 - acc: 0.6098 - val_loss: 3.9514 - val_acc: 0.5851\n",
      "Epoch 781/5000\n",
      "8692/8692 [==============================] - 1s 83us/step - loss: 3.8988 - acc: 0.6090 - val_loss: 3.9491 - val_acc: 0.5980\n",
      "Epoch 782/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.9013 - acc: 0.6050 - val_loss: 3.9445 - val_acc: 0.5934\n",
      "Epoch 783/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8992 - acc: 0.6090 - val_loss: 3.9437 - val_acc: 0.5952\n",
      "Epoch 784/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 3.8980 - acc: 0.6100 - val_loss: 3.9453 - val_acc: 0.5938\n",
      "Epoch 785/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8987 - acc: 0.6098 - val_loss: 3.9433 - val_acc: 0.6007\n",
      "Epoch 786/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8987 - acc: 0.6081 - val_loss: 3.9445 - val_acc: 0.5920\n",
      "Epoch 787/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8995 - acc: 0.6092 - val_loss: 3.9444 - val_acc: 0.5920\n",
      "Epoch 788/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8980 - acc: 0.6127 - val_loss: 3.9464 - val_acc: 0.5911\n",
      "Epoch 789/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8985 - acc: 0.6083 - val_loss: 3.9442 - val_acc: 0.5975\n",
      "Epoch 790/5000\n",
      "8692/8692 [==============================] - 1s 89us/step - loss: 3.8970 - acc: 0.6113 - val_loss: 3.9532 - val_acc: 0.5819\n",
      "Epoch 791/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.8995 - acc: 0.6085 - val_loss: 3.9436 - val_acc: 0.6026\n",
      "Epoch 792/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8999 - acc: 0.6096 - val_loss: 3.9448 - val_acc: 0.5938\n",
      "Epoch 793/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8982 - acc: 0.6095 - val_loss: 3.9443 - val_acc: 0.5984\n",
      "Epoch 794/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8977 - acc: 0.6122 - val_loss: 3.9485 - val_acc: 0.5980\n",
      "Epoch 795/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.9002 - acc: 0.6069 - val_loss: 3.9615 - val_acc: 0.5883\n",
      "Epoch 796/5000\n",
      "8692/8692 [==============================] - ETA: 0s - loss: 3.8955 - acc: 0.604 - 0s 52us/step - loss: 3.9008 - acc: 0.6042 - val_loss: 3.9445 - val_acc: 0.5925\n",
      "Epoch 797/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8979 - acc: 0.6095 - val_loss: 3.9461 - val_acc: 0.5943\n",
      "Epoch 798/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8986 - acc: 0.6101 - val_loss: 3.9557 - val_acc: 0.5915\n",
      "Epoch 799/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8998 - acc: 0.6098 - val_loss: 3.9557 - val_acc: 0.5800\n",
      "Epoch 800/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8991 - acc: 0.6098 - val_loss: 3.9444 - val_acc: 0.5920\n",
      "Epoch 801/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8993 - acc: 0.6091 - val_loss: 3.9438 - val_acc: 0.5975\n",
      "Epoch 802/5000\n",
      "8692/8692 [==============================] - 1s 84us/step - loss: 3.8996 - acc: 0.6103 - val_loss: 3.9505 - val_acc: 0.5980\n",
      "Epoch 803/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.8996 - acc: 0.6084 - val_loss: 3.9446 - val_acc: 0.6012\n",
      "Epoch 804/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8983 - acc: 0.6084 - val_loss: 3.9495 - val_acc: 0.5948\n",
      "Epoch 805/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.9003 - acc: 0.6093 - val_loss: 3.9448 - val_acc: 0.5929\n",
      "Epoch 806/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8987 - acc: 0.6095 - val_loss: 3.9577 - val_acc: 0.5906\n",
      "Epoch 807/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.8990 - acc: 0.6113 - val_loss: 3.9500 - val_acc: 0.5915\n",
      "Epoch 808/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8979 - acc: 0.6149 - val_loss: 3.9447 - val_acc: 0.5943\n",
      "Epoch 809/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.8994 - acc: 0.6115 - val_loss: 3.9458 - val_acc: 0.5943\n",
      "Epoch 810/5000\n",
      "8692/8692 [==============================] - 1s 75us/step - loss: 3.8982 - acc: 0.6095 - val_loss: 3.9469 - val_acc: 0.6007\n",
      "Epoch 811/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.8970 - acc: 0.6141 - val_loss: 3.9558 - val_acc: 0.5782\n",
      "Epoch 812/5000\n",
      "8692/8692 [==============================] - 1s 81us/step - loss: 3.8993 - acc: 0.6083 - val_loss: 3.9445 - val_acc: 0.5984\n",
      "Epoch 813/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8987 - acc: 0.6113 - val_loss: 3.9489 - val_acc: 0.5897\n",
      "Epoch 814/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8993 - acc: 0.6076 - val_loss: 3.9504 - val_acc: 0.5948\n",
      "Epoch 815/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.9002 - acc: 0.6083 - val_loss: 3.9440 - val_acc: 0.5989\n",
      "Epoch 816/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.8991 - acc: 0.6124 - val_loss: 3.9442 - val_acc: 0.5975\n",
      "Epoch 817/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8993 - acc: 0.6090 - val_loss: 3.9471 - val_acc: 0.5897\n",
      "Epoch 818/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8993 - acc: 0.6093 - val_loss: 3.9438 - val_acc: 0.5966\n",
      "Epoch 819/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8983 - acc: 0.6104 - val_loss: 3.9477 - val_acc: 0.5989\n",
      "Epoch 820/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8994 - acc: 0.6085 - val_loss: 3.9559 - val_acc: 0.5966\n",
      "Epoch 821/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.9003 - acc: 0.6078 - val_loss: 3.9441 - val_acc: 0.5957\n",
      "Epoch 822/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8991 - acc: 0.6111 - val_loss: 3.9458 - val_acc: 0.5934\n",
      "Epoch 823/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8979 - acc: 0.6103 - val_loss: 3.9451 - val_acc: 0.6012\n",
      "Epoch 824/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8988 - acc: 0.6080 - val_loss: 3.9462 - val_acc: 0.5943\n",
      "Epoch 825/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.8990 - acc: 0.6093 - val_loss: 3.9506 - val_acc: 0.5879\n",
      "Epoch 826/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8984 - acc: 0.6091 - val_loss: 3.9524 - val_acc: 0.5879\n",
      "Epoch 827/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8986 - acc: 0.6110 - val_loss: 3.9442 - val_acc: 0.5971\n",
      "Epoch 828/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.8976 - acc: 0.6079 - val_loss: 3.9555 - val_acc: 0.5948\n",
      "Epoch 829/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8982 - acc: 0.6087 - val_loss: 3.9488 - val_acc: 0.5892\n",
      "Epoch 830/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.8999 - acc: 0.6081 - val_loss: 3.9482 - val_acc: 0.6007\n",
      "Epoch 831/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.8984 - acc: 0.6108 - val_loss: 3.9442 - val_acc: 0.5994\n",
      "Epoch 832/5000\n",
      "8692/8692 [==============================] - 1s 77us/step - loss: 3.8991 - acc: 0.6093 - val_loss: 3.9494 - val_acc: 0.5980\n",
      "Epoch 833/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8971 - acc: 0.6131 - val_loss: 3.9436 - val_acc: 0.5952\n",
      "Epoch 834/5000\n",
      "8692/8692 [==============================] - 1s 93us/step - loss: 3.9005 - acc: 0.6060 - val_loss: 3.9435 - val_acc: 0.5980\n",
      "Epoch 835/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8997 - acc: 0.6058 - val_loss: 3.9693 - val_acc: 0.5823\n",
      "Epoch 836/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.8988 - acc: 0.6081 - val_loss: 3.9444 - val_acc: 0.6012\n",
      "Epoch 837/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8984 - acc: 0.6093 - val_loss: 3.9446 - val_acc: 0.5920\n",
      "Epoch 838/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.9001 - acc: 0.6066 - val_loss: 3.9454 - val_acc: 0.6021\n",
      "Epoch 839/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8989 - acc: 0.6100 - val_loss: 3.9515 - val_acc: 0.5869\n",
      "Epoch 840/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8990 - acc: 0.6109 - val_loss: 3.9443 - val_acc: 0.5925\n",
      "Epoch 841/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8986 - acc: 0.6083 - val_loss: 3.9437 - val_acc: 0.5971\n",
      "Epoch 842/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8972 - acc: 0.6113 - val_loss: 3.9467 - val_acc: 0.5902\n",
      "Epoch 843/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8993 - acc: 0.6101 - val_loss: 3.9565 - val_acc: 0.5925\n",
      "Epoch 844/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8988 - acc: 0.6111 - val_loss: 3.9458 - val_acc: 0.5906\n",
      "Epoch 845/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8977 - acc: 0.6121 - val_loss: 3.9460 - val_acc: 0.5929\n",
      "Epoch 846/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8981 - acc: 0.6093 - val_loss: 3.9438 - val_acc: 0.5938\n",
      "Epoch 847/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8991 - acc: 0.6084 - val_loss: 3.9504 - val_acc: 0.5879\n",
      "Epoch 848/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8999 - acc: 0.6079 - val_loss: 3.9534 - val_acc: 0.5952\n",
      "Epoch 849/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.9002 - acc: 0.6098 - val_loss: 3.9442 - val_acc: 0.5902\n",
      "Epoch 850/5000\n",
      "8692/8692 [==============================] - 1s 81us/step - loss: 3.8975 - acc: 0.6118 - val_loss: 3.9451 - val_acc: 0.5934\n",
      "Epoch 851/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8992 - acc: 0.6102 - val_loss: 3.9469 - val_acc: 0.6017\n",
      "Epoch 852/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8981 - acc: 0.6107 - val_loss: 3.9436 - val_acc: 0.5980\n",
      "Epoch 853/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8982 - acc: 0.6102 - val_loss: 3.9443 - val_acc: 0.5984\n",
      "Epoch 854/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8987 - acc: 0.6083 - val_loss: 3.9471 - val_acc: 0.6012\n",
      "Epoch 855/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8981 - acc: 0.6087 - val_loss: 3.9445 - val_acc: 0.5966\n",
      "Epoch 856/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8972 - acc: 0.6118 - val_loss: 3.9449 - val_acc: 0.5975\n",
      "Epoch 857/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8980 - acc: 0.6071 - val_loss: 3.9441 - val_acc: 0.5994\n",
      "Epoch 858/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8978 - acc: 0.6109 - val_loss: 3.9483 - val_acc: 0.6003\n",
      "Epoch 859/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8985 - acc: 0.6102 - val_loss: 3.9445 - val_acc: 0.5980\n",
      "Epoch 860/5000\n",
      "8692/8692 [==============================] - 1s 73us/step - loss: 3.8978 - acc: 0.6080 - val_loss: 3.9466 - val_acc: 0.5897\n",
      "Epoch 861/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8982 - acc: 0.6119 - val_loss: 3.9442 - val_acc: 0.5934\n",
      "Epoch 862/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8978 - acc: 0.6129 - val_loss: 3.9445 - val_acc: 0.5980\n",
      "Epoch 863/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8981 - acc: 0.6100 - val_loss: 3.9522 - val_acc: 0.5971\n",
      "Epoch 864/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8993 - acc: 0.6068 - val_loss: 3.9587 - val_acc: 0.5911\n",
      "Epoch 865/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8977 - acc: 0.6092 - val_loss: 3.9461 - val_acc: 0.5920\n",
      "Epoch 866/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8989 - acc: 0.6080 - val_loss: 3.9501 - val_acc: 0.5911\n",
      "Epoch 867/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8973 - acc: 0.6100 - val_loss: 3.9470 - val_acc: 0.6012\n",
      "Epoch 868/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8974 - acc: 0.6119 - val_loss: 3.9478 - val_acc: 0.5920\n",
      "Epoch 869/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8975 - acc: 0.6107 - val_loss: 3.9477 - val_acc: 0.5975\n",
      "Epoch 870/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8982 - acc: 0.6119 - val_loss: 3.9445 - val_acc: 0.5943\n",
      "Epoch 871/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.8989 - acc: 0.6102 - val_loss: 3.9462 - val_acc: 0.6012\n",
      "Epoch 872/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.9001 - acc: 0.6060 - val_loss: 3.9541 - val_acc: 0.5773\n",
      "Epoch 873/5000\n",
      "8692/8692 [==============================] - 1s 75us/step - loss: 3.8973 - acc: 0.6099 - val_loss: 3.9448 - val_acc: 0.5998\n",
      "Epoch 874/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8980 - acc: 0.6098 - val_loss: 3.9434 - val_acc: 0.5980\n",
      "Epoch 875/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8979 - acc: 0.6126 - val_loss: 3.9577 - val_acc: 0.5915\n",
      "Epoch 876/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8994 - acc: 0.6091 - val_loss: 3.9481 - val_acc: 0.5925\n",
      "Epoch 877/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8979 - acc: 0.6117 - val_loss: 3.9435 - val_acc: 0.5980\n",
      "Epoch 878/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8982 - acc: 0.6125 - val_loss: 3.9448 - val_acc: 0.6007\n",
      "Epoch 879/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.8986 - acc: 0.6102 - val_loss: 3.9442 - val_acc: 0.6003\n",
      "Epoch 880/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8991 - acc: 0.6093 - val_loss: 3.9451 - val_acc: 0.5998\n",
      "Epoch 881/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8996 - acc: 0.6109 - val_loss: 3.9453 - val_acc: 0.5948\n",
      "Epoch 882/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8981 - acc: 0.6098 - val_loss: 3.9458 - val_acc: 0.5984\n",
      "Epoch 883/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8985 - acc: 0.6094 - val_loss: 3.9444 - val_acc: 0.5934\n",
      "Epoch 884/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8976 - acc: 0.6101 - val_loss: 3.9439 - val_acc: 0.5938\n",
      "Epoch 885/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8984 - acc: 0.6087 - val_loss: 3.9487 - val_acc: 0.6017\n",
      "Epoch 886/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8984 - acc: 0.6081 - val_loss: 3.9506 - val_acc: 0.5851\n",
      "Epoch 887/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8990 - acc: 0.6083 - val_loss: 3.9448 - val_acc: 0.5925\n",
      "Epoch 888/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8999 - acc: 0.6055 - val_loss: 3.9480 - val_acc: 0.5883\n",
      "Epoch 889/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8976 - acc: 0.6090 - val_loss: 3.9439 - val_acc: 0.5971\n",
      "Epoch 890/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8989 - acc: 0.6094 - val_loss: 3.9454 - val_acc: 0.5929\n",
      "Epoch 891/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8984 - acc: 0.6078 - val_loss: 3.9449 - val_acc: 0.5925\n",
      "Epoch 892/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8972 - acc: 0.6126 - val_loss: 3.9458 - val_acc: 0.5989\n",
      "Epoch 893/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8972 - acc: 0.6101 - val_loss: 3.9443 - val_acc: 0.5929\n",
      "Epoch 894/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8979 - acc: 0.6115 - val_loss: 3.9438 - val_acc: 0.5980\n",
      "Epoch 895/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.8980 - acc: 0.6103 - val_loss: 3.9436 - val_acc: 0.5975\n",
      "Epoch 896/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8978 - acc: 0.6093 - val_loss: 3.9452 - val_acc: 0.5920\n",
      "Epoch 897/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8996 - acc: 0.6045 - val_loss: 3.9496 - val_acc: 0.5902\n",
      "Epoch 898/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8984 - acc: 0.6087 - val_loss: 3.9438 - val_acc: 0.5989\n",
      "Epoch 899/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8989 - acc: 0.6071 - val_loss: 3.9441 - val_acc: 0.5938\n",
      "Epoch 900/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.8994 - acc: 0.6098 - val_loss: 3.9441 - val_acc: 0.5998\n",
      "Epoch 901/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8980 - acc: 0.6116 - val_loss: 3.9466 - val_acc: 0.5943\n",
      "Epoch 902/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 3.8979 - acc: 0.6091 - val_loss: 3.9472 - val_acc: 0.6021\n",
      "Epoch 903/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8981 - acc: 0.6125 - val_loss: 3.9464 - val_acc: 0.5911\n",
      "Epoch 904/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9001 - acc: 0.6076 - val_loss: 3.9450 - val_acc: 0.5934\n",
      "Epoch 905/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8976 - acc: 0.6110 - val_loss: 3.9453 - val_acc: 0.5938\n",
      "Epoch 906/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8979 - acc: 0.6092 - val_loss: 3.9448 - val_acc: 0.5915\n",
      "Epoch 907/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8985 - acc: 0.6100 - val_loss: 3.9454 - val_acc: 0.6021\n",
      "Epoch 908/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8982 - acc: 0.6084 - val_loss: 3.9464 - val_acc: 0.6017\n",
      "Epoch 909/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8996 - acc: 0.6076 - val_loss: 3.9490 - val_acc: 0.5994\n",
      "Epoch 910/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8979 - acc: 0.6111 - val_loss: 3.9478 - val_acc: 0.5966\n",
      "Epoch 911/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8998 - acc: 0.6095 - val_loss: 3.9452 - val_acc: 0.5943\n",
      "Epoch 912/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8975 - acc: 0.6100 - val_loss: 3.9440 - val_acc: 0.5961\n",
      "Epoch 913/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8988 - acc: 0.6078 - val_loss: 3.9440 - val_acc: 0.5971\n",
      "Epoch 914/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8979 - acc: 0.6122 - val_loss: 3.9554 - val_acc: 0.5814\n",
      "Epoch 915/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8968 - acc: 0.6114 - val_loss: 3.9440 - val_acc: 0.5994\n",
      "Epoch 916/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8987 - acc: 0.6117 - val_loss: 3.9444 - val_acc: 0.5957\n",
      "Epoch 917/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8987 - acc: 0.6118 - val_loss: 3.9457 - val_acc: 0.5920\n",
      "Epoch 918/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8988 - acc: 0.6111 - val_loss: 3.9451 - val_acc: 0.6007\n",
      "Epoch 919/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8981 - acc: 0.6094 - val_loss: 3.9454 - val_acc: 0.5961\n",
      "Epoch 920/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.9000 - acc: 0.6087 - val_loss: 3.9453 - val_acc: 0.5925\n",
      "Epoch 921/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8976 - acc: 0.6104 - val_loss: 3.9592 - val_acc: 0.5929\n",
      "Epoch 922/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8990 - acc: 0.6096 - val_loss: 3.9447 - val_acc: 0.6017\n",
      "Epoch 923/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8984 - acc: 0.6126 - val_loss: 3.9508 - val_acc: 0.5883\n",
      "Epoch 924/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8973 - acc: 0.6119 - val_loss: 3.9457 - val_acc: 0.5994\n",
      "Epoch 925/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8977 - acc: 0.6111 - val_loss: 3.9450 - val_acc: 0.5984\n",
      "Epoch 926/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8989 - acc: 0.6122 - val_loss: 3.9467 - val_acc: 0.5911\n",
      "Epoch 927/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8971 - acc: 0.6099 - val_loss: 3.9454 - val_acc: 0.5929\n",
      "Epoch 928/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8968 - acc: 0.6095 - val_loss: 3.9483 - val_acc: 0.6030\n",
      "Epoch 929/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8980 - acc: 0.6117 - val_loss: 3.9526 - val_acc: 0.5869\n",
      "Epoch 930/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8981 - acc: 0.6095 - val_loss: 3.9445 - val_acc: 0.6003\n",
      "Epoch 931/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.9003 - acc: 0.6052 - val_loss: 3.9546 - val_acc: 0.5920\n",
      "Epoch 932/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8980 - acc: 0.6111 - val_loss: 3.9550 - val_acc: 0.5938\n",
      "Epoch 933/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8979 - acc: 0.6119 - val_loss: 3.9588 - val_acc: 0.5777\n",
      "Epoch 934/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8990 - acc: 0.6096 - val_loss: 3.9571 - val_acc: 0.5768\n",
      "Epoch 935/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8978 - acc: 0.6094 - val_loss: 3.9447 - val_acc: 0.6003\n",
      "Epoch 936/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8978 - acc: 0.6065 - val_loss: 3.9496 - val_acc: 0.5906\n",
      "Epoch 937/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8986 - acc: 0.6101 - val_loss: 3.9466 - val_acc: 0.6007\n",
      "Epoch 938/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8992 - acc: 0.6091 - val_loss: 3.9498 - val_acc: 0.6003\n",
      "Epoch 939/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8983 - acc: 0.6099 - val_loss: 3.9478 - val_acc: 0.6021\n",
      "Epoch 940/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8976 - acc: 0.6109 - val_loss: 3.9456 - val_acc: 0.5971\n",
      "Epoch 941/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8977 - acc: 0.6100 - val_loss: 3.9464 - val_acc: 0.5943\n",
      "Epoch 942/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8980 - acc: 0.6088 - val_loss: 3.9484 - val_acc: 0.5911\n",
      "Epoch 943/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8985 - acc: 0.6076 - val_loss: 3.9509 - val_acc: 0.5897\n",
      "Epoch 944/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8968 - acc: 0.6106 - val_loss: 3.9465 - val_acc: 0.5938\n",
      "Epoch 945/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8971 - acc: 0.6111 - val_loss: 3.9457 - val_acc: 0.5943\n",
      "Epoch 946/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8993 - acc: 0.6115 - val_loss: 3.9455 - val_acc: 0.5998\n",
      "Epoch 947/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8987 - acc: 0.6086 - val_loss: 3.9458 - val_acc: 0.5929\n",
      "Epoch 948/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8983 - acc: 0.6076 - val_loss: 3.9454 - val_acc: 0.5934\n",
      "Epoch 949/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8991 - acc: 0.6072 - val_loss: 3.9628 - val_acc: 0.5768\n",
      "Epoch 950/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8985 - acc: 0.6103 - val_loss: 3.9473 - val_acc: 0.6040\n",
      "Epoch 951/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8974 - acc: 0.6103 - val_loss: 3.9464 - val_acc: 0.5938\n",
      "Epoch 952/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8989 - acc: 0.6056 - val_loss: 3.9456 - val_acc: 0.5980\n",
      "Epoch 953/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8971 - acc: 0.6098 - val_loss: 3.9530 - val_acc: 0.5948\n",
      "Epoch 954/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8979 - acc: 0.6115 - val_loss: 3.9493 - val_acc: 0.5925\n",
      "Epoch 955/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8988 - acc: 0.6095 - val_loss: 3.9468 - val_acc: 0.5989\n",
      "Epoch 956/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8990 - acc: 0.6091 - val_loss: 3.9450 - val_acc: 0.5957\n",
      "Epoch 957/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8972 - acc: 0.6118 - val_loss: 3.9462 - val_acc: 0.5915\n",
      "Epoch 958/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8971 - acc: 0.6115 - val_loss: 3.9462 - val_acc: 0.5938\n",
      "Epoch 959/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8973 - acc: 0.6085 - val_loss: 3.9481 - val_acc: 0.5998\n",
      "Epoch 960/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.9000 - acc: 0.6065 - val_loss: 3.9458 - val_acc: 0.5998\n",
      "Epoch 961/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8993 - acc: 0.6048 - val_loss: 3.9451 - val_acc: 0.5989\n",
      "Epoch 962/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8968 - acc: 0.6118 - val_loss: 3.9468 - val_acc: 0.5925\n",
      "Epoch 963/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8989 - acc: 0.6054 - val_loss: 3.9456 - val_acc: 0.5961\n",
      "Epoch 964/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8976 - acc: 0.6102 - val_loss: 3.9471 - val_acc: 0.5925\n",
      "Epoch 965/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8973 - acc: 0.6127 - val_loss: 3.9458 - val_acc: 0.5994\n",
      "Epoch 966/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8994 - acc: 0.6075 - val_loss: 3.9478 - val_acc: 0.5906\n",
      "Epoch 967/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8991 - acc: 0.6099 - val_loss: 3.9515 - val_acc: 0.5984\n",
      "Epoch 968/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8977 - acc: 0.6087 - val_loss: 3.9459 - val_acc: 0.5934\n",
      "Epoch 969/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8985 - acc: 0.6087 - val_loss: 3.9474 - val_acc: 0.5938\n",
      "Epoch 970/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8980 - acc: 0.6106 - val_loss: 3.9483 - val_acc: 0.5948\n",
      "Epoch 971/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8986 - acc: 0.6095 - val_loss: 3.9460 - val_acc: 0.5975\n",
      "Epoch 972/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8975 - acc: 0.6092 - val_loss: 3.9476 - val_acc: 0.6003\n",
      "Epoch 973/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8981 - acc: 0.6088 - val_loss: 3.9520 - val_acc: 0.5998\n",
      "Epoch 974/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8969 - acc: 0.6119 - val_loss: 3.9517 - val_acc: 0.5998\n",
      "Epoch 975/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8987 - acc: 0.6108 - val_loss: 3.9484 - val_acc: 0.5934\n",
      "Epoch 976/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8986 - acc: 0.6113 - val_loss: 3.9489 - val_acc: 0.6017\n",
      "Epoch 977/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8981 - acc: 0.6099 - val_loss: 3.9488 - val_acc: 0.5929\n",
      "Epoch 978/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8967 - acc: 0.6110 - val_loss: 3.9460 - val_acc: 0.6007\n",
      "Epoch 979/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8995 - acc: 0.6113 - val_loss: 3.9461 - val_acc: 0.5934\n",
      "Epoch 980/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8969 - acc: 0.6081 - val_loss: 3.9571 - val_acc: 0.5948\n",
      "Epoch 981/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8976 - acc: 0.6113 - val_loss: 3.9609 - val_acc: 0.5915\n",
      "Epoch 982/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8995 - acc: 0.6093 - val_loss: 3.9464 - val_acc: 0.5971\n",
      "Epoch 983/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8978 - acc: 0.6116 - val_loss: 3.9462 - val_acc: 0.5984\n",
      "Epoch 984/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8987 - acc: 0.6121 - val_loss: 3.9477 - val_acc: 0.5938\n",
      "Epoch 985/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8973 - acc: 0.6099 - val_loss: 3.9461 - val_acc: 0.5952\n",
      "Epoch 986/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8970 - acc: 0.6099 - val_loss: 3.9467 - val_acc: 0.6007\n",
      "Epoch 987/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8983 - acc: 0.6073 - val_loss: 3.9450 - val_acc: 0.5994\n",
      "Epoch 988/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8963 - acc: 0.6101 - val_loss: 3.9511 - val_acc: 0.5998\n",
      "Epoch 989/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8988 - acc: 0.6110 - val_loss: 3.9455 - val_acc: 0.5971\n",
      "Epoch 990/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8967 - acc: 0.6108 - val_loss: 3.9458 - val_acc: 0.5948\n",
      "Epoch 991/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8983 - acc: 0.6106 - val_loss: 3.9488 - val_acc: 0.6012\n",
      "Epoch 992/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8964 - acc: 0.6110 - val_loss: 3.9488 - val_acc: 0.6053\n",
      "Epoch 993/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8971 - acc: 0.6102 - val_loss: 3.9463 - val_acc: 0.5961\n",
      "Epoch 994/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8971 - acc: 0.6104 - val_loss: 3.9451 - val_acc: 0.5980\n",
      "Epoch 995/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8978 - acc: 0.6068 - val_loss: 3.9469 - val_acc: 0.6007\n",
      "Epoch 996/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8988 - acc: 0.6060 - val_loss: 3.9463 - val_acc: 0.5957\n",
      "Epoch 997/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8982 - acc: 0.6108 - val_loss: 3.9464 - val_acc: 0.5971\n",
      "Epoch 998/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8975 - acc: 0.6099 - val_loss: 3.9465 - val_acc: 0.5980\n",
      "Epoch 999/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8978 - acc: 0.6094 - val_loss: 3.9461 - val_acc: 0.5971\n",
      "Epoch 1000/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8972 - acc: 0.6098 - val_loss: 3.9455 - val_acc: 0.5971\n",
      "Epoch 1001/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.8970 - acc: 0.6079 - val_loss: 3.9459 - val_acc: 0.5961\n",
      "Epoch 1002/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8988 - acc: 0.6098 - val_loss: 3.9497 - val_acc: 0.5925\n",
      "Epoch 1003/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8978 - acc: 0.6102 - val_loss: 3.9507 - val_acc: 0.5920\n",
      "Epoch 1004/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8972 - acc: 0.6109 - val_loss: 3.9466 - val_acc: 0.5984\n",
      "Epoch 1005/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8980 - acc: 0.6096 - val_loss: 3.9453 - val_acc: 0.5975\n",
      "Epoch 1006/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8981 - acc: 0.6087 - val_loss: 3.9460 - val_acc: 0.5961\n",
      "Epoch 1007/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8980 - acc: 0.6114 - val_loss: 3.9456 - val_acc: 0.5971\n",
      "Epoch 1008/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8980 - acc: 0.6102 - val_loss: 3.9477 - val_acc: 0.5929\n",
      "Epoch 1009/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8989 - acc: 0.6087 - val_loss: 3.9472 - val_acc: 0.5994\n",
      "Epoch 1010/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8970 - acc: 0.6129 - val_loss: 3.9503 - val_acc: 0.5925\n",
      "Epoch 1011/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8975 - acc: 0.6117 - val_loss: 3.9467 - val_acc: 0.5920\n",
      "Epoch 1012/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8975 - acc: 0.6139 - val_loss: 3.9564 - val_acc: 0.5777\n",
      "Epoch 1013/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8974 - acc: 0.6114 - val_loss: 3.9520 - val_acc: 0.5851\n",
      "Epoch 1014/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8983 - acc: 0.6102 - val_loss: 3.9487 - val_acc: 0.6044\n",
      "Epoch 1015/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8969 - acc: 0.6116 - val_loss: 3.9468 - val_acc: 0.5915\n",
      "Epoch 1016/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8979 - acc: 0.6084 - val_loss: 3.9469 - val_acc: 0.5906\n",
      "Epoch 1017/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8982 - acc: 0.6102 - val_loss: 3.9453 - val_acc: 0.5938\n",
      "Epoch 1018/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8967 - acc: 0.6103 - val_loss: 3.9461 - val_acc: 0.5998\n",
      "Epoch 1019/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8974 - acc: 0.6110 - val_loss: 3.9463 - val_acc: 0.5971\n",
      "Epoch 1020/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8971 - acc: 0.6096 - val_loss: 3.9457 - val_acc: 0.5984\n",
      "Epoch 1021/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8972 - acc: 0.6096 - val_loss: 3.9453 - val_acc: 0.5984\n",
      "Epoch 1022/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8972 - acc: 0.6109 - val_loss: 3.9467 - val_acc: 0.6017\n",
      "Epoch 1023/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8991 - acc: 0.6099 - val_loss: 3.9458 - val_acc: 0.5948\n",
      "Epoch 1024/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8973 - acc: 0.6101 - val_loss: 3.9474 - val_acc: 0.5929\n",
      "Epoch 1025/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8982 - acc: 0.6101 - val_loss: 3.9456 - val_acc: 0.5961\n",
      "Epoch 1026/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8988 - acc: 0.6083 - val_loss: 3.9463 - val_acc: 0.5938\n",
      "Epoch 1027/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8987 - acc: 0.6075 - val_loss: 3.9470 - val_acc: 0.5989\n",
      "Epoch 1028/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8983 - acc: 0.6106 - val_loss: 3.9463 - val_acc: 0.5961\n",
      "Epoch 1029/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8974 - acc: 0.6108 - val_loss: 3.9464 - val_acc: 0.5925\n",
      "Epoch 1030/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8986 - acc: 0.6102 - val_loss: 3.9542 - val_acc: 0.5814\n",
      "Epoch 1031/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8977 - acc: 0.6104 - val_loss: 3.9485 - val_acc: 0.5929\n",
      "Epoch 1032/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8980 - acc: 0.6076 - val_loss: 3.9471 - val_acc: 0.5998\n",
      "Epoch 1033/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8955 - acc: 0.6127 - val_loss: 3.9619 - val_acc: 0.5883\n",
      "Epoch 1034/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8970 - acc: 0.6101 - val_loss: 3.9462 - val_acc: 0.5961\n",
      "Epoch 1035/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8965 - acc: 0.6109 - val_loss: 3.9621 - val_acc: 0.5759\n",
      "Epoch 1036/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8978 - acc: 0.6084 - val_loss: 3.9476 - val_acc: 0.5994\n",
      "Epoch 1037/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8986 - acc: 0.6080 - val_loss: 3.9456 - val_acc: 0.5980\n",
      "Epoch 1038/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8975 - acc: 0.6086 - val_loss: 3.9487 - val_acc: 0.5938\n",
      "Epoch 1039/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8992 - acc: 0.6072 - val_loss: 3.9486 - val_acc: 0.6049\n",
      "Epoch 1040/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8977 - acc: 0.6083 - val_loss: 3.9460 - val_acc: 0.6021\n",
      "Epoch 1041/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8992 - acc: 0.6081 - val_loss: 3.9491 - val_acc: 0.5925\n",
      "Epoch 1042/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8976 - acc: 0.6111 - val_loss: 3.9487 - val_acc: 0.6007\n",
      "Epoch 1043/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.8985 - acc: 0.6096 - val_loss: 3.9468 - val_acc: 0.5980\n",
      "Epoch 1044/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8972 - acc: 0.6118 - val_loss: 3.9493 - val_acc: 0.5915\n",
      "Epoch 1045/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8975 - acc: 0.6086 - val_loss: 3.9585 - val_acc: 0.5925\n",
      "Epoch 1046/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8977 - acc: 0.6103 - val_loss: 3.9465 - val_acc: 0.5971\n",
      "Epoch 1047/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8978 - acc: 0.6094 - val_loss: 3.9615 - val_acc: 0.5902\n",
      "Epoch 1048/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8976 - acc: 0.6104 - val_loss: 3.9472 - val_acc: 0.5989\n",
      "Epoch 1049/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.8977 - acc: 0.6100 - val_loss: 3.9459 - val_acc: 0.5994\n",
      "Epoch 1050/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8984 - acc: 0.6091 - val_loss: 3.9482 - val_acc: 0.5952\n",
      "Epoch 1051/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8982 - acc: 0.6113 - val_loss: 3.9503 - val_acc: 0.5998\n",
      "Epoch 1052/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.8978 - acc: 0.6104 - val_loss: 3.9494 - val_acc: 0.6040\n",
      "Epoch 1053/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.8960 - acc: 0.6129 - val_loss: 3.9459 - val_acc: 0.5971\n",
      "Epoch 1054/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8968 - acc: 0.6109 - val_loss: 3.9458 - val_acc: 0.6003\n",
      "Epoch 1055/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8974 - acc: 0.6069 - val_loss: 3.9479 - val_acc: 0.5984\n",
      "Epoch 1056/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8984 - acc: 0.6078 - val_loss: 3.9497 - val_acc: 0.6040\n",
      "Epoch 1057/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8978 - acc: 0.6111 - val_loss: 3.9465 - val_acc: 0.5925\n",
      "Epoch 1058/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8969 - acc: 0.6118 - val_loss: 3.9459 - val_acc: 0.5971\n",
      "Epoch 1059/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8982 - acc: 0.6087 - val_loss: 3.9470 - val_acc: 0.5975\n",
      "Epoch 1060/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8983 - acc: 0.6116 - val_loss: 3.9464 - val_acc: 0.5998\n",
      "Epoch 1061/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8970 - acc: 0.6085 - val_loss: 3.9467 - val_acc: 0.6003\n",
      "Epoch 1062/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8974 - acc: 0.6104 - val_loss: 3.9460 - val_acc: 0.5966\n",
      "Epoch 1063/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8984 - acc: 0.6085 - val_loss: 3.9453 - val_acc: 0.5957\n",
      "Epoch 1064/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8980 - acc: 0.6088 - val_loss: 3.9464 - val_acc: 0.5952\n",
      "Epoch 1065/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8969 - acc: 0.6109 - val_loss: 3.9492 - val_acc: 0.6017\n",
      "Epoch 1066/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8961 - acc: 0.6118 - val_loss: 3.9491 - val_acc: 0.6049\n",
      "Epoch 1067/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8964 - acc: 0.6103 - val_loss: 3.9461 - val_acc: 0.5998\n",
      "Epoch 1068/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8980 - acc: 0.6104 - val_loss: 3.9510 - val_acc: 0.5911\n",
      "Epoch 1069/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8978 - acc: 0.6091 - val_loss: 3.9467 - val_acc: 0.5957\n",
      "Epoch 1070/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8970 - acc: 0.6103 - val_loss: 3.9470 - val_acc: 0.5994\n",
      "Epoch 1071/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8974 - acc: 0.6106 - val_loss: 3.9499 - val_acc: 0.5915\n",
      "Epoch 1072/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8976 - acc: 0.6096 - val_loss: 3.9510 - val_acc: 0.5915\n",
      "Epoch 1073/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8988 - acc: 0.6107 - val_loss: 3.9480 - val_acc: 0.6040\n",
      "Epoch 1074/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8985 - acc: 0.6094 - val_loss: 3.9477 - val_acc: 0.6017\n",
      "Epoch 1075/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8980 - acc: 0.6111 - val_loss: 3.9458 - val_acc: 0.5984\n",
      "Epoch 1076/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8984 - acc: 0.6080 - val_loss: 3.9485 - val_acc: 0.6017\n",
      "Epoch 1077/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8978 - acc: 0.6090 - val_loss: 3.9466 - val_acc: 0.5984\n",
      "Epoch 1078/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8971 - acc: 0.6083 - val_loss: 3.9468 - val_acc: 0.5989\n",
      "Epoch 1079/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8989 - acc: 0.6109 - val_loss: 3.9533 - val_acc: 0.5902\n",
      "Epoch 1080/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8968 - acc: 0.6116 - val_loss: 3.9473 - val_acc: 0.5920\n",
      "Epoch 1081/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8971 - acc: 0.6106 - val_loss: 3.9469 - val_acc: 0.5994\n",
      "Epoch 1082/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8961 - acc: 0.6092 - val_loss: 3.9496 - val_acc: 0.5892\n",
      "Epoch 1083/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8972 - acc: 0.6116 - val_loss: 3.9466 - val_acc: 0.5989\n",
      "Epoch 1084/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8970 - acc: 0.6126 - val_loss: 3.9562 - val_acc: 0.5805\n",
      "Epoch 1085/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8976 - acc: 0.6122 - val_loss: 3.9466 - val_acc: 0.5929\n",
      "Epoch 1086/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8964 - acc: 0.6102 - val_loss: 3.9472 - val_acc: 0.5971\n",
      "Epoch 1087/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8970 - acc: 0.6119 - val_loss: 3.9475 - val_acc: 0.5984\n",
      "Epoch 1088/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8971 - acc: 0.6115 - val_loss: 3.9466 - val_acc: 0.5971\n",
      "Epoch 1089/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8975 - acc: 0.6106 - val_loss: 3.9478 - val_acc: 0.5938\n",
      "Epoch 1090/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8971 - acc: 0.6144 - val_loss: 3.9480 - val_acc: 0.5998\n",
      "Epoch 1091/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8970 - acc: 0.6107 - val_loss: 3.9462 - val_acc: 0.5971\n",
      "Epoch 1092/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8967 - acc: 0.6117 - val_loss: 3.9469 - val_acc: 0.5943\n",
      "Epoch 1093/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8979 - acc: 0.6091 - val_loss: 3.9465 - val_acc: 0.5957\n",
      "Epoch 1094/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8968 - acc: 0.6081 - val_loss: 3.9537 - val_acc: 0.6003\n",
      "Epoch 1095/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8966 - acc: 0.6090 - val_loss: 3.9469 - val_acc: 0.5925\n",
      "Epoch 1096/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8977 - acc: 0.6095 - val_loss: 3.9463 - val_acc: 0.5980\n",
      "Epoch 1097/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8971 - acc: 0.6106 - val_loss: 3.9467 - val_acc: 0.5929\n",
      "Epoch 1098/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8972 - acc: 0.6110 - val_loss: 3.9477 - val_acc: 0.5934\n",
      "Epoch 1099/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8972 - acc: 0.6121 - val_loss: 3.9511 - val_acc: 0.6035\n",
      "Epoch 1100/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8973 - acc: 0.6115 - val_loss: 3.9477 - val_acc: 0.5975\n",
      "Epoch 1101/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8986 - acc: 0.6101 - val_loss: 3.9470 - val_acc: 0.5998\n",
      "Epoch 1102/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8958 - acc: 0.6104 - val_loss: 3.9479 - val_acc: 0.5911\n",
      "Epoch 1103/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8985 - acc: 0.6075 - val_loss: 3.9461 - val_acc: 0.5971\n",
      "Epoch 1104/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8982 - acc: 0.6087 - val_loss: 3.9469 - val_acc: 0.5975\n",
      "Epoch 1105/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8965 - acc: 0.6134 - val_loss: 3.9492 - val_acc: 0.6044\n",
      "Epoch 1106/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8972 - acc: 0.6113 - val_loss: 3.9483 - val_acc: 0.6030\n",
      "Epoch 1107/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8973 - acc: 0.6122 - val_loss: 3.9466 - val_acc: 0.5943\n",
      "Epoch 1108/5000\n",
      "8692/8692 [==============================] - 1s 84us/step - loss: 3.8977 - acc: 0.6110 - val_loss: 3.9463 - val_acc: 0.5980\n",
      "Epoch 1109/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8964 - acc: 0.6088 - val_loss: 3.9478 - val_acc: 0.5897\n",
      "Epoch 1110/5000\n",
      "8692/8692 [==============================] - 1s 80us/step - loss: 3.8965 - acc: 0.6109 - val_loss: 3.9471 - val_acc: 0.5934\n",
      "Epoch 1111/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8977 - acc: 0.6115 - val_loss: 3.9474 - val_acc: 0.6007\n",
      "Epoch 1112/5000\n",
      "8692/8692 [==============================] - 1s 77us/step - loss: 3.8976 - acc: 0.6123 - val_loss: 3.9477 - val_acc: 0.6026\n",
      "Epoch 1113/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8963 - acc: 0.6124 - val_loss: 3.9480 - val_acc: 0.5915\n",
      "Epoch 1114/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8978 - acc: 0.6081 - val_loss: 3.9465 - val_acc: 0.5994\n",
      "Epoch 1115/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8972 - acc: 0.6121 - val_loss: 3.9465 - val_acc: 0.5966\n",
      "Epoch 1116/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8978 - acc: 0.6099 - val_loss: 3.9491 - val_acc: 0.5929\n",
      "Epoch 1117/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8978 - acc: 0.6123 - val_loss: 3.9469 - val_acc: 0.5943\n",
      "Epoch 1118/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8960 - acc: 0.6130 - val_loss: 3.9470 - val_acc: 0.5966\n",
      "Epoch 1119/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8970 - acc: 0.6127 - val_loss: 3.9578 - val_acc: 0.5823\n",
      "Epoch 1120/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8977 - acc: 0.6100 - val_loss: 3.9488 - val_acc: 0.5929\n",
      "Epoch 1121/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8984 - acc: 0.6103 - val_loss: 3.9467 - val_acc: 0.5952\n",
      "Epoch 1122/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8973 - acc: 0.6113 - val_loss: 3.9467 - val_acc: 0.5971\n",
      "Epoch 1123/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8980 - acc: 0.6130 - val_loss: 3.9541 - val_acc: 0.5980\n",
      "Epoch 1124/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.8976 - acc: 0.6077 - val_loss: 3.9467 - val_acc: 0.5971\n",
      "Epoch 1125/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8978 - acc: 0.6102 - val_loss: 3.9523 - val_acc: 0.5869\n",
      "Epoch 1126/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8963 - acc: 0.6109 - val_loss: 3.9468 - val_acc: 0.5943\n",
      "Epoch 1127/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8976 - acc: 0.6078 - val_loss: 3.9469 - val_acc: 0.5961\n",
      "Epoch 1128/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8970 - acc: 0.6110 - val_loss: 3.9515 - val_acc: 0.5879\n",
      "Epoch 1129/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8969 - acc: 0.6119 - val_loss: 3.9467 - val_acc: 0.5984\n",
      "Epoch 1130/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8965 - acc: 0.6102 - val_loss: 3.9468 - val_acc: 0.5966\n",
      "Epoch 1131/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8984 - acc: 0.6092 - val_loss: 3.9469 - val_acc: 0.6003\n",
      "Epoch 1132/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8959 - acc: 0.6115 - val_loss: 3.9493 - val_acc: 0.5920\n",
      "Epoch 1133/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8983 - acc: 0.6079 - val_loss: 3.9482 - val_acc: 0.6007\n",
      "Epoch 1134/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8982 - acc: 0.6117 - val_loss: 3.9471 - val_acc: 0.6003\n",
      "Epoch 1135/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8964 - acc: 0.6096 - val_loss: 3.9501 - val_acc: 0.5915\n",
      "Epoch 1136/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8975 - acc: 0.6101 - val_loss: 3.9472 - val_acc: 0.6003\n",
      "Epoch 1137/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8978 - acc: 0.6111 - val_loss: 3.9611 - val_acc: 0.5805\n",
      "Epoch 1138/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8988 - acc: 0.6077 - val_loss: 3.9486 - val_acc: 0.5938\n",
      "Epoch 1139/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8974 - acc: 0.6096 - val_loss: 3.9514 - val_acc: 0.5906\n",
      "Epoch 1140/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8979 - acc: 0.6085 - val_loss: 3.9475 - val_acc: 0.5998\n",
      "Epoch 1141/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8965 - acc: 0.6111 - val_loss: 3.9485 - val_acc: 0.5938\n",
      "Epoch 1142/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8976 - acc: 0.6110 - val_loss: 3.9486 - val_acc: 0.5966\n",
      "Epoch 1143/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8979 - acc: 0.6115 - val_loss: 3.9472 - val_acc: 0.5980\n",
      "Epoch 1144/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8964 - acc: 0.6096 - val_loss: 3.9532 - val_acc: 0.5998\n",
      "Epoch 1145/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8976 - acc: 0.6077 - val_loss: 3.9472 - val_acc: 0.5929\n",
      "Epoch 1146/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8964 - acc: 0.6087 - val_loss: 3.9551 - val_acc: 0.5842\n",
      "Epoch 1147/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8965 - acc: 0.6102 - val_loss: 3.9514 - val_acc: 0.5998\n",
      "Epoch 1148/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8963 - acc: 0.6122 - val_loss: 3.9495 - val_acc: 0.6035\n",
      "Epoch 1149/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8977 - acc: 0.6096 - val_loss: 3.9458 - val_acc: 0.5994\n",
      "Epoch 1150/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8962 - acc: 0.6137 - val_loss: 3.9487 - val_acc: 0.5975\n",
      "Epoch 1151/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.9010 - acc: 0.6035 - val_loss: 3.9487 - val_acc: 0.5929\n",
      "Epoch 1152/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8966 - acc: 0.6095 - val_loss: 3.9465 - val_acc: 0.5957\n",
      "Epoch 1153/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8962 - acc: 0.6124 - val_loss: 3.9488 - val_acc: 0.6026\n",
      "Epoch 1154/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8965 - acc: 0.6123 - val_loss: 3.9460 - val_acc: 0.5975\n",
      "Epoch 1155/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8963 - acc: 0.6098 - val_loss: 3.9463 - val_acc: 0.5929\n",
      "Epoch 1156/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.8975 - acc: 0.6107 - val_loss: 3.9502 - val_acc: 0.5994\n",
      "Epoch 1157/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8959 - acc: 0.6122 - val_loss: 3.9546 - val_acc: 0.5856\n",
      "Epoch 1158/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8970 - acc: 0.6111 - val_loss: 3.9475 - val_acc: 0.5984\n",
      "Epoch 1159/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8967 - acc: 0.6113 - val_loss: 3.9484 - val_acc: 0.5948\n",
      "Epoch 1160/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8966 - acc: 0.6116 - val_loss: 3.9468 - val_acc: 0.5984\n",
      "Epoch 1161/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8965 - acc: 0.6075 - val_loss: 3.9486 - val_acc: 0.5915\n",
      "Epoch 1162/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8969 - acc: 0.6109 - val_loss: 3.9469 - val_acc: 0.6012\n",
      "Epoch 1163/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8977 - acc: 0.6103 - val_loss: 3.9467 - val_acc: 0.5975\n",
      "Epoch 1164/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8968 - acc: 0.6104 - val_loss: 3.9515 - val_acc: 0.5892\n",
      "Epoch 1165/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8972 - acc: 0.6111 - val_loss: 3.9476 - val_acc: 0.5971\n",
      "Epoch 1166/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8973 - acc: 0.6107 - val_loss: 3.9472 - val_acc: 0.5975\n",
      "Epoch 1167/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8975 - acc: 0.6099 - val_loss: 3.9478 - val_acc: 0.5994\n",
      "Epoch 1168/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8961 - acc: 0.6096 - val_loss: 3.9468 - val_acc: 0.5975\n",
      "Epoch 1169/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8956 - acc: 0.6108 - val_loss: 3.9528 - val_acc: 0.5851\n",
      "Epoch 1170/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8986 - acc: 0.6073 - val_loss: 3.9475 - val_acc: 0.5975\n",
      "Epoch 1171/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8967 - acc: 0.6094 - val_loss: 3.9488 - val_acc: 0.6007\n",
      "Epoch 1172/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8969 - acc: 0.6114 - val_loss: 3.9475 - val_acc: 0.5966\n",
      "Epoch 1173/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8953 - acc: 0.6160 - val_loss: 3.9470 - val_acc: 0.5938\n",
      "Epoch 1174/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8965 - acc: 0.6118 - val_loss: 3.9470 - val_acc: 0.5989\n",
      "Epoch 1175/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8970 - acc: 0.6126 - val_loss: 3.9471 - val_acc: 0.5948\n",
      "Epoch 1176/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8976 - acc: 0.6109 - val_loss: 3.9470 - val_acc: 0.5971\n",
      "Epoch 1177/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8968 - acc: 0.6107 - val_loss: 3.9481 - val_acc: 0.5966\n",
      "Epoch 1178/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8962 - acc: 0.6103 - val_loss: 3.9512 - val_acc: 0.5925\n",
      "Epoch 1179/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8970 - acc: 0.6123 - val_loss: 3.9515 - val_acc: 0.6012\n",
      "Epoch 1180/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8961 - acc: 0.6126 - val_loss: 3.9501 - val_acc: 0.6049\n",
      "Epoch 1181/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8977 - acc: 0.6102 - val_loss: 3.9465 - val_acc: 0.5975\n",
      "Epoch 1182/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8972 - acc: 0.6103 - val_loss: 3.9495 - val_acc: 0.6030\n",
      "Epoch 1183/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8965 - acc: 0.6098 - val_loss: 3.9506 - val_acc: 0.5934\n",
      "Epoch 1184/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8962 - acc: 0.6121 - val_loss: 3.9471 - val_acc: 0.5952\n",
      "Epoch 1185/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8970 - acc: 0.6101 - val_loss: 3.9550 - val_acc: 0.5994\n",
      "Epoch 1186/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8976 - acc: 0.6094 - val_loss: 3.9468 - val_acc: 0.5984\n",
      "Epoch 1187/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8969 - acc: 0.6103 - val_loss: 3.9488 - val_acc: 0.5948\n",
      "Epoch 1188/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8960 - acc: 0.6111 - val_loss: 3.9480 - val_acc: 0.5934\n",
      "Epoch 1189/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8964 - acc: 0.6094 - val_loss: 3.9483 - val_acc: 0.5948\n",
      "Epoch 1190/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8964 - acc: 0.6115 - val_loss: 3.9471 - val_acc: 0.5938\n",
      "Epoch 1191/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8974 - acc: 0.6142 - val_loss: 3.9464 - val_acc: 0.5971\n",
      "Epoch 1192/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8960 - acc: 0.6115 - val_loss: 3.9479 - val_acc: 0.5948\n",
      "Epoch 1193/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8974 - acc: 0.6111 - val_loss: 3.9479 - val_acc: 0.5984\n",
      "Epoch 1194/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8986 - acc: 0.6101 - val_loss: 3.9470 - val_acc: 0.5952\n",
      "Epoch 1195/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8980 - acc: 0.6123 - val_loss: 3.9505 - val_acc: 0.6035\n",
      "Epoch 1196/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8971 - acc: 0.6108 - val_loss: 3.9463 - val_acc: 0.5966\n",
      "Epoch 1197/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8973 - acc: 0.6115 - val_loss: 3.9532 - val_acc: 0.5975\n",
      "Epoch 1198/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8969 - acc: 0.6125 - val_loss: 3.9487 - val_acc: 0.5971\n",
      "Epoch 1199/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8971 - acc: 0.6123 - val_loss: 3.9469 - val_acc: 0.5952\n",
      "Epoch 1200/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8960 - acc: 0.6104 - val_loss: 3.9614 - val_acc: 0.5948\n",
      "Epoch 1201/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8970 - acc: 0.6101 - val_loss: 3.9515 - val_acc: 0.6040\n",
      "Epoch 1202/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8983 - acc: 0.6095 - val_loss: 3.9472 - val_acc: 0.5984\n",
      "Epoch 1203/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8974 - acc: 0.6095 - val_loss: 3.9562 - val_acc: 0.5805\n",
      "Epoch 1204/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8974 - acc: 0.6136 - val_loss: 3.9491 - val_acc: 0.5892\n",
      "Epoch 1205/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8968 - acc: 0.6092 - val_loss: 3.9478 - val_acc: 0.6007\n",
      "Epoch 1206/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8982 - acc: 0.6084 - val_loss: 3.9466 - val_acc: 0.5961\n",
      "Epoch 1207/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8974 - acc: 0.6124 - val_loss: 3.9512 - val_acc: 0.5994\n",
      "Epoch 1208/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8972 - acc: 0.6115 - val_loss: 3.9465 - val_acc: 0.5938\n",
      "Epoch 1209/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8965 - acc: 0.6122 - val_loss: 3.9475 - val_acc: 0.5934\n",
      "Epoch 1210/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8962 - acc: 0.6131 - val_loss: 3.9470 - val_acc: 0.5948\n",
      "Epoch 1211/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8972 - acc: 0.6106 - val_loss: 3.9484 - val_acc: 0.5966\n",
      "Epoch 1212/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8968 - acc: 0.6099 - val_loss: 3.9482 - val_acc: 0.5925\n",
      "Epoch 1213/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8965 - acc: 0.6115 - val_loss: 3.9468 - val_acc: 0.5994\n",
      "Epoch 1214/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8967 - acc: 0.6101 - val_loss: 3.9479 - val_acc: 0.6007\n",
      "Epoch 1215/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8975 - acc: 0.6095 - val_loss: 3.9467 - val_acc: 0.5975\n",
      "Epoch 1216/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8962 - acc: 0.6101 - val_loss: 3.9499 - val_acc: 0.5934\n",
      "Epoch 1217/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8977 - acc: 0.6117 - val_loss: 3.9469 - val_acc: 0.5934\n",
      "Epoch 1218/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8954 - acc: 0.6125 - val_loss: 3.9471 - val_acc: 0.5952\n",
      "Epoch 1219/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8982 - acc: 0.6113 - val_loss: 3.9468 - val_acc: 0.5971\n",
      "Epoch 1220/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8975 - acc: 0.6133 - val_loss: 3.9487 - val_acc: 0.6003\n",
      "Epoch 1221/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8967 - acc: 0.6122 - val_loss: 3.9468 - val_acc: 0.5925\n",
      "Epoch 1222/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8974 - acc: 0.6100 - val_loss: 3.9511 - val_acc: 0.5929\n",
      "Epoch 1223/5000\n",
      "8692/8692 [==============================] - 1s 92us/step - loss: 3.8966 - acc: 0.6101 - val_loss: 3.9492 - val_acc: 0.6035\n",
      "Epoch 1224/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8959 - acc: 0.6126 - val_loss: 3.9496 - val_acc: 0.6026\n",
      "Epoch 1225/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8956 - acc: 0.6132 - val_loss: 3.9484 - val_acc: 0.5948\n",
      "Epoch 1226/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8963 - acc: 0.6092 - val_loss: 3.9475 - val_acc: 0.5934\n",
      "Epoch 1227/5000\n",
      "8692/8692 [==============================] - 1s 77us/step - loss: 3.8969 - acc: 0.6113 - val_loss: 3.9484 - val_acc: 0.5948\n",
      "Epoch 1228/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8965 - acc: 0.6103 - val_loss: 3.9477 - val_acc: 0.6007\n",
      "Epoch 1229/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8974 - acc: 0.6102 - val_loss: 3.9511 - val_acc: 0.5906\n",
      "Epoch 1230/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8958 - acc: 0.6113 - val_loss: 3.9478 - val_acc: 0.5980\n",
      "Epoch 1231/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8972 - acc: 0.6118 - val_loss: 3.9481 - val_acc: 0.5989\n",
      "Epoch 1232/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8965 - acc: 0.6102 - val_loss: 3.9486 - val_acc: 0.5938\n",
      "Epoch 1233/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8969 - acc: 0.6144 - val_loss: 3.9494 - val_acc: 0.5925\n",
      "Epoch 1234/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8964 - acc: 0.6101 - val_loss: 3.9476 - val_acc: 0.5957\n",
      "Epoch 1235/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8953 - acc: 0.6134 - val_loss: 3.9513 - val_acc: 0.6007\n",
      "Epoch 1236/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8964 - acc: 0.6093 - val_loss: 3.9515 - val_acc: 0.5888\n",
      "Epoch 1237/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8961 - acc: 0.6114 - val_loss: 3.9469 - val_acc: 0.5975\n",
      "Epoch 1238/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8962 - acc: 0.6140 - val_loss: 3.9468 - val_acc: 0.5980\n",
      "Epoch 1239/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.8990 - acc: 0.6104 - val_loss: 3.9476 - val_acc: 0.5975\n",
      "Epoch 1240/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8974 - acc: 0.6110 - val_loss: 3.9545 - val_acc: 0.5869\n",
      "Epoch 1241/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.8959 - acc: 0.6099 - val_loss: 3.9473 - val_acc: 0.5929\n",
      "Epoch 1242/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8966 - acc: 0.6109 - val_loss: 3.9477 - val_acc: 0.5994\n",
      "Epoch 1243/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.8961 - acc: 0.6123 - val_loss: 3.9471 - val_acc: 0.5929\n",
      "Epoch 1244/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8966 - acc: 0.6136 - val_loss: 3.9475 - val_acc: 0.5975\n",
      "Epoch 1245/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.8963 - acc: 0.6141 - val_loss: 3.9491 - val_acc: 0.5920\n",
      "Epoch 1246/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8957 - acc: 0.6134 - val_loss: 3.9494 - val_acc: 0.6017\n",
      "Epoch 1247/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8965 - acc: 0.6106 - val_loss: 3.9488 - val_acc: 0.6007\n",
      "Epoch 1248/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8953 - acc: 0.6118 - val_loss: 3.9472 - val_acc: 0.5975\n",
      "Epoch 1249/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.8971 - acc: 0.6115 - val_loss: 3.9502 - val_acc: 0.6040\n",
      "Epoch 1250/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8975 - acc: 0.6118 - val_loss: 3.9485 - val_acc: 0.5994\n",
      "Epoch 1251/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8968 - acc: 0.6126 - val_loss: 3.9478 - val_acc: 0.5980\n",
      "Epoch 1252/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8969 - acc: 0.6107 - val_loss: 3.9480 - val_acc: 0.5948\n",
      "Epoch 1253/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8967 - acc: 0.6088 - val_loss: 3.9471 - val_acc: 0.5952\n",
      "Epoch 1254/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8963 - acc: 0.6127 - val_loss: 3.9475 - val_acc: 0.6003\n",
      "Epoch 1255/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8953 - acc: 0.6152 - val_loss: 3.9505 - val_acc: 0.5911\n",
      "Epoch 1256/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8958 - acc: 0.6126 - val_loss: 3.9518 - val_acc: 0.6030\n",
      "Epoch 1257/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8973 - acc: 0.6106 - val_loss: 3.9498 - val_acc: 0.5948\n",
      "Epoch 1258/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8972 - acc: 0.6111 - val_loss: 3.9472 - val_acc: 0.5971\n",
      "Epoch 1259/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8970 - acc: 0.6104 - val_loss: 3.9472 - val_acc: 0.5948\n",
      "Epoch 1260/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8972 - acc: 0.6116 - val_loss: 3.9474 - val_acc: 0.5952\n",
      "Epoch 1261/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8964 - acc: 0.6096 - val_loss: 3.9512 - val_acc: 0.5883\n",
      "Epoch 1262/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8962 - acc: 0.6110 - val_loss: 3.9467 - val_acc: 0.5994\n",
      "Epoch 1263/5000\n",
      "8692/8692 [==============================] - 1s 93us/step - loss: 3.8971 - acc: 0.6121 - val_loss: 3.9522 - val_acc: 0.5902\n",
      "Epoch 1264/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8969 - acc: 0.6121 - val_loss: 3.9610 - val_acc: 0.5768\n",
      "Epoch 1265/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8967 - acc: 0.6116 - val_loss: 3.9475 - val_acc: 0.5938\n",
      "Epoch 1266/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8966 - acc: 0.6109 - val_loss: 3.9478 - val_acc: 0.5948\n",
      "Epoch 1267/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8967 - acc: 0.6115 - val_loss: 3.9510 - val_acc: 0.5883\n",
      "Epoch 1268/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8975 - acc: 0.6093 - val_loss: 3.9616 - val_acc: 0.5741\n",
      "Epoch 1269/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8967 - acc: 0.6119 - val_loss: 3.9488 - val_acc: 0.5984\n",
      "Epoch 1270/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8961 - acc: 0.6090 - val_loss: 3.9472 - val_acc: 0.5934\n",
      "Epoch 1271/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8959 - acc: 0.6102 - val_loss: 3.9499 - val_acc: 0.6035\n",
      "Epoch 1272/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8968 - acc: 0.6131 - val_loss: 3.9470 - val_acc: 0.5952\n",
      "Epoch 1273/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 3.8966 - acc: 0.6094 - val_loss: 3.9465 - val_acc: 0.5961\n",
      "Epoch 1274/5000\n",
      "8692/8692 [==============================] - 1s 103us/step - loss: 3.8968 - acc: 0.6113 - val_loss: 3.9479 - val_acc: 0.5961\n",
      "Epoch 1275/5000\n",
      "8692/8692 [==============================] - 1s 113us/step - loss: 3.8969 - acc: 0.6107 - val_loss: 3.9640 - val_acc: 0.5731\n",
      "Epoch 1276/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8968 - acc: 0.6116 - val_loss: 3.9505 - val_acc: 0.5929\n",
      "Epoch 1277/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8961 - acc: 0.6107 - val_loss: 3.9470 - val_acc: 0.5957\n",
      "Epoch 1278/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8958 - acc: 0.6108 - val_loss: 3.9472 - val_acc: 0.5961\n",
      "Epoch 1279/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8964 - acc: 0.6093 - val_loss: 3.9500 - val_acc: 0.6021\n",
      "Epoch 1280/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8958 - acc: 0.6132 - val_loss: 3.9472 - val_acc: 0.5994\n",
      "Epoch 1281/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.8959 - acc: 0.6144 - val_loss: 3.9496 - val_acc: 0.5938\n",
      "Epoch 1282/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8964 - acc: 0.6137 - val_loss: 3.9523 - val_acc: 0.5874\n",
      "Epoch 1283/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8993 - acc: 0.6090 - val_loss: 3.9509 - val_acc: 0.5929\n",
      "Epoch 1284/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8963 - acc: 0.6100 - val_loss: 3.9535 - val_acc: 0.5957\n",
      "Epoch 1285/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8965 - acc: 0.6087 - val_loss: 3.9459 - val_acc: 0.5975\n",
      "Epoch 1286/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.8965 - acc: 0.6104 - val_loss: 3.9507 - val_acc: 0.6007\n",
      "Epoch 1287/5000\n",
      "8692/8692 [==============================] - 1s 83us/step - loss: 3.8970 - acc: 0.6118 - val_loss: 3.9658 - val_acc: 0.5764\n",
      "Epoch 1288/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8965 - acc: 0.6093 - val_loss: 3.9526 - val_acc: 0.5911\n",
      "Epoch 1289/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8970 - acc: 0.6117 - val_loss: 3.9515 - val_acc: 0.5897\n",
      "Epoch 1290/5000\n",
      "8692/8692 [==============================] - 1s 75us/step - loss: 3.8967 - acc: 0.6115 - val_loss: 3.9472 - val_acc: 0.6003\n",
      "Epoch 1291/5000\n",
      "8692/8692 [==============================] - 1s 73us/step - loss: 3.8960 - acc: 0.6096 - val_loss: 3.9479 - val_acc: 0.5966\n",
      "Epoch 1292/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8958 - acc: 0.6129 - val_loss: 3.9471 - val_acc: 0.5938\n",
      "Epoch 1293/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.8966 - acc: 0.6093 - val_loss: 3.9534 - val_acc: 0.5879\n",
      "Epoch 1294/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8960 - acc: 0.6103 - val_loss: 3.9469 - val_acc: 0.5980\n",
      "Epoch 1295/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8965 - acc: 0.6095 - val_loss: 3.9474 - val_acc: 0.5943\n",
      "Epoch 1296/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8961 - acc: 0.6108 - val_loss: 3.9478 - val_acc: 0.5948\n",
      "Epoch 1297/5000\n",
      "8692/8692 [==============================] - 1s 85us/step - loss: 3.8956 - acc: 0.6114 - val_loss: 3.9476 - val_acc: 0.5975\n",
      "Epoch 1298/5000\n",
      "8692/8692 [==============================] - 1s 80us/step - loss: 3.8967 - acc: 0.6095 - val_loss: 3.9489 - val_acc: 0.5994\n",
      "Epoch 1299/5000\n",
      "8692/8692 [==============================] - 1s 86us/step - loss: 3.8961 - acc: 0.6118 - val_loss: 3.9472 - val_acc: 0.5943\n",
      "Epoch 1300/5000\n",
      "8692/8692 [==============================] - 1s 90us/step - loss: 3.8960 - acc: 0.6113 - val_loss: 3.9462 - val_acc: 0.5957\n",
      "Epoch 1301/5000\n",
      "8692/8692 [==============================] - 1s 81us/step - loss: 3.8969 - acc: 0.6077 - val_loss: 3.9493 - val_acc: 0.5934\n",
      "Epoch 1302/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.8964 - acc: 0.6111 - val_loss: 3.9547 - val_acc: 0.5869\n",
      "Epoch 1303/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.8971 - acc: 0.6071 - val_loss: 3.9473 - val_acc: 0.5948\n",
      "Epoch 1304/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.8954 - acc: 0.6131 - val_loss: 3.9464 - val_acc: 0.5971\n",
      "Epoch 1305/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.8951 - acc: 0.6142 - val_loss: 3.9547 - val_acc: 0.5869\n",
      "Epoch 1306/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8957 - acc: 0.6072 - val_loss: 3.9484 - val_acc: 0.5938\n",
      "Epoch 1307/5000\n",
      "8692/8692 [==============================] - 1s 73us/step - loss: 3.8964 - acc: 0.6102 - val_loss: 3.9532 - val_acc: 0.6007\n",
      "Epoch 1308/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 3.8955 - acc: 0.6107 - val_loss: 3.9532 - val_acc: 0.5902\n",
      "Epoch 1309/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8945 - acc: 0.6122 - val_loss: 3.9560 - val_acc: 0.5846\n",
      "Epoch 1310/5000\n",
      "8692/8692 [==============================] - 1s 80us/step - loss: 3.8960 - acc: 0.6106 - val_loss: 3.9474 - val_acc: 0.5984\n",
      "Epoch 1311/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.8958 - acc: 0.6138 - val_loss: 3.9463 - val_acc: 0.5980\n",
      "Epoch 1312/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8964 - acc: 0.6133 - val_loss: 3.9475 - val_acc: 0.5938\n",
      "Epoch 1313/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8951 - acc: 0.6134 - val_loss: 3.9472 - val_acc: 0.5961\n",
      "Epoch 1314/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8955 - acc: 0.6110 - val_loss: 3.9466 - val_acc: 0.5911\n",
      "Epoch 1315/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 3.8967 - acc: 0.6100 - val_loss: 3.9462 - val_acc: 0.5984\n",
      "Epoch 1316/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8961 - acc: 0.6141 - val_loss: 3.9474 - val_acc: 0.5943\n",
      "Epoch 1317/5000\n",
      "8692/8692 [==============================] - 1s 85us/step - loss: 3.8970 - acc: 0.6084 - val_loss: 3.9483 - val_acc: 0.5989\n",
      "Epoch 1318/5000\n",
      "8692/8692 [==============================] - 1s 96us/step - loss: 3.8950 - acc: 0.6111 - val_loss: 3.9465 - val_acc: 0.5989\n",
      "Epoch 1319/5000\n",
      "8692/8692 [==============================] - 1s 90us/step - loss: 3.8953 - acc: 0.6142 - val_loss: 3.9516 - val_acc: 0.5925\n",
      "Epoch 1320/5000\n",
      "8692/8692 [==============================] - 1s 97us/step - loss: 3.8956 - acc: 0.6115 - val_loss: 3.9491 - val_acc: 0.5943\n",
      "Epoch 1321/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8962 - acc: 0.6102 - val_loss: 3.9483 - val_acc: 0.5998\n",
      "Epoch 1322/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8965 - acc: 0.6109 - val_loss: 3.9464 - val_acc: 0.5966\n",
      "Epoch 1323/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8945 - acc: 0.6122 - val_loss: 3.9559 - val_acc: 0.5934\n",
      "Epoch 1324/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8950 - acc: 0.6133 - val_loss: 3.9465 - val_acc: 0.5966\n",
      "Epoch 1325/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8961 - acc: 0.6100 - val_loss: 3.9474 - val_acc: 0.5929\n",
      "Epoch 1326/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8961 - acc: 0.6117 - val_loss: 3.9528 - val_acc: 0.5892\n",
      "Epoch 1327/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8951 - acc: 0.6103 - val_loss: 3.9474 - val_acc: 0.5957\n",
      "Epoch 1328/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8955 - acc: 0.6126 - val_loss: 3.9489 - val_acc: 0.6053\n",
      "Epoch 1329/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8946 - acc: 0.6126 - val_loss: 3.9473 - val_acc: 0.5989\n",
      "Epoch 1330/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8965 - acc: 0.6100 - val_loss: 3.9500 - val_acc: 0.6021\n",
      "Epoch 1331/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8960 - acc: 0.6101 - val_loss: 3.9469 - val_acc: 0.6017\n",
      "Epoch 1332/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8956 - acc: 0.6115 - val_loss: 3.9553 - val_acc: 0.6003\n",
      "Epoch 1333/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8962 - acc: 0.6119 - val_loss: 3.9495 - val_acc: 0.6044\n",
      "Epoch 1334/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8956 - acc: 0.6129 - val_loss: 3.9463 - val_acc: 0.5957\n",
      "Epoch 1335/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8948 - acc: 0.6133 - val_loss: 3.9492 - val_acc: 0.6040\n",
      "Epoch 1336/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8956 - acc: 0.6123 - val_loss: 3.9475 - val_acc: 0.5984\n",
      "Epoch 1337/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8969 - acc: 0.6116 - val_loss: 3.9457 - val_acc: 0.5957\n",
      "Epoch 1338/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8965 - acc: 0.6103 - val_loss: 3.9468 - val_acc: 0.5952\n",
      "Epoch 1339/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8949 - acc: 0.6146 - val_loss: 3.9481 - val_acc: 0.5911\n",
      "Epoch 1340/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8961 - acc: 0.6133 - val_loss: 3.9463 - val_acc: 0.5980\n",
      "Epoch 1341/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8952 - acc: 0.6119 - val_loss: 3.9469 - val_acc: 0.5952\n",
      "Epoch 1342/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8950 - acc: 0.6113 - val_loss: 3.9473 - val_acc: 0.5980\n",
      "Epoch 1343/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8951 - acc: 0.6116 - val_loss: 3.9480 - val_acc: 0.5929\n",
      "Epoch 1344/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8953 - acc: 0.6109 - val_loss: 3.9461 - val_acc: 0.5957\n",
      "Epoch 1345/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8947 - acc: 0.6145 - val_loss: 3.9485 - val_acc: 0.5989\n",
      "Epoch 1346/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8957 - acc: 0.6126 - val_loss: 3.9522 - val_acc: 0.5897\n",
      "Epoch 1347/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8949 - acc: 0.6134 - val_loss: 3.9467 - val_acc: 0.5938\n",
      "Epoch 1348/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8952 - acc: 0.6126 - val_loss: 3.9457 - val_acc: 0.5975\n",
      "Epoch 1349/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8969 - acc: 0.6114 - val_loss: 3.9595 - val_acc: 0.5948\n",
      "Epoch 1350/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8962 - acc: 0.6113 - val_loss: 3.9466 - val_acc: 0.5994\n",
      "Epoch 1351/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8949 - acc: 0.6121 - val_loss: 3.9472 - val_acc: 0.5934\n",
      "Epoch 1352/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8952 - acc: 0.6104 - val_loss: 3.9470 - val_acc: 0.5929\n",
      "Epoch 1353/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8949 - acc: 0.6119 - val_loss: 3.9496 - val_acc: 0.5925\n",
      "Epoch 1354/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8956 - acc: 0.6108 - val_loss: 3.9465 - val_acc: 0.5975\n",
      "Epoch 1355/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8952 - acc: 0.6102 - val_loss: 3.9554 - val_acc: 0.5851\n",
      "Epoch 1356/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8953 - acc: 0.6106 - val_loss: 3.9498 - val_acc: 0.5961\n",
      "Epoch 1357/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8948 - acc: 0.6118 - val_loss: 3.9473 - val_acc: 0.5998\n",
      "Epoch 1358/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8943 - acc: 0.6126 - val_loss: 3.9484 - val_acc: 0.6035\n",
      "Epoch 1359/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8955 - acc: 0.6116 - val_loss: 3.9452 - val_acc: 0.5952\n",
      "Epoch 1360/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8943 - acc: 0.6138 - val_loss: 3.9487 - val_acc: 0.5998\n",
      "Epoch 1361/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8939 - acc: 0.6136 - val_loss: 3.9470 - val_acc: 0.5980\n",
      "Epoch 1362/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8959 - acc: 0.6100 - val_loss: 3.9487 - val_acc: 0.5957\n",
      "Epoch 1363/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 3.8944 - acc: 0.6141 - val_loss: 3.9486 - val_acc: 0.5980\n",
      "Epoch 1364/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8945 - acc: 0.6146 - val_loss: 3.9467 - val_acc: 0.5971\n",
      "Epoch 1365/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 3.8958 - acc: 0.6129 - val_loss: 3.9474 - val_acc: 0.5948\n",
      "Epoch 1366/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8942 - acc: 0.6119 - val_loss: 3.9461 - val_acc: 0.5966\n",
      "Epoch 1367/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8949 - acc: 0.6108 - val_loss: 3.9490 - val_acc: 0.6012\n",
      "Epoch 1368/5000\n",
      "8692/8692 [==============================] - 1s 86us/step - loss: 3.8956 - acc: 0.6116 - val_loss: 3.9453 - val_acc: 0.5961\n",
      "Epoch 1369/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8954 - acc: 0.6122 - val_loss: 3.9466 - val_acc: 0.5952\n",
      "Epoch 1370/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8944 - acc: 0.6123 - val_loss: 3.9452 - val_acc: 0.5989\n",
      "Epoch 1371/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8944 - acc: 0.6130 - val_loss: 3.9586 - val_acc: 0.5828\n",
      "Epoch 1372/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8950 - acc: 0.6130 - val_loss: 3.9455 - val_acc: 0.5998\n",
      "Epoch 1373/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8950 - acc: 0.6136 - val_loss: 3.9511 - val_acc: 0.5943\n",
      "Epoch 1374/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8932 - acc: 0.6146 - val_loss: 3.9511 - val_acc: 0.6026\n",
      "Epoch 1375/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8965 - acc: 0.6075 - val_loss: 3.9475 - val_acc: 0.5980\n",
      "Epoch 1376/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8954 - acc: 0.6108 - val_loss: 3.9461 - val_acc: 0.5952\n",
      "Epoch 1377/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 3.8935 - acc: 0.6127 - val_loss: 3.9458 - val_acc: 0.5975\n",
      "Epoch 1378/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8942 - acc: 0.6136 - val_loss: 3.9486 - val_acc: 0.6007\n",
      "Epoch 1379/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8947 - acc: 0.6117 - val_loss: 3.9473 - val_acc: 0.5975\n",
      "Epoch 1380/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8947 - acc: 0.6114 - val_loss: 3.9468 - val_acc: 0.5957\n",
      "Epoch 1381/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8940 - acc: 0.6137 - val_loss: 3.9467 - val_acc: 0.5934\n",
      "Epoch 1382/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8948 - acc: 0.6119 - val_loss: 3.9475 - val_acc: 0.5961\n",
      "Epoch 1383/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8950 - acc: 0.6130 - val_loss: 3.9483 - val_acc: 0.5994\n",
      "Epoch 1384/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8945 - acc: 0.6132 - val_loss: 3.9600 - val_acc: 0.5777\n",
      "Epoch 1385/5000\n",
      "8692/8692 [==============================] - 1s 73us/step - loss: 3.8938 - acc: 0.6141 - val_loss: 3.9466 - val_acc: 0.5943\n",
      "Epoch 1386/5000\n",
      "8692/8692 [==============================] - 1s 77us/step - loss: 3.8943 - acc: 0.6146 - val_loss: 3.9464 - val_acc: 0.5975\n",
      "Epoch 1387/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8940 - acc: 0.6114 - val_loss: 3.9479 - val_acc: 0.5989\n",
      "Epoch 1388/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8937 - acc: 0.6138 - val_loss: 3.9476 - val_acc: 0.5943\n",
      "Epoch 1389/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8937 - acc: 0.6139 - val_loss: 3.9463 - val_acc: 0.5966\n",
      "Epoch 1390/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 3.8951 - acc: 0.6122 - val_loss: 3.9472 - val_acc: 0.6021\n",
      "Epoch 1391/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8951 - acc: 0.6139 - val_loss: 3.9498 - val_acc: 0.5925\n",
      "Epoch 1392/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8941 - acc: 0.6114 - val_loss: 3.9470 - val_acc: 0.5980\n",
      "Epoch 1393/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8936 - acc: 0.6149 - val_loss: 3.9476 - val_acc: 0.5952\n",
      "Epoch 1394/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8946 - acc: 0.6110 - val_loss: 3.9488 - val_acc: 0.6012\n",
      "Epoch 1395/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8942 - acc: 0.6149 - val_loss: 3.9480 - val_acc: 0.6017\n",
      "Epoch 1396/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8952 - acc: 0.6122 - val_loss: 3.9555 - val_acc: 0.5869\n",
      "Epoch 1397/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8943 - acc: 0.6119 - val_loss: 3.9466 - val_acc: 0.5971\n",
      "Epoch 1398/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 3.8935 - acc: 0.6124 - val_loss: 3.9464 - val_acc: 0.6035\n",
      "Epoch 1399/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8954 - acc: 0.6085 - val_loss: 3.9473 - val_acc: 0.5980\n",
      "Epoch 1400/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8944 - acc: 0.6125 - val_loss: 3.9469 - val_acc: 0.5961\n",
      "Epoch 1401/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8942 - acc: 0.6115 - val_loss: 3.9482 - val_acc: 0.5989\n",
      "Epoch 1402/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8951 - acc: 0.6083 - val_loss: 3.9469 - val_acc: 0.5975\n",
      "Epoch 1403/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8949 - acc: 0.6119 - val_loss: 3.9487 - val_acc: 0.5966\n",
      "Epoch 1404/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8945 - acc: 0.6092 - val_loss: 3.9475 - val_acc: 0.5934\n",
      "Epoch 1405/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8948 - acc: 0.6123 - val_loss: 3.9525 - val_acc: 0.6017\n",
      "Epoch 1406/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8954 - acc: 0.6108 - val_loss: 3.9491 - val_acc: 0.6012\n",
      "Epoch 1407/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8959 - acc: 0.6114 - val_loss: 3.9469 - val_acc: 0.5980\n",
      "Epoch 1408/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8945 - acc: 0.6108 - val_loss: 3.9467 - val_acc: 0.5984\n",
      "Epoch 1409/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8929 - acc: 0.6114 - val_loss: 3.9467 - val_acc: 0.5966\n",
      "Epoch 1410/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8945 - acc: 0.6118 - val_loss: 3.9525 - val_acc: 0.5915\n",
      "Epoch 1411/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8950 - acc: 0.6115 - val_loss: 3.9474 - val_acc: 0.6012\n",
      "Epoch 1412/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8930 - acc: 0.6167 - val_loss: 3.9466 - val_acc: 0.5994\n",
      "Epoch 1413/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8956 - acc: 0.6117 - val_loss: 3.9467 - val_acc: 0.5989\n",
      "Epoch 1414/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8949 - acc: 0.6134 - val_loss: 3.9471 - val_acc: 0.6026\n",
      "Epoch 1415/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8933 - acc: 0.6117 - val_loss: 3.9478 - val_acc: 0.5975\n",
      "Epoch 1416/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8950 - acc: 0.6134 - val_loss: 3.9513 - val_acc: 0.5925\n",
      "Epoch 1417/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8944 - acc: 0.6109 - val_loss: 3.9488 - val_acc: 0.5952\n",
      "Epoch 1418/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8950 - acc: 0.6133 - val_loss: 3.9492 - val_acc: 0.5952\n",
      "Epoch 1419/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8947 - acc: 0.6108 - val_loss: 3.9474 - val_acc: 0.5961\n",
      "Epoch 1420/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8944 - acc: 0.6113 - val_loss: 3.9476 - val_acc: 0.5966\n",
      "Epoch 1421/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8949 - acc: 0.6084 - val_loss: 3.9492 - val_acc: 0.5961\n",
      "Epoch 1422/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8938 - acc: 0.6126 - val_loss: 3.9484 - val_acc: 0.5934\n",
      "Epoch 1423/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8929 - acc: 0.6148 - val_loss: 3.9511 - val_acc: 0.5915\n",
      "Epoch 1424/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8945 - acc: 0.6109 - val_loss: 3.9472 - val_acc: 0.5971\n",
      "Epoch 1425/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8937 - acc: 0.6127 - val_loss: 3.9472 - val_acc: 0.5975\n",
      "Epoch 1426/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8943 - acc: 0.6160 - val_loss: 3.9465 - val_acc: 0.5975\n",
      "Epoch 1427/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8938 - acc: 0.6131 - val_loss: 3.9465 - val_acc: 0.5998\n",
      "Epoch 1428/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8937 - acc: 0.6150 - val_loss: 3.9502 - val_acc: 0.6058\n",
      "Epoch 1429/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8925 - acc: 0.6164 - val_loss: 3.9494 - val_acc: 0.5989\n",
      "Epoch 1430/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8941 - acc: 0.6146 - val_loss: 3.9493 - val_acc: 0.5961\n",
      "Epoch 1431/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8940 - acc: 0.6127 - val_loss: 3.9480 - val_acc: 0.6003\n",
      "Epoch 1432/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8941 - acc: 0.6144 - val_loss: 3.9486 - val_acc: 0.5961\n",
      "Epoch 1433/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8938 - acc: 0.6114 - val_loss: 3.9470 - val_acc: 0.5975\n",
      "Epoch 1434/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8933 - acc: 0.6141 - val_loss: 3.9469 - val_acc: 0.5975\n",
      "Epoch 1435/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8931 - acc: 0.6131 - val_loss: 3.9507 - val_acc: 0.5943\n",
      "Epoch 1436/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8951 - acc: 0.6132 - val_loss: 3.9493 - val_acc: 0.5925\n",
      "Epoch 1437/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8932 - acc: 0.6118 - val_loss: 3.9473 - val_acc: 0.5980\n",
      "Epoch 1438/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8934 - acc: 0.6142 - val_loss: 3.9478 - val_acc: 0.5989\n",
      "Epoch 1439/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 3.8945 - acc: 0.6111 - val_loss: 3.9493 - val_acc: 0.5957\n",
      "Epoch 1440/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 3.8937 - acc: 0.6121 - val_loss: 3.9505 - val_acc: 0.5957\n",
      "Epoch 1441/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8935 - acc: 0.6145 - val_loss: 3.9504 - val_acc: 0.5948\n",
      "Epoch 1442/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8947 - acc: 0.6134 - val_loss: 3.9506 - val_acc: 0.6049\n",
      "Epoch 1443/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8942 - acc: 0.6127 - val_loss: 3.9480 - val_acc: 0.5961\n",
      "Epoch 1444/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8956 - acc: 0.6133 - val_loss: 3.9518 - val_acc: 0.5911\n",
      "Epoch 1445/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8947 - acc: 0.6131 - val_loss: 3.9463 - val_acc: 0.5984\n",
      "Epoch 1446/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8939 - acc: 0.6137 - val_loss: 3.9482 - val_acc: 0.5915\n",
      "Epoch 1447/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8940 - acc: 0.6146 - val_loss: 3.9488 - val_acc: 0.5961\n",
      "Epoch 1448/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8949 - acc: 0.6122 - val_loss: 3.9493 - val_acc: 0.6030\n",
      "Epoch 1449/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8942 - acc: 0.6126 - val_loss: 3.9484 - val_acc: 0.5966\n",
      "Epoch 1450/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8937 - acc: 0.6132 - val_loss: 3.9495 - val_acc: 0.5984\n",
      "Epoch 1451/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8943 - acc: 0.6109 - val_loss: 3.9550 - val_acc: 0.5892\n",
      "Epoch 1452/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8936 - acc: 0.6132 - val_loss: 3.9556 - val_acc: 0.6012\n",
      "Epoch 1453/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8947 - acc: 0.6139 - val_loss: 3.9471 - val_acc: 0.5989\n",
      "Epoch 1454/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8928 - acc: 0.6134 - val_loss: 3.9570 - val_acc: 0.6003\n",
      "Epoch 1455/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8939 - acc: 0.6115 - val_loss: 3.9464 - val_acc: 0.5989\n",
      "Epoch 1456/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8937 - acc: 0.6125 - val_loss: 3.9472 - val_acc: 0.5984\n",
      "Epoch 1457/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8937 - acc: 0.6139 - val_loss: 3.9559 - val_acc: 0.5897\n",
      "Epoch 1458/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8944 - acc: 0.6093 - val_loss: 3.9502 - val_acc: 0.5943\n",
      "Epoch 1459/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8938 - acc: 0.6103 - val_loss: 3.9510 - val_acc: 0.5975\n",
      "Epoch 1460/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8942 - acc: 0.6115 - val_loss: 3.9473 - val_acc: 0.5980\n",
      "Epoch 1461/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8943 - acc: 0.6111 - val_loss: 3.9481 - val_acc: 0.5984\n",
      "Epoch 1462/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8941 - acc: 0.6132 - val_loss: 3.9473 - val_acc: 0.6026\n",
      "Epoch 1463/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8943 - acc: 0.6127 - val_loss: 3.9504 - val_acc: 0.5938\n",
      "Epoch 1464/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8945 - acc: 0.6123 - val_loss: 3.9478 - val_acc: 0.6017\n",
      "Epoch 1465/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8939 - acc: 0.6116 - val_loss: 3.9491 - val_acc: 0.5952\n",
      "Epoch 1466/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8947 - acc: 0.6094 - val_loss: 3.9486 - val_acc: 0.5975\n",
      "Epoch 1467/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8944 - acc: 0.6103 - val_loss: 3.9485 - val_acc: 0.5984\n",
      "Epoch 1468/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8945 - acc: 0.6124 - val_loss: 3.9476 - val_acc: 0.5966\n",
      "Epoch 1469/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8934 - acc: 0.6159 - val_loss: 3.9497 - val_acc: 0.5961\n",
      "Epoch 1470/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8943 - acc: 0.6106 - val_loss: 3.9483 - val_acc: 0.5929\n",
      "Epoch 1471/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8935 - acc: 0.6142 - val_loss: 3.9535 - val_acc: 0.6049\n",
      "Epoch 1472/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8949 - acc: 0.6115 - val_loss: 3.9473 - val_acc: 0.5957\n",
      "Epoch 1473/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 3.8945 - acc: 0.6129 - val_loss: 3.9477 - val_acc: 0.5984\n",
      "Epoch 1474/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8938 - acc: 0.6141 - val_loss: 3.9470 - val_acc: 0.5980\n",
      "Epoch 1475/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8936 - acc: 0.6118 - val_loss: 3.9495 - val_acc: 0.6044\n",
      "Epoch 1476/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 3.8944 - acc: 0.6127 - val_loss: 3.9477 - val_acc: 0.5980\n",
      "Epoch 1477/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8939 - acc: 0.6123 - val_loss: 3.9475 - val_acc: 0.5971\n",
      "Epoch 1478/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8938 - acc: 0.6137 - val_loss: 3.9530 - val_acc: 0.6040\n",
      "Epoch 1479/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8945 - acc: 0.6152 - val_loss: 3.9491 - val_acc: 0.6007\n",
      "Epoch 1480/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8938 - acc: 0.6123 - val_loss: 3.9485 - val_acc: 0.6007\n",
      "Epoch 1481/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8946 - acc: 0.6130 - val_loss: 3.9472 - val_acc: 0.6012\n",
      "Epoch 1482/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8939 - acc: 0.6146 - val_loss: 3.9489 - val_acc: 0.5957\n",
      "Epoch 1483/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8940 - acc: 0.6132 - val_loss: 3.9475 - val_acc: 0.5980\n",
      "Epoch 1484/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8939 - acc: 0.6095 - val_loss: 3.9512 - val_acc: 0.6058\n",
      "Epoch 1485/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8934 - acc: 0.6136 - val_loss: 3.9503 - val_acc: 0.5989\n",
      "Epoch 1486/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8935 - acc: 0.6133 - val_loss: 3.9480 - val_acc: 0.5998\n",
      "Epoch 1487/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8933 - acc: 0.6133 - val_loss: 3.9487 - val_acc: 0.5961\n",
      "Epoch 1488/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8938 - acc: 0.6119 - val_loss: 3.9497 - val_acc: 0.5948\n",
      "Epoch 1489/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8944 - acc: 0.6114 - val_loss: 3.9484 - val_acc: 0.5980\n",
      "Epoch 1490/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8941 - acc: 0.6125 - val_loss: 3.9496 - val_acc: 0.5961\n",
      "Epoch 1491/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8936 - acc: 0.6115 - val_loss: 3.9492 - val_acc: 0.5984\n",
      "Epoch 1492/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8942 - acc: 0.6142 - val_loss: 3.9485 - val_acc: 0.5984\n",
      "Epoch 1493/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8941 - acc: 0.6110 - val_loss: 3.9481 - val_acc: 0.5989\n",
      "Epoch 1494/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8934 - acc: 0.6139 - val_loss: 3.9505 - val_acc: 0.5948\n",
      "Epoch 1495/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8941 - acc: 0.6106 - val_loss: 3.9483 - val_acc: 0.6035\n",
      "Epoch 1496/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8942 - acc: 0.6150 - val_loss: 3.9535 - val_acc: 0.6035\n",
      "Epoch 1497/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8939 - acc: 0.6142 - val_loss: 3.9480 - val_acc: 0.5989\n",
      "Epoch 1498/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8934 - acc: 0.6132 - val_loss: 3.9479 - val_acc: 0.5989\n",
      "Epoch 1499/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8930 - acc: 0.6141 - val_loss: 3.9485 - val_acc: 0.5984\n",
      "Epoch 1500/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8942 - acc: 0.6138 - val_loss: 3.9502 - val_acc: 0.5984\n",
      "Epoch 1501/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8941 - acc: 0.6119 - val_loss: 3.9515 - val_acc: 0.6040\n",
      "Epoch 1502/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8945 - acc: 0.6132 - val_loss: 3.9479 - val_acc: 0.5961\n",
      "Epoch 1503/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 3.8936 - acc: 0.6137 - val_loss: 3.9497 - val_acc: 0.5989\n",
      "Epoch 1504/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.8949 - acc: 0.6126 - val_loss: 3.9494 - val_acc: 0.6058\n",
      "Epoch 1505/5000\n",
      "8692/8692 [==============================] - 1s 86us/step - loss: 3.8936 - acc: 0.6116 - val_loss: 3.9488 - val_acc: 0.5961\n",
      "Epoch 1506/5000\n",
      "8692/8692 [==============================] - 1s 86us/step - loss: 3.8929 - acc: 0.6125 - val_loss: 3.9492 - val_acc: 0.5975\n",
      "Epoch 1507/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8935 - acc: 0.6125 - val_loss: 3.9482 - val_acc: 0.5957\n",
      "Epoch 1508/5000\n",
      "8692/8692 [==============================] - 1s 93us/step - loss: 3.8934 - acc: 0.6131 - val_loss: 3.9509 - val_acc: 0.5948\n",
      "Epoch 1509/5000\n",
      "8692/8692 [==============================] - ETA: 0s - loss: 3.9024 - acc: 0.610 - 1s 81us/step - loss: 3.8946 - acc: 0.6117 - val_loss: 3.9486 - val_acc: 0.5966\n",
      "Epoch 1510/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8927 - acc: 0.6133 - val_loss: 3.9494 - val_acc: 0.6003\n",
      "Epoch 1511/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8923 - acc: 0.6138 - val_loss: 3.9518 - val_acc: 0.6063\n",
      "Epoch 1512/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8951 - acc: 0.6107 - val_loss: 3.9491 - val_acc: 0.5984\n",
      "Epoch 1513/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8944 - acc: 0.6108 - val_loss: 3.9535 - val_acc: 0.5929\n",
      "Epoch 1514/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 3.8932 - acc: 0.6133 - val_loss: 3.9478 - val_acc: 0.6007\n",
      "Epoch 1515/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8942 - acc: 0.6136 - val_loss: 3.9485 - val_acc: 0.5998\n",
      "Epoch 1516/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8939 - acc: 0.6100 - val_loss: 3.9505 - val_acc: 0.5952\n",
      "Epoch 1517/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8936 - acc: 0.6139 - val_loss: 3.9543 - val_acc: 0.5911\n",
      "Epoch 1518/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8935 - acc: 0.6090 - val_loss: 3.9491 - val_acc: 0.5980\n",
      "Epoch 1519/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8932 - acc: 0.6111 - val_loss: 3.9482 - val_acc: 0.6007\n",
      "Epoch 1520/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8940 - acc: 0.6123 - val_loss: 3.9485 - val_acc: 0.5994\n",
      "Epoch 1521/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8937 - acc: 0.6141 - val_loss: 3.9502 - val_acc: 0.6003\n",
      "Epoch 1522/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8942 - acc: 0.6119 - val_loss: 3.9488 - val_acc: 0.5971\n",
      "Epoch 1523/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8927 - acc: 0.6139 - val_loss: 3.9487 - val_acc: 0.5984\n",
      "Epoch 1524/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8931 - acc: 0.6100 - val_loss: 3.9499 - val_acc: 0.5971\n",
      "Epoch 1525/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8940 - acc: 0.6130 - val_loss: 3.9498 - val_acc: 0.6067\n",
      "Epoch 1526/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8935 - acc: 0.6126 - val_loss: 3.9490 - val_acc: 0.5998\n",
      "Epoch 1527/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8927 - acc: 0.6155 - val_loss: 3.9537 - val_acc: 0.5915\n",
      "Epoch 1528/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8938 - acc: 0.6147 - val_loss: 3.9557 - val_acc: 0.5888\n",
      "Epoch 1529/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8945 - acc: 0.6134 - val_loss: 3.9539 - val_acc: 0.5938\n",
      "Epoch 1530/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8922 - acc: 0.6147 - val_loss: 3.9516 - val_acc: 0.5998\n",
      "Epoch 1531/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8955 - acc: 0.6106 - val_loss: 3.9543 - val_acc: 0.6040\n",
      "Epoch 1532/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8940 - acc: 0.6127 - val_loss: 3.9503 - val_acc: 0.5966\n",
      "Epoch 1533/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8933 - acc: 0.6126 - val_loss: 3.9549 - val_acc: 0.5911\n",
      "Epoch 1534/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8942 - acc: 0.6142 - val_loss: 3.9489 - val_acc: 0.5971\n",
      "Epoch 1535/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8951 - acc: 0.6123 - val_loss: 3.9511 - val_acc: 0.6044\n",
      "Epoch 1536/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8930 - acc: 0.6129 - val_loss: 3.9488 - val_acc: 0.5952\n",
      "Epoch 1537/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8934 - acc: 0.6125 - val_loss: 3.9515 - val_acc: 0.6058\n",
      "Epoch 1538/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8936 - acc: 0.6122 - val_loss: 3.9491 - val_acc: 0.5948\n",
      "Epoch 1539/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8934 - acc: 0.6145 - val_loss: 3.9485 - val_acc: 0.5971\n",
      "Epoch 1540/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8942 - acc: 0.6127 - val_loss: 3.9513 - val_acc: 0.6044\n",
      "Epoch 1541/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8928 - acc: 0.6155 - val_loss: 3.9482 - val_acc: 0.5971\n",
      "Epoch 1542/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8938 - acc: 0.6131 - val_loss: 3.9490 - val_acc: 0.5998\n",
      "Epoch 1543/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8933 - acc: 0.6122 - val_loss: 3.9526 - val_acc: 0.5911\n",
      "Epoch 1544/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8930 - acc: 0.6134 - val_loss: 3.9506 - val_acc: 0.6063\n",
      "Epoch 1545/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8927 - acc: 0.6139 - val_loss: 3.9499 - val_acc: 0.5984\n",
      "Epoch 1546/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8938 - acc: 0.6084 - val_loss: 3.9543 - val_acc: 0.5920\n",
      "Epoch 1547/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8939 - acc: 0.6122 - val_loss: 3.9488 - val_acc: 0.5966\n",
      "Epoch 1548/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8935 - acc: 0.6122 - val_loss: 3.9493 - val_acc: 0.5989\n",
      "Epoch 1549/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8930 - acc: 0.6137 - val_loss: 3.9477 - val_acc: 0.5998\n",
      "Epoch 1550/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8936 - acc: 0.6139 - val_loss: 3.9489 - val_acc: 0.6026\n",
      "Epoch 1551/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8934 - acc: 0.6126 - val_loss: 3.9519 - val_acc: 0.5984\n",
      "Epoch 1552/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8929 - acc: 0.6146 - val_loss: 3.9483 - val_acc: 0.5998\n",
      "Epoch 1553/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8936 - acc: 0.6130 - val_loss: 3.9497 - val_acc: 0.5957\n",
      "Epoch 1554/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8934 - acc: 0.6123 - val_loss: 3.9509 - val_acc: 0.5975\n",
      "Epoch 1555/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8931 - acc: 0.6122 - val_loss: 3.9545 - val_acc: 0.5934\n",
      "Epoch 1556/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8927 - acc: 0.6138 - val_loss: 3.9484 - val_acc: 0.5966\n",
      "Epoch 1557/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8944 - acc: 0.6119 - val_loss: 3.9497 - val_acc: 0.5929\n",
      "Epoch 1558/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8939 - acc: 0.6129 - val_loss: 3.9493 - val_acc: 0.6017\n",
      "Epoch 1559/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8931 - acc: 0.6147 - val_loss: 3.9482 - val_acc: 0.5975\n",
      "Epoch 1560/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8932 - acc: 0.6132 - val_loss: 3.9499 - val_acc: 0.5957\n",
      "Epoch 1561/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8931 - acc: 0.6114 - val_loss: 3.9556 - val_acc: 0.5915\n",
      "Epoch 1562/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8929 - acc: 0.6121 - val_loss: 3.9504 - val_acc: 0.5998\n",
      "Epoch 1563/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8932 - acc: 0.6118 - val_loss: 3.9495 - val_acc: 0.6017\n",
      "Epoch 1564/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8940 - acc: 0.6121 - val_loss: 3.9489 - val_acc: 0.5989\n",
      "Epoch 1565/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8945 - acc: 0.6125 - val_loss: 3.9481 - val_acc: 0.5989\n",
      "Epoch 1566/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8947 - acc: 0.6134 - val_loss: 3.9483 - val_acc: 0.5980\n",
      "Epoch 1567/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8925 - acc: 0.6138 - val_loss: 3.9569 - val_acc: 0.6017\n",
      "Epoch 1568/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8942 - acc: 0.6125 - val_loss: 3.9494 - val_acc: 0.5989\n",
      "Epoch 1569/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8944 - acc: 0.6132 - val_loss: 3.9552 - val_acc: 0.5897\n",
      "Epoch 1570/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8940 - acc: 0.6114 - val_loss: 3.9485 - val_acc: 0.5966\n",
      "Epoch 1571/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8924 - acc: 0.6138 - val_loss: 3.9523 - val_acc: 0.6063\n",
      "Epoch 1572/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8929 - acc: 0.6145 - val_loss: 3.9499 - val_acc: 0.5971\n",
      "Epoch 1573/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8945 - acc: 0.6132 - val_loss: 3.9494 - val_acc: 0.6017\n",
      "Epoch 1574/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8939 - acc: 0.6144 - val_loss: 3.9480 - val_acc: 0.5957\n",
      "Epoch 1575/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 3.8935 - acc: 0.6123 - val_loss: 3.9542 - val_acc: 0.6063\n",
      "Epoch 1576/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8940 - acc: 0.6133 - val_loss: 3.9491 - val_acc: 0.6007\n",
      "Epoch 1577/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8936 - acc: 0.6116 - val_loss: 3.9490 - val_acc: 0.6021\n",
      "Epoch 1578/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8941 - acc: 0.6168 - val_loss: 3.9509 - val_acc: 0.5934\n",
      "Epoch 1579/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8937 - acc: 0.6131 - val_loss: 3.9487 - val_acc: 0.5980\n",
      "Epoch 1580/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8933 - acc: 0.6153 - val_loss: 3.9570 - val_acc: 0.5897\n",
      "Epoch 1581/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8944 - acc: 0.6104 - val_loss: 3.9489 - val_acc: 0.5994\n",
      "Epoch 1582/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8917 - acc: 0.6154 - val_loss: 3.9502 - val_acc: 0.5938\n",
      "Epoch 1583/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8925 - acc: 0.6155 - val_loss: 3.9488 - val_acc: 0.5961\n",
      "Epoch 1584/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8929 - acc: 0.6130 - val_loss: 3.9483 - val_acc: 0.5994\n",
      "Epoch 1585/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8931 - acc: 0.6138 - val_loss: 3.9483 - val_acc: 0.5989\n",
      "Epoch 1586/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8938 - acc: 0.6108 - val_loss: 3.9630 - val_acc: 0.5975\n",
      "Epoch 1587/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8939 - acc: 0.6138 - val_loss: 3.9516 - val_acc: 0.5934\n",
      "Epoch 1588/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8934 - acc: 0.6167 - val_loss: 3.9479 - val_acc: 0.5971\n",
      "Epoch 1589/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8940 - acc: 0.6124 - val_loss: 3.9520 - val_acc: 0.6049\n",
      "Epoch 1590/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8930 - acc: 0.6131 - val_loss: 3.9488 - val_acc: 0.5938\n",
      "Epoch 1591/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8933 - acc: 0.6119 - val_loss: 3.9510 - val_acc: 0.5994\n",
      "Epoch 1592/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8929 - acc: 0.6129 - val_loss: 3.9489 - val_acc: 0.5980\n",
      "Epoch 1593/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8946 - acc: 0.6125 - val_loss: 3.9482 - val_acc: 0.5957\n",
      "Epoch 1594/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8923 - acc: 0.6155 - val_loss: 3.9483 - val_acc: 0.5984\n",
      "Epoch 1595/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8928 - acc: 0.6137 - val_loss: 3.9494 - val_acc: 0.5966\n",
      "Epoch 1596/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8934 - acc: 0.6162 - val_loss: 3.9504 - val_acc: 0.5966\n",
      "Epoch 1597/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8947 - acc: 0.6116 - val_loss: 3.9493 - val_acc: 0.5975\n",
      "Epoch 1598/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8931 - acc: 0.6107 - val_loss: 3.9491 - val_acc: 0.5966\n",
      "Epoch 1599/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8937 - acc: 0.6137 - val_loss: 3.9490 - val_acc: 0.5934\n",
      "Epoch 1600/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8939 - acc: 0.6141 - val_loss: 3.9497 - val_acc: 0.5971\n",
      "Epoch 1601/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8930 - acc: 0.6133 - val_loss: 3.9533 - val_acc: 0.6063\n",
      "Epoch 1602/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8934 - acc: 0.6116 - val_loss: 3.9485 - val_acc: 0.5961\n",
      "Epoch 1603/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8932 - acc: 0.6154 - val_loss: 3.9494 - val_acc: 0.5989\n",
      "Epoch 1604/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8942 - acc: 0.6104 - val_loss: 3.9489 - val_acc: 0.5975\n",
      "Epoch 1605/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8933 - acc: 0.6125 - val_loss: 3.9509 - val_acc: 0.6030\n",
      "Epoch 1606/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 3.8935 - acc: 0.6114 - val_loss: 3.9494 - val_acc: 0.5934\n",
      "Epoch 1607/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8932 - acc: 0.6115 - val_loss: 3.9494 - val_acc: 0.5994\n",
      "Epoch 1608/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8929 - acc: 0.6099 - val_loss: 3.9509 - val_acc: 0.5961\n",
      "Epoch 1609/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8940 - acc: 0.6104 - val_loss: 3.9531 - val_acc: 0.5998\n",
      "Epoch 1610/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8933 - acc: 0.6127 - val_loss: 3.9501 - val_acc: 0.6058\n",
      "Epoch 1611/5000\n",
      "8692/8692 [==============================] - 1s 76us/step - loss: 3.8937 - acc: 0.6131 - val_loss: 3.9483 - val_acc: 0.5971\n",
      "Epoch 1612/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 3.8917 - acc: 0.6150 - val_loss: 3.9478 - val_acc: 0.5952\n",
      "Epoch 1613/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8935 - acc: 0.6142 - val_loss: 3.9521 - val_acc: 0.5938\n",
      "Epoch 1614/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8934 - acc: 0.6140 - val_loss: 3.9511 - val_acc: 0.6076\n",
      "Epoch 1615/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8920 - acc: 0.6155 - val_loss: 3.9502 - val_acc: 0.5971\n",
      "Epoch 1616/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8936 - acc: 0.6108 - val_loss: 3.9541 - val_acc: 0.5915\n",
      "Epoch 1617/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8933 - acc: 0.6101 - val_loss: 3.9475 - val_acc: 0.5989\n",
      "Epoch 1618/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8944 - acc: 0.6127 - val_loss: 3.9506 - val_acc: 0.5948\n",
      "Epoch 1619/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8934 - acc: 0.6113 - val_loss: 3.9483 - val_acc: 0.5966\n",
      "Epoch 1620/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8943 - acc: 0.6092 - val_loss: 3.9554 - val_acc: 0.5998\n",
      "Epoch 1621/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 3.8928 - acc: 0.6109 - val_loss: 3.9525 - val_acc: 0.6035\n",
      "Epoch 1622/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 3.8940 - acc: 0.6111 - val_loss: 3.9495 - val_acc: 0.5975\n",
      "Epoch 1623/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8930 - acc: 0.6129 - val_loss: 3.9562 - val_acc: 0.5892\n",
      "Epoch 1624/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8938 - acc: 0.6126 - val_loss: 3.9488 - val_acc: 0.5989\n",
      "Epoch 1625/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8939 - acc: 0.6104 - val_loss: 3.9482 - val_acc: 0.5998\n",
      "Epoch 1626/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 3.8936 - acc: 0.6127 - val_loss: 3.9591 - val_acc: 0.5888\n",
      "Epoch 1627/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8924 - acc: 0.6155 - val_loss: 3.9612 - val_acc: 0.5851\n",
      "Epoch 1628/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8930 - acc: 0.6148 - val_loss: 3.9549 - val_acc: 0.6035\n",
      "Epoch 1629/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8933 - acc: 0.6157 - val_loss: 3.9488 - val_acc: 0.6026\n",
      "Epoch 1630/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8931 - acc: 0.6131 - val_loss: 3.9491 - val_acc: 0.5984\n",
      "Epoch 1631/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8930 - acc: 0.6144 - val_loss: 3.9488 - val_acc: 0.5948\n",
      "Epoch 1632/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8939 - acc: 0.6126 - val_loss: 3.9524 - val_acc: 0.6067\n",
      "Epoch 1633/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8941 - acc: 0.6101 - val_loss: 3.9479 - val_acc: 0.5975\n",
      "Epoch 1634/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8932 - acc: 0.6113 - val_loss: 3.9543 - val_acc: 0.5897\n",
      "Epoch 1635/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 3.8935 - acc: 0.6131 - val_loss: 3.9482 - val_acc: 0.6007\n",
      "Epoch 1636/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8928 - acc: 0.6122 - val_loss: 3.9481 - val_acc: 0.5948\n",
      "Epoch 1637/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 3.8922 - acc: 0.6162 - val_loss: 3.9496 - val_acc: 0.6063\n",
      "Epoch 1638/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8940 - acc: 0.6127 - val_loss: 3.9488 - val_acc: 0.5984\n",
      "Epoch 1639/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8933 - acc: 0.6117 - val_loss: 3.9485 - val_acc: 0.5957\n",
      "Epoch 1640/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8927 - acc: 0.6145 - val_loss: 3.9493 - val_acc: 0.5980\n",
      "Epoch 1641/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8929 - acc: 0.6136 - val_loss: 3.9494 - val_acc: 0.6017\n",
      "Epoch 1642/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8928 - acc: 0.6126 - val_loss: 3.9488 - val_acc: 0.5980\n",
      "Epoch 1643/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8935 - acc: 0.6103 - val_loss: 3.9534 - val_acc: 0.6030\n",
      "Epoch 1644/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8929 - acc: 0.6150 - val_loss: 3.9489 - val_acc: 0.6007\n",
      "Epoch 1645/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8928 - acc: 0.6129 - val_loss: 3.9512 - val_acc: 0.6053\n",
      "Epoch 1646/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8936 - acc: 0.6140 - val_loss: 3.9489 - val_acc: 0.5980\n",
      "Epoch 1647/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8925 - acc: 0.6142 - val_loss: 3.9510 - val_acc: 0.6058\n",
      "Epoch 1648/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8928 - acc: 0.6123 - val_loss: 3.9482 - val_acc: 0.6021\n",
      "Epoch 1649/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 3.8926 - acc: 0.6134 - val_loss: 3.9482 - val_acc: 0.5971\n",
      "Epoch 1650/5000\n",
      "8692/8692 [==============================] - 1s 78us/step - loss: 3.8927 - acc: 0.6130 - val_loss: 3.9485 - val_acc: 0.5966\n",
      "Epoch 1651/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 3.8932 - acc: 0.6139 - val_loss: 3.9499 - val_acc: 0.6058\n",
      "Epoch 1652/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8937 - acc: 0.6113 - val_loss: 3.9531 - val_acc: 0.6003\n",
      "Epoch 1653/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8952 - acc: 0.6099 - val_loss: 3.9479 - val_acc: 0.5952\n",
      "Epoch 1654/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8938 - acc: 0.6130 - val_loss: 3.9555 - val_acc: 0.5911\n",
      "Epoch 1655/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8918 - acc: 0.6122 - val_loss: 3.9494 - val_acc: 0.5952\n",
      "Epoch 1656/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8935 - acc: 0.6130 - val_loss: 3.9494 - val_acc: 0.6049\n",
      "Epoch 1657/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8927 - acc: 0.6107 - val_loss: 3.9523 - val_acc: 0.5938\n",
      "Epoch 1658/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8943 - acc: 0.6130 - val_loss: 3.9486 - val_acc: 0.5957\n",
      "Epoch 1659/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8925 - acc: 0.6155 - val_loss: 3.9516 - val_acc: 0.5920\n",
      "Epoch 1660/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8937 - acc: 0.6103 - val_loss: 3.9484 - val_acc: 0.5975\n",
      "Epoch 1661/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8936 - acc: 0.6118 - val_loss: 3.9497 - val_acc: 0.5948\n",
      "Epoch 1662/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8928 - acc: 0.6142 - val_loss: 3.9486 - val_acc: 0.5994\n",
      "Epoch 1663/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8932 - acc: 0.6102 - val_loss: 3.9557 - val_acc: 0.6035\n",
      "Epoch 1664/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8928 - acc: 0.6144 - val_loss: 3.9477 - val_acc: 0.6007\n",
      "Epoch 1665/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8941 - acc: 0.6101 - val_loss: 3.9496 - val_acc: 0.5961\n",
      "Epoch 1666/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8928 - acc: 0.6124 - val_loss: 3.9508 - val_acc: 0.6067\n",
      "Epoch 1667/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8933 - acc: 0.6132 - val_loss: 3.9474 - val_acc: 0.5980\n",
      "Epoch 1668/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8938 - acc: 0.6146 - val_loss: 3.9492 - val_acc: 0.6044\n",
      "Epoch 1669/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8922 - acc: 0.6139 - val_loss: 3.9497 - val_acc: 0.5938\n",
      "Epoch 1670/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8927 - acc: 0.6134 - val_loss: 3.9488 - val_acc: 0.5984\n",
      "Epoch 1671/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8920 - acc: 0.6148 - val_loss: 3.9497 - val_acc: 0.6007\n",
      "Epoch 1672/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8937 - acc: 0.6132 - val_loss: 3.9546 - val_acc: 0.5897\n",
      "Epoch 1673/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8925 - acc: 0.6134 - val_loss: 3.9516 - val_acc: 0.5952\n",
      "Epoch 1674/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8927 - acc: 0.6125 - val_loss: 3.9561 - val_acc: 0.5860\n",
      "Epoch 1675/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8922 - acc: 0.6138 - val_loss: 3.9520 - val_acc: 0.6040\n",
      "Epoch 1676/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 3.8927 - acc: 0.6139 - val_loss: 3.9504 - val_acc: 0.6067\n",
      "Epoch 1677/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8936 - acc: 0.6123 - val_loss: 3.9492 - val_acc: 0.6058\n",
      "Epoch 1678/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8921 - acc: 0.6157 - val_loss: 3.9514 - val_acc: 0.6040\n",
      "Epoch 1679/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 3.8926 - acc: 0.6138 - val_loss: 3.9495 - val_acc: 0.5966\n",
      "Epoch 1680/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8933 - acc: 0.6145 - val_loss: 3.9505 - val_acc: 0.6058\n",
      "Epoch 1681/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8932 - acc: 0.6100 - val_loss: 3.9496 - val_acc: 0.6058\n",
      "Epoch 1682/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8942 - acc: 0.6142 - val_loss: 3.9538 - val_acc: 0.5883\n",
      "Epoch 1683/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8923 - acc: 0.6136 - val_loss: 3.9476 - val_acc: 0.5971\n",
      "Epoch 1684/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8925 - acc: 0.6148 - val_loss: 3.9474 - val_acc: 0.5971\n",
      "Epoch 1685/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8924 - acc: 0.6149 - val_loss: 3.9505 - val_acc: 0.5961\n",
      "Epoch 1686/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 3.8929 - acc: 0.6109 - val_loss: 3.9479 - val_acc: 0.5998\n",
      "Epoch 1687/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 3.8931 - acc: 0.6084 - val_loss: 3.9493 - val_acc: 0.5961\n",
      "Epoch 1688/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8924 - acc: 0.6124 - val_loss: 3.9536 - val_acc: 0.5920\n",
      "Epoch 1689/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 3.8919 - acc: 0.6163 - val_loss: 3.9551 - val_acc: 0.6030\n",
      "Epoch 1690/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8928 - acc: 0.6096 - val_loss: 3.9515 - val_acc: 0.6058\n",
      "Epoch 1691/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8928 - acc: 0.6131 - val_loss: 3.9531 - val_acc: 0.5925\n",
      "Epoch 1692/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8918 - acc: 0.6124 - val_loss: 3.9484 - val_acc: 0.5957\n",
      "Epoch 1693/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8920 - acc: 0.6119 - val_loss: 3.9542 - val_acc: 0.5915\n",
      "Epoch 1694/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 3.8917 - acc: 0.6137 - val_loss: 3.9477 - val_acc: 0.5994\n",
      "Epoch 1695/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 3.8932 - acc: 0.6122 - val_loss: 3.9514 - val_acc: 0.5929\n",
      "Epoch 1696/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 3.8927 - acc: 0.6134 - val_loss: 3.9566 - val_acc: 0.5998\n",
      "Epoch 1697/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 3.8933 - acc: 0.6136 - val_loss: 3.9484 - val_acc: 0.6007\n",
      "Epoch 1698/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 3.8932 - acc: 0.6138 - val_loss: 3.9533 - val_acc: 0.5925\n",
      "Epoch 1699/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 50us/step - loss: 3.8935 - acc: 0.6116 - val_loss: 3.9488 - val_acc: 0.5971\n",
      "Epoch 1700/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 3.8922 - acc: 0.6141 - val_loss: 3.9492 - val_acc: 0.6017\n",
      "Epoch 1701/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8933 - acc: 0.6142 - val_loss: 3.9471 - val_acc: 0.5998\n",
      "Epoch 1702/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8932 - acc: 0.6137 - val_loss: 3.9538 - val_acc: 0.5883\n",
      "Epoch 1703/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8929 - acc: 0.6127 - val_loss: 3.9472 - val_acc: 0.5966\n",
      "Epoch 1704/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8927 - acc: 0.6133 - val_loss: 3.9508 - val_acc: 0.6030\n",
      "Epoch 1705/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8922 - acc: 0.6137 - val_loss: 3.9478 - val_acc: 0.5989\n",
      "Epoch 1706/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8921 - acc: 0.6141 - val_loss: 3.9492 - val_acc: 0.5975\n",
      "Epoch 1707/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8933 - acc: 0.6132 - val_loss: 3.9505 - val_acc: 0.6058\n",
      "Epoch 1708/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 3.8932 - acc: 0.6142 - val_loss: 3.9531 - val_acc: 0.6040\n",
      "Epoch 1709/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.8930 - acc: 0.6118 - val_loss: 3.9444 - val_acc: 0.5989\n",
      "Epoch 1710/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 3.9912 - acc: 0.6069 - val_loss: 4.0723 - val_acc: 0.5915\n",
      "Epoch 1711/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2994 - acc: 0.5892 - val_loss: 4.0695 - val_acc: 0.5961\n",
      "Epoch 1712/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2998 - acc: 0.5897 - val_loss: 4.0760 - val_acc: 0.5860\n",
      "Epoch 1713/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.3000 - acc: 0.5890 - val_loss: 4.0705 - val_acc: 0.5952\n",
      "Epoch 1714/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2999 - acc: 0.5894 - val_loss: 4.0760 - val_acc: 0.6007\n",
      "Epoch 1715/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2994 - acc: 0.5933 - val_loss: 4.0724 - val_acc: 0.5920\n",
      "Epoch 1716/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2988 - acc: 0.5943 - val_loss: 4.0697 - val_acc: 0.5897\n",
      "Epoch 1717/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2544 - acc: 0.5935 - val_loss: 4.0728 - val_acc: 0.5920\n",
      "Epoch 1718/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2992 - acc: 0.5882 - val_loss: 4.0696 - val_acc: 0.5929\n",
      "Epoch 1719/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.3003 - acc: 0.5878 - val_loss: 4.0696 - val_acc: 0.5925\n",
      "Epoch 1720/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2990 - acc: 0.5912 - val_loss: 4.0715 - val_acc: 0.5971\n",
      "Epoch 1721/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2997 - acc: 0.5901 - val_loss: 4.0697 - val_acc: 0.5929\n",
      "Epoch 1722/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2993 - acc: 0.5920 - val_loss: 4.0824 - val_acc: 0.5814\n",
      "Epoch 1723/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.3000 - acc: 0.5911 - val_loss: 4.0755 - val_acc: 0.5984\n",
      "Epoch 1724/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.3001 - acc: 0.5899 - val_loss: 4.0698 - val_acc: 0.5971\n",
      "Epoch 1725/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2998 - acc: 0.5911 - val_loss: 4.0714 - val_acc: 0.6017\n",
      "Epoch 1726/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2996 - acc: 0.5895 - val_loss: 4.0696 - val_acc: 0.5925\n",
      "Epoch 1727/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2988 - acc: 0.5900 - val_loss: 4.0753 - val_acc: 0.5846\n",
      "Epoch 1728/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2887 - acc: 0.5912 - val_loss: 4.0697 - val_acc: 0.5938\n",
      "Epoch 1729/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2992 - acc: 0.5918 - val_loss: 4.0695 - val_acc: 0.5902\n",
      "Epoch 1730/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2996 - acc: 0.5927 - val_loss: 4.0735 - val_acc: 0.5860\n",
      "Epoch 1731/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2996 - acc: 0.5908 - val_loss: 4.0696 - val_acc: 0.5934\n",
      "Epoch 1732/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2993 - acc: 0.5893 - val_loss: 4.0723 - val_acc: 0.6003\n",
      "Epoch 1733/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2988 - acc: 0.5909 - val_loss: 4.0718 - val_acc: 0.5920\n",
      "Epoch 1734/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.3002 - acc: 0.5897 - val_loss: 4.0704 - val_acc: 0.5980\n",
      "Epoch 1735/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2997 - acc: 0.5916 - val_loss: 4.0709 - val_acc: 0.5929\n",
      "Epoch 1736/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2986 - acc: 0.5910 - val_loss: 4.0693 - val_acc: 0.5902\n",
      "Epoch 1737/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2999 - acc: 0.5899 - val_loss: 4.0703 - val_acc: 0.5925\n",
      "Epoch 1738/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2993 - acc: 0.5901 - val_loss: 4.0703 - val_acc: 0.5971\n",
      "Epoch 1739/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2991 - acc: 0.5923 - val_loss: 4.0710 - val_acc: 0.5915\n",
      "Epoch 1740/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2993 - acc: 0.5900 - val_loss: 4.0755 - val_acc: 0.6003\n",
      "Epoch 1741/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.3003 - acc: 0.5887 - val_loss: 4.0728 - val_acc: 0.5994\n",
      "Epoch 1742/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2986 - acc: 0.5873 - val_loss: 4.0749 - val_acc: 0.5994\n",
      "Epoch 1743/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 4.2990 - acc: 0.5923 - val_loss: 4.0722 - val_acc: 0.6003\n",
      "Epoch 1744/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 4.2983 - acc: 0.5900 - val_loss: 4.0708 - val_acc: 0.5892\n",
      "Epoch 1745/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2994 - acc: 0.5917 - val_loss: 4.0711 - val_acc: 0.6007\n",
      "Epoch 1746/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2992 - acc: 0.5910 - val_loss: 4.0703 - val_acc: 0.5998\n",
      "Epoch 1747/5000\n",
      "8692/8692 [==============================] - 1s 73us/step - loss: 4.2990 - acc: 0.5957 - val_loss: 4.0737 - val_acc: 0.5888\n",
      "Epoch 1748/5000\n",
      "8692/8692 [==============================] - 1s 79us/step - loss: 4.2992 - acc: 0.5901 - val_loss: 4.0766 - val_acc: 0.5998\n",
      "Epoch 1749/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.3000 - acc: 0.5903 - val_loss: 4.0707 - val_acc: 0.5971\n",
      "Epoch 1750/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 4.2989 - acc: 0.5911 - val_loss: 4.0734 - val_acc: 0.5920\n",
      "Epoch 1751/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 4.2998 - acc: 0.5919 - val_loss: 4.0774 - val_acc: 0.5842\n",
      "Epoch 1752/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2998 - acc: 0.5909 - val_loss: 4.0695 - val_acc: 0.5948\n",
      "Epoch 1753/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2998 - acc: 0.5917 - val_loss: 4.0724 - val_acc: 0.5883\n",
      "Epoch 1754/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.3000 - acc: 0.5893 - val_loss: 4.0706 - val_acc: 0.5920\n",
      "Epoch 1755/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2986 - acc: 0.5907 - val_loss: 4.0748 - val_acc: 0.5874\n",
      "Epoch 1756/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.3000 - acc: 0.5880 - val_loss: 4.0697 - val_acc: 0.5915\n",
      "Epoch 1757/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2990 - acc: 0.5903 - val_loss: 4.0746 - val_acc: 0.5865\n",
      "Epoch 1758/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.3001 - acc: 0.5872 - val_loss: 4.0711 - val_acc: 0.5929\n",
      "Epoch 1759/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.2998 - acc: 0.5882 - val_loss: 4.0697 - val_acc: 0.5934\n",
      "Epoch 1760/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 4.2994 - acc: 0.5945 - val_loss: 4.0709 - val_acc: 0.5984\n",
      "Epoch 1761/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2998 - acc: 0.5915 - val_loss: 4.0724 - val_acc: 0.5980\n",
      "Epoch 1762/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.3006 - acc: 0.5882 - val_loss: 4.0702 - val_acc: 0.5925\n",
      "Epoch 1763/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2999 - acc: 0.5894 - val_loss: 4.0712 - val_acc: 0.5929\n",
      "Epoch 1764/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2995 - acc: 0.5920 - val_loss: 4.0719 - val_acc: 0.5984\n",
      "Epoch 1765/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2999 - acc: 0.5893 - val_loss: 4.0708 - val_acc: 0.5897\n",
      "Epoch 1766/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2997 - acc: 0.5912 - val_loss: 4.0710 - val_acc: 0.5911\n",
      "Epoch 1767/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2994 - acc: 0.5913 - val_loss: 4.0709 - val_acc: 0.5892\n",
      "Epoch 1768/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2991 - acc: 0.5912 - val_loss: 4.0700 - val_acc: 0.5966\n",
      "Epoch 1769/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.2992 - acc: 0.5916 - val_loss: 4.0720 - val_acc: 0.5938\n",
      "Epoch 1770/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2989 - acc: 0.5910 - val_loss: 4.0712 - val_acc: 0.5883\n",
      "Epoch 1771/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.3000 - acc: 0.5896 - val_loss: 4.0700 - val_acc: 0.5943\n",
      "Epoch 1772/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2994 - acc: 0.5890 - val_loss: 4.0702 - val_acc: 0.5938\n",
      "Epoch 1773/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2996 - acc: 0.5889 - val_loss: 4.0714 - val_acc: 0.5948\n",
      "Epoch 1774/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2994 - acc: 0.5895 - val_loss: 4.0703 - val_acc: 0.5920\n",
      "Epoch 1775/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 4.2990 - acc: 0.5934 - val_loss: 4.0714 - val_acc: 0.5911\n",
      "Epoch 1776/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2995 - acc: 0.5907 - val_loss: 4.0782 - val_acc: 0.5846\n",
      "Epoch 1777/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2989 - acc: 0.5896 - val_loss: 4.0716 - val_acc: 0.5883\n",
      "Epoch 1778/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2983 - acc: 0.5920 - val_loss: 4.0718 - val_acc: 0.5892\n",
      "Epoch 1779/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.3004 - acc: 0.5872 - val_loss: 4.0709 - val_acc: 0.5920\n",
      "Epoch 1780/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2989 - acc: 0.5916 - val_loss: 4.0712 - val_acc: 0.5948\n",
      "Epoch 1781/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 4.3008 - acc: 0.5916 - val_loss: 4.0770 - val_acc: 0.5966\n",
      "Epoch 1782/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.3002 - acc: 0.5908 - val_loss: 4.0703 - val_acc: 0.5929\n",
      "Epoch 1783/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 4.2986 - acc: 0.5907 - val_loss: 4.0698 - val_acc: 0.5915\n",
      "Epoch 1784/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 4.2996 - acc: 0.5895 - val_loss: 4.0731 - val_acc: 0.6007\n",
      "Epoch 1785/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 4.2993 - acc: 0.5927 - val_loss: 4.0713 - val_acc: 0.5879\n",
      "Epoch 1786/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.3005 - acc: 0.5911 - val_loss: 4.0703 - val_acc: 0.5961\n",
      "Epoch 1787/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2985 - acc: 0.5887 - val_loss: 4.0708 - val_acc: 0.5971\n",
      "Epoch 1788/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2996 - acc: 0.5903 - val_loss: 4.0711 - val_acc: 0.5994\n",
      "Epoch 1789/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2992 - acc: 0.5923 - val_loss: 4.0708 - val_acc: 0.5929\n",
      "Epoch 1790/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2995 - acc: 0.5864 - val_loss: 4.0716 - val_acc: 0.6012\n",
      "Epoch 1791/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2990 - acc: 0.5902 - val_loss: 4.0731 - val_acc: 0.6003\n",
      "Epoch 1792/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2996 - acc: 0.5911 - val_loss: 4.0711 - val_acc: 0.5943\n",
      "Epoch 1793/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2994 - acc: 0.5896 - val_loss: 4.0707 - val_acc: 0.5952\n",
      "Epoch 1794/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2982 - acc: 0.5907 - val_loss: 4.0710 - val_acc: 0.5925\n",
      "Epoch 1795/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.2985 - acc: 0.5887 - val_loss: 4.0704 - val_acc: 0.5971\n",
      "Epoch 1796/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2993 - acc: 0.5888 - val_loss: 4.0717 - val_acc: 0.6003\n",
      "Epoch 1797/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2987 - acc: 0.5889 - val_loss: 4.0707 - val_acc: 0.5943\n",
      "Epoch 1798/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2980 - acc: 0.5910 - val_loss: 4.0714 - val_acc: 0.5952\n",
      "Epoch 1799/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2999 - acc: 0.5901 - val_loss: 4.0749 - val_acc: 0.5911\n",
      "Epoch 1800/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.3005 - acc: 0.5863 - val_loss: 4.0704 - val_acc: 0.5911\n",
      "Epoch 1801/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2985 - acc: 0.5940 - val_loss: 4.0697 - val_acc: 0.5929\n",
      "Epoch 1802/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2981 - acc: 0.5920 - val_loss: 4.0762 - val_acc: 0.5856\n",
      "Epoch 1803/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2995 - acc: 0.5897 - val_loss: 4.0698 - val_acc: 0.5925\n",
      "Epoch 1804/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2990 - acc: 0.5894 - val_loss: 4.0710 - val_acc: 0.5915\n",
      "Epoch 1805/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2995 - acc: 0.5915 - val_loss: 4.0703 - val_acc: 0.5934\n",
      "Epoch 1806/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.3001 - acc: 0.5882 - val_loss: 4.0740 - val_acc: 0.5902\n",
      "Epoch 1807/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.3014 - acc: 0.5889 - val_loss: 4.0695 - val_acc: 0.5934\n",
      "Epoch 1808/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2991 - acc: 0.5908 - val_loss: 4.0720 - val_acc: 0.5952\n",
      "Epoch 1809/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2995 - acc: 0.5907 - val_loss: 4.0712 - val_acc: 0.5902\n",
      "Epoch 1810/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.3003 - acc: 0.5915 - val_loss: 4.0709 - val_acc: 0.5948\n",
      "Epoch 1811/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2999 - acc: 0.5911 - val_loss: 4.0705 - val_acc: 0.5952\n",
      "Epoch 1812/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2989 - acc: 0.5877 - val_loss: 4.0733 - val_acc: 0.5883\n",
      "Epoch 1813/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2986 - acc: 0.5887 - val_loss: 4.0711 - val_acc: 0.5925\n",
      "Epoch 1814/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.3002 - acc: 0.5913 - val_loss: 4.0700 - val_acc: 0.5902\n",
      "Epoch 1815/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2983 - acc: 0.5919 - val_loss: 4.0707 - val_acc: 0.5994\n",
      "Epoch 1816/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2991 - acc: 0.5916 - val_loss: 4.0708 - val_acc: 0.5934\n",
      "Epoch 1817/5000\n",
      "8692/8692 [==============================] - 1s 70us/step - loss: 4.2990 - acc: 0.5919 - val_loss: 4.0763 - val_acc: 0.5846\n",
      "Epoch 1818/5000\n",
      "8692/8692 [==============================] - 1s 61us/step - loss: 4.2994 - acc: 0.5904 - val_loss: 4.0723 - val_acc: 0.5925\n",
      "Epoch 1819/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2992 - acc: 0.5889 - val_loss: 4.0706 - val_acc: 0.5925\n",
      "Epoch 1820/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2988 - acc: 0.5900 - val_loss: 4.0708 - val_acc: 0.5938\n",
      "Epoch 1821/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.3001 - acc: 0.5901 - val_loss: 4.0704 - val_acc: 0.5998\n",
      "Epoch 1822/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 4.2993 - acc: 0.5888 - val_loss: 4.0734 - val_acc: 0.6012\n",
      "Epoch 1823/5000\n",
      "8692/8692 [==============================] - 1s 69us/step - loss: 4.2994 - acc: 0.5916 - val_loss: 4.0729 - val_acc: 0.5994\n",
      "Epoch 1824/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.2991 - acc: 0.5899 - val_loss: 4.0718 - val_acc: 0.5897\n",
      "Epoch 1825/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2997 - acc: 0.5902 - val_loss: 4.0726 - val_acc: 0.6003\n",
      "Epoch 1826/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2995 - acc: 0.5925 - val_loss: 4.0721 - val_acc: 0.5994\n",
      "Epoch 1827/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2996 - acc: 0.5877 - val_loss: 4.0721 - val_acc: 0.6007\n",
      "Epoch 1828/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 4.2992 - acc: 0.5903 - val_loss: 4.0714 - val_acc: 0.5915\n",
      "Epoch 1829/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 4.2997 - acc: 0.5850 - val_loss: 4.0705 - val_acc: 0.5925\n",
      "Epoch 1830/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 4.2987 - acc: 0.5912 - val_loss: 4.0733 - val_acc: 0.5892\n",
      "Epoch 1831/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 4.2986 - acc: 0.5900 - val_loss: 4.0695 - val_acc: 0.5902 - loss: 4.3771 - acc: 0.5\n",
      "Epoch 1832/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2995 - acc: 0.5896 - val_loss: 4.0748 - val_acc: 0.5906\n",
      "Epoch 1833/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2993 - acc: 0.5922 - val_loss: 4.0707 - val_acc: 0.5943\n",
      "Epoch 1834/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2984 - acc: 0.5888 - val_loss: 4.0713 - val_acc: 0.5874\n",
      "Epoch 1835/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2980 - acc: 0.5887 - val_loss: 4.0714 - val_acc: 0.5938\n",
      "Epoch 1836/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2989 - acc: 0.5913 - val_loss: 4.0699 - val_acc: 0.5925\n",
      "Epoch 1837/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2989 - acc: 0.5905 - val_loss: 4.0701 - val_acc: 0.5934\n",
      "Epoch 1838/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2986 - acc: 0.5926 - val_loss: 4.0718 - val_acc: 0.5952\n",
      "Epoch 1839/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.3006 - acc: 0.5887 - val_loss: 4.0723 - val_acc: 0.5971\n",
      "Epoch 1840/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2985 - acc: 0.5887 - val_loss: 4.0716 - val_acc: 0.5911\n",
      "Epoch 1841/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2984 - acc: 0.5935 - val_loss: 4.0711 - val_acc: 0.5920\n",
      "Epoch 1842/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.2997 - acc: 0.5900 - val_loss: 4.0704 - val_acc: 0.5948\n",
      "Epoch 1843/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2988 - acc: 0.5911 - val_loss: 4.0833 - val_acc: 0.5961\n",
      "Epoch 1844/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2984 - acc: 0.5905 - val_loss: 4.0704 - val_acc: 0.5929\n",
      "Epoch 1845/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2980 - acc: 0.5904 - val_loss: 4.0707 - val_acc: 0.5929\n",
      "Epoch 1846/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.3007 - acc: 0.5893 - val_loss: 4.0702 - val_acc: 0.5929\n",
      "Epoch 1847/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2990 - acc: 0.5941 - val_loss: 4.0728 - val_acc: 0.5920\n",
      "Epoch 1848/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2986 - acc: 0.5879 - val_loss: 4.0726 - val_acc: 0.5934\n",
      "Epoch 1849/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2991 - acc: 0.5895 - val_loss: 4.0699 - val_acc: 0.5925\n",
      "Epoch 1850/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2995 - acc: 0.5885 - val_loss: 4.0712 - val_acc: 0.5966\n",
      "Epoch 1851/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2996 - acc: 0.5911 - val_loss: 4.0700 - val_acc: 0.5892\n",
      "Epoch 1852/5000\n",
      "8692/8692 [==============================] - 0s 55us/step - loss: 4.2991 - acc: 0.5900 - val_loss: 4.0706 - val_acc: 0.5943\n",
      "Epoch 1853/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2988 - acc: 0.5927 - val_loss: 4.0748 - val_acc: 0.6003\n",
      "Epoch 1854/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.3003 - acc: 0.5880 - val_loss: 4.0712 - val_acc: 0.5966\n",
      "Epoch 1855/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2986 - acc: 0.5923 - val_loss: 4.0711 - val_acc: 0.5892\n",
      "Epoch 1856/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2989 - acc: 0.5890 - val_loss: 4.0703 - val_acc: 0.5897\n",
      "Epoch 1857/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2985 - acc: 0.5905 - val_loss: 4.0754 - val_acc: 0.5989\n",
      "Epoch 1858/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.3002 - acc: 0.5887 - val_loss: 4.0711 - val_acc: 0.5920\n",
      "Epoch 1859/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2982 - acc: 0.5910 - val_loss: 4.0717 - val_acc: 0.5975\n",
      "Epoch 1860/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2988 - acc: 0.5896 - val_loss: 4.0721 - val_acc: 0.5998\n",
      "Epoch 1861/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2987 - acc: 0.5905 - val_loss: 4.0711 - val_acc: 0.5902\n",
      "Epoch 1862/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2980 - acc: 0.5911 - val_loss: 4.0704 - val_acc: 0.5925\n",
      "Epoch 1863/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2987 - acc: 0.5922 - val_loss: 4.0719 - val_acc: 0.5934\n",
      "Epoch 1864/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2983 - acc: 0.5902 - val_loss: 4.0711 - val_acc: 0.5980\n",
      "Epoch 1865/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2984 - acc: 0.5917 - val_loss: 4.0721 - val_acc: 0.5892\n",
      "Epoch 1866/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2988 - acc: 0.5923 - val_loss: 4.0708 - val_acc: 0.5906\n",
      "Epoch 1867/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2981 - acc: 0.5896 - val_loss: 4.0728 - val_acc: 0.5971\n",
      "Epoch 1868/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2987 - acc: 0.5892 - val_loss: 4.0708 - val_acc: 0.5879\n",
      "Epoch 1869/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2990 - acc: 0.5904 - val_loss: 4.0714 - val_acc: 0.6012\n",
      "Epoch 1870/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2994 - acc: 0.5881 - val_loss: 4.0747 - val_acc: 0.5902\n",
      "Epoch 1871/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2994 - acc: 0.5909 - val_loss: 4.0734 - val_acc: 0.5915\n",
      "Epoch 1872/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 4.2981 - acc: 0.5918 - val_loss: 4.0736 - val_acc: 0.5943\n",
      "Epoch 1873/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 1s 64us/step - loss: 4.2986 - acc: 0.5915 - val_loss: 4.0711 - val_acc: 0.5920\n",
      "Epoch 1874/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 4.2984 - acc: 0.5895 - val_loss: 4.0739 - val_acc: 0.5989\n",
      "Epoch 1875/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2991 - acc: 0.5897 - val_loss: 4.0704 - val_acc: 0.5920\n",
      "Epoch 1876/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 4.2983 - acc: 0.5924 - val_loss: 4.0707 - val_acc: 0.5906\n",
      "Epoch 1877/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2986 - acc: 0.5901 - val_loss: 4.0720 - val_acc: 0.5961\n",
      "Epoch 1878/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2988 - acc: 0.5903 - val_loss: 4.0723 - val_acc: 0.5897\n",
      "Epoch 1879/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2989 - acc: 0.5880 - val_loss: 4.0718 - val_acc: 0.5906\n",
      "Epoch 1880/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.3000 - acc: 0.5886 - val_loss: 4.0725 - val_acc: 0.5998\n",
      "Epoch 1881/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2997 - acc: 0.5862 - val_loss: 4.0699 - val_acc: 0.5925\n",
      "Epoch 1882/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2983 - acc: 0.5909 - val_loss: 4.0708 - val_acc: 0.5943\n",
      "Epoch 1883/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2987 - acc: 0.5886 - val_loss: 4.0794 - val_acc: 0.5984\n",
      "Epoch 1884/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.3011 - acc: 0.5880 - val_loss: 4.0713 - val_acc: 0.5920\n",
      "Epoch 1885/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2981 - acc: 0.5904 - val_loss: 4.0698 - val_acc: 0.5975\n",
      "Epoch 1886/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.3004 - acc: 0.5889 - val_loss: 4.0773 - val_acc: 0.5938\n",
      "Epoch 1887/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2987 - acc: 0.5895 - val_loss: 4.0709 - val_acc: 0.5888\n",
      "Epoch 1888/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2984 - acc: 0.5919 - val_loss: 4.0707 - val_acc: 0.5948\n",
      "Epoch 1889/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2984 - acc: 0.5889 - val_loss: 4.0747 - val_acc: 0.5874\n",
      "Epoch 1890/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2990 - acc: 0.5889 - val_loss: 4.0704 - val_acc: 0.5911\n",
      "Epoch 1891/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.3002 - acc: 0.5877 - val_loss: 4.0702 - val_acc: 0.5929\n",
      "Epoch 1892/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2980 - acc: 0.5913 - val_loss: 4.0705 - val_acc: 0.5938\n",
      "Epoch 1893/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2975 - acc: 0.5913 - val_loss: 4.0725 - val_acc: 0.5980\n",
      "Epoch 1894/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2984 - acc: 0.5880 - val_loss: 4.0709 - val_acc: 0.5915\n",
      "Epoch 1895/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2975 - acc: 0.5905 - val_loss: 4.0705 - val_acc: 0.5957\n",
      "Epoch 1896/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2980 - acc: 0.5912 - val_loss: 4.0737 - val_acc: 0.5925\n",
      "Epoch 1897/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2997 - acc: 0.5904 - val_loss: 4.0706 - val_acc: 0.5938\n",
      "Epoch 1898/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2985 - acc: 0.5927 - val_loss: 4.0719 - val_acc: 0.5897\n",
      "Epoch 1899/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2996 - acc: 0.5878 - val_loss: 4.0722 - val_acc: 0.5874\n",
      "Epoch 1900/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2983 - acc: 0.5913 - val_loss: 4.0741 - val_acc: 0.5952\n",
      "Epoch 1901/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2996 - acc: 0.5903 - val_loss: 4.0701 - val_acc: 0.5911\n",
      "Epoch 1902/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2979 - acc: 0.5908 - val_loss: 4.0790 - val_acc: 0.5823\n",
      "Epoch 1903/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2988 - acc: 0.5895 - val_loss: 4.0719 - val_acc: 0.5902\n",
      "Epoch 1904/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2987 - acc: 0.5924 - val_loss: 4.0736 - val_acc: 0.5994\n",
      "Epoch 1905/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2991 - acc: 0.5901 - val_loss: 4.0722 - val_acc: 0.5911\n",
      "Epoch 1906/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2993 - acc: 0.5882 - val_loss: 4.0741 - val_acc: 0.5989\n",
      "Epoch 1907/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2991 - acc: 0.5932 - val_loss: 4.0705 - val_acc: 0.5906\n",
      "Epoch 1908/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2983 - acc: 0.5897 - val_loss: 4.0708 - val_acc: 0.5934\n",
      "Epoch 1909/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 4.2992 - acc: 0.5878 - val_loss: 4.0726 - val_acc: 0.5897\n",
      "Epoch 1910/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2992 - acc: 0.5887 - val_loss: 4.0732 - val_acc: 0.5925\n",
      "Epoch 1911/5000\n",
      "8692/8692 [==============================] - 1s 67us/step - loss: 4.2989 - acc: 0.5904 - val_loss: 4.0699 - val_acc: 0.5915\n",
      "Epoch 1912/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.3000 - acc: 0.5905 - val_loss: 4.0709 - val_acc: 0.5892\n",
      "Epoch 1913/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2983 - acc: 0.5911 - val_loss: 4.0704 - val_acc: 0.5929\n",
      "Epoch 1914/5000\n",
      "8692/8692 [==============================] - 0s 41us/step - loss: 4.2991 - acc: 0.5880 - val_loss: 4.0725 - val_acc: 0.5856\n",
      "Epoch 1915/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2982 - acc: 0.5933 - val_loss: 4.0720 - val_acc: 0.5948\n",
      "Epoch 1916/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2989 - acc: 0.5894 - val_loss: 4.0711 - val_acc: 0.5920\n",
      "Epoch 1917/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2984 - acc: 0.5928 - val_loss: 4.0709 - val_acc: 0.5925\n",
      "Epoch 1918/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2990 - acc: 0.5892 - val_loss: 4.0724 - val_acc: 0.5906\n",
      "Epoch 1919/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2987 - acc: 0.5913 - val_loss: 4.0697 - val_acc: 0.5920\n",
      "Epoch 1920/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2985 - acc: 0.5899 - val_loss: 4.0728 - val_acc: 0.5975\n",
      "Epoch 1921/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2982 - acc: 0.5920 - val_loss: 4.0740 - val_acc: 0.5911\n",
      "Epoch 1922/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2981 - acc: 0.5923 - val_loss: 4.0720 - val_acc: 0.5957\n",
      "Epoch 1923/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2995 - acc: 0.5910 - val_loss: 4.0711 - val_acc: 0.5920\n",
      "Epoch 1924/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2972 - acc: 0.5882 - val_loss: 4.0725 - val_acc: 0.5934\n",
      "Epoch 1925/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2987 - acc: 0.5900 - val_loss: 4.0767 - val_acc: 0.5980\n",
      "Epoch 1926/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2984 - acc: 0.5892 - val_loss: 4.0725 - val_acc: 0.5998\n",
      "Epoch 1927/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2994 - acc: 0.5899 - val_loss: 4.0715 - val_acc: 0.5957\n",
      "Epoch 1928/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 4.2995 - acc: 0.5915 - val_loss: 4.0739 - val_acc: 0.6007\n",
      "Epoch 1929/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2993 - acc: 0.5913 - val_loss: 4.0774 - val_acc: 0.5823\n",
      "Epoch 1930/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2971 - acc: 0.5939 - val_loss: 4.0735 - val_acc: 0.6012\n",
      "Epoch 1931/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2982 - acc: 0.5904 - val_loss: 4.0726 - val_acc: 0.5902\n",
      "Epoch 1932/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2977 - acc: 0.5918 - val_loss: 4.0708 - val_acc: 0.5957\n",
      "Epoch 1933/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2982 - acc: 0.5908 - val_loss: 4.0703 - val_acc: 0.5934\n",
      "Epoch 1934/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2985 - acc: 0.5927 - val_loss: 4.0783 - val_acc: 0.5980\n",
      "Epoch 1935/5000\n",
      "8692/8692 [==============================] - 1s 68us/step - loss: 4.2985 - acc: 0.5902 - val_loss: 4.0706 - val_acc: 0.5929\n",
      "Epoch 1936/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 4.2994 - acc: 0.5909 - val_loss: 4.0706 - val_acc: 0.5943\n",
      "Epoch 1937/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 4.2988 - acc: 0.5905 - val_loss: 4.0739 - val_acc: 0.6003\n",
      "Epoch 1938/5000\n",
      "8692/8692 [==============================] - 1s 59us/step - loss: 4.2983 - acc: 0.5900 - val_loss: 4.0728 - val_acc: 0.5883\n",
      "Epoch 1939/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 4.3001 - acc: 0.5903 - val_loss: 4.0737 - val_acc: 0.6012\n",
      "Epoch 1940/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2987 - acc: 0.5872 - val_loss: 4.0722 - val_acc: 0.5911\n",
      "Epoch 1941/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2985 - acc: 0.5923 - val_loss: 4.0783 - val_acc: 0.5842\n",
      "Epoch 1942/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 4.2991 - acc: 0.5901 - val_loss: 4.0709 - val_acc: 0.5915\n",
      "Epoch 1943/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2978 - acc: 0.5901 - val_loss: 4.0745 - val_acc: 0.5998\n",
      "Epoch 1944/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2987 - acc: 0.5900 - val_loss: 4.0702 - val_acc: 0.5934\n",
      "Epoch 1945/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2991 - acc: 0.5902 - val_loss: 4.0711 - val_acc: 0.5929\n",
      "Epoch 1946/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2991 - acc: 0.5890 - val_loss: 4.0700 - val_acc: 0.5920\n",
      "Epoch 1947/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 4.2989 - acc: 0.5927 - val_loss: 4.0748 - val_acc: 0.5860\n",
      "Epoch 1948/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2992 - acc: 0.5878 - val_loss: 4.0712 - val_acc: 0.5888\n",
      "Epoch 1949/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2989 - acc: 0.5874 - val_loss: 4.0808 - val_acc: 0.5796\n",
      "Epoch 1950/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2983 - acc: 0.5893 - val_loss: 4.0702 - val_acc: 0.5934\n",
      "Epoch 1951/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2991 - acc: 0.5900 - val_loss: 4.0706 - val_acc: 0.5906\n",
      "Epoch 1952/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2989 - acc: 0.5895 - val_loss: 4.0699 - val_acc: 0.5948\n",
      "Epoch 1953/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2984 - acc: 0.5911 - val_loss: 4.0705 - val_acc: 0.5925\n",
      "Epoch 1954/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2982 - acc: 0.5911 - val_loss: 4.0700 - val_acc: 0.5906\n",
      "Epoch 1955/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2980 - acc: 0.5890 - val_loss: 4.0731 - val_acc: 0.5883\n",
      "Epoch 1956/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 4.2986 - acc: 0.5918 - val_loss: 4.0735 - val_acc: 0.5911\n",
      "Epoch 1957/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2992 - acc: 0.5894 - val_loss: 4.0703 - val_acc: 0.5952\n",
      "Epoch 1958/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2993 - acc: 0.5877 - val_loss: 4.0744 - val_acc: 0.5892\n",
      "Epoch 1959/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2984 - acc: 0.5920 - val_loss: 4.0722 - val_acc: 0.6003\n",
      "Epoch 1960/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2978 - acc: 0.5897 - val_loss: 4.0724 - val_acc: 0.5869\n",
      "Epoch 1961/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2974 - acc: 0.5905 - val_loss: 4.0715 - val_acc: 0.5911\n",
      "Epoch 1962/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2984 - acc: 0.5933 - val_loss: 4.0736 - val_acc: 0.5911\n",
      "Epoch 1963/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2983 - acc: 0.5911 - val_loss: 4.0715 - val_acc: 0.5934\n",
      "Epoch 1964/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2989 - acc: 0.5904 - val_loss: 4.0701 - val_acc: 0.5883\n",
      "Epoch 1965/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2976 - acc: 0.5888 - val_loss: 4.0710 - val_acc: 0.5966\n",
      "Epoch 1966/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2988 - acc: 0.5892 - val_loss: 4.0719 - val_acc: 0.5906\n",
      "Epoch 1967/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2981 - acc: 0.5917 - val_loss: 4.0698 - val_acc: 0.5920\n",
      "Epoch 1968/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2982 - acc: 0.5900 - val_loss: 4.0773 - val_acc: 0.5842\n",
      "Epoch 1969/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2997 - acc: 0.5895 - val_loss: 4.0722 - val_acc: 0.5961\n",
      "Epoch 1970/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2979 - acc: 0.5942 - val_loss: 4.0728 - val_acc: 0.5892\n",
      "Epoch 1971/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2989 - acc: 0.5903 - val_loss: 4.0712 - val_acc: 0.5888\n",
      "Epoch 1972/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2985 - acc: 0.5918 - val_loss: 4.0745 - val_acc: 0.5883\n",
      "Epoch 1973/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2990 - acc: 0.5896 - val_loss: 4.0708 - val_acc: 0.5961\n",
      "Epoch 1974/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2983 - acc: 0.5890 - val_loss: 4.0718 - val_acc: 0.5897\n",
      "Epoch 1975/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2994 - acc: 0.5862 - val_loss: 4.0706 - val_acc: 0.5980\n",
      "Epoch 1976/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2984 - acc: 0.5900 - val_loss: 4.0705 - val_acc: 0.5938\n",
      "Epoch 1977/5000\n",
      "8692/8692 [==============================] - 0s 42us/step - loss: 4.2983 - acc: 0.5896 - val_loss: 4.0700 - val_acc: 0.5966\n",
      "Epoch 1978/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2986 - acc: 0.5915 - val_loss: 4.0734 - val_acc: 0.5879\n",
      "Epoch 1979/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2978 - acc: 0.5879 - val_loss: 4.0708 - val_acc: 0.5938\n",
      "Epoch 1980/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2987 - acc: 0.5923 - val_loss: 4.0718 - val_acc: 0.5994\n",
      "Epoch 1981/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 4.2991 - acc: 0.5922 - val_loss: 4.0721 - val_acc: 0.5920\n",
      "Epoch 1982/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2981 - acc: 0.5920 - val_loss: 4.0744 - val_acc: 0.5897\n",
      "Epoch 1983/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2985 - acc: 0.5925 - val_loss: 4.0724 - val_acc: 0.5888\n",
      "Epoch 1984/5000\n",
      "8692/8692 [==============================] - 0s 56us/step - loss: 4.2984 - acc: 0.5909 - val_loss: 4.0716 - val_acc: 0.5952\n",
      "Epoch 1985/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.2988 - acc: 0.5896 - val_loss: 4.0733 - val_acc: 0.5915\n",
      "Epoch 1986/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.3002 - acc: 0.5877 - val_loss: 4.0722 - val_acc: 0.5911\n",
      "Epoch 1987/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 4.2991 - acc: 0.5913 - val_loss: 4.0721 - val_acc: 0.5994\n",
      "Epoch 1988/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2994 - acc: 0.5905 - val_loss: 4.0733 - val_acc: 0.5906\n",
      "Epoch 1989/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 1s 66us/step - loss: 4.2984 - acc: 0.5888 - val_loss: 4.0729 - val_acc: 0.5925\n",
      "Epoch 1990/5000\n",
      "8692/8692 [==============================] - 1s 77us/step - loss: 4.2985 - acc: 0.5879 - val_loss: 4.0709 - val_acc: 0.5948\n",
      "Epoch 1991/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2985 - acc: 0.5908 - val_loss: 4.0716 - val_acc: 0.5915\n",
      "Epoch 1992/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2990 - acc: 0.5903 - val_loss: 4.0719 - val_acc: 0.5938\n",
      "Epoch 1993/5000\n",
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2982 - acc: 0.5913 - val_loss: 4.0785 - val_acc: 0.5869\n",
      "Epoch 1994/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 4.2980 - acc: 0.5904 - val_loss: 4.0697 - val_acc: 0.5883\n",
      "Epoch 1995/5000\n",
      "8692/8692 [==============================] - 1s 83us/step - loss: 4.2988 - acc: 0.5916 - val_loss: 4.0735 - val_acc: 0.5897\n",
      "Epoch 1996/5000\n",
      "8692/8692 [==============================] - 1s 74us/step - loss: 4.2980 - acc: 0.5926 - val_loss: 4.0722 - val_acc: 0.5920\n",
      "Epoch 1997/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2983 - acc: 0.5874 - val_loss: 4.0727 - val_acc: 0.5920\n",
      "Epoch 1998/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 4.2991 - acc: 0.5908 - val_loss: 4.0722 - val_acc: 0.5897\n",
      "Epoch 1999/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2985 - acc: 0.5916 - val_loss: 4.0710 - val_acc: 0.5943\n",
      "Epoch 2000/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2975 - acc: 0.5924 - val_loss: 4.0726 - val_acc: 0.5925\n",
      "Epoch 2001/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 4.2978 - acc: 0.5918 - val_loss: 4.0711 - val_acc: 0.5943\n",
      "Epoch 2002/5000\n",
      "8692/8692 [==============================] - 1s 63us/step - loss: 4.2986 - acc: 0.5931 - val_loss: 4.0722 - val_acc: 0.5943\n",
      "Epoch 2003/5000\n",
      "8692/8692 [==============================] - 1s 87us/step - loss: 4.3002 - acc: 0.5880 - val_loss: 4.0715 - val_acc: 0.5915\n",
      "Epoch 2004/5000\n",
      "8692/8692 [==============================] - 1s 64us/step - loss: 4.2984 - acc: 0.5919 - val_loss: 4.0722 - val_acc: 0.6003\n",
      "Epoch 2005/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2985 - acc: 0.5924 - val_loss: 4.0702 - val_acc: 0.5943\n",
      "Epoch 2006/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 4.2999 - acc: 0.5894 - val_loss: 4.0749 - val_acc: 0.5869\n",
      "Epoch 2007/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 4.2978 - acc: 0.5899 - val_loss: 4.0699 - val_acc: 0.5938\n",
      "Epoch 2008/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2983 - acc: 0.5913 - val_loss: 4.0709 - val_acc: 0.5920\n",
      "Epoch 2009/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2978 - acc: 0.5909 - val_loss: 4.0703 - val_acc: 0.5952\n",
      "Epoch 2010/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2977 - acc: 0.5911 - val_loss: 4.0707 - val_acc: 0.5920\n",
      "Epoch 2011/5000\n",
      "8692/8692 [==============================] - 1s 93us/step - loss: 4.2984 - acc: 0.5918 - val_loss: 4.0725 - val_acc: 0.5971\n",
      "Epoch 2012/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2991 - acc: 0.5897 - val_loss: 4.0713 - val_acc: 0.5879\n",
      "Epoch 2013/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2987 - acc: 0.5872 - val_loss: 4.0735 - val_acc: 0.6003\n",
      "Epoch 2014/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2990 - acc: 0.5900 - val_loss: 4.0747 - val_acc: 0.5883\n",
      "Epoch 2015/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2977 - acc: 0.5890 - val_loss: 4.0732 - val_acc: 0.5998\n",
      "Epoch 2016/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2985 - acc: 0.5897 - val_loss: 4.0707 - val_acc: 0.5925\n",
      "Epoch 2017/5000\n",
      "8692/8692 [==============================] - 0s 50us/step - loss: 4.2978 - acc: 0.5913 - val_loss: 4.0699 - val_acc: 0.5915\n",
      "Epoch 2018/5000\n",
      "8692/8692 [==============================] - 0s 57us/step - loss: 4.2977 - acc: 0.5901 - val_loss: 4.0704 - val_acc: 0.5906\n",
      "Epoch 2019/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2981 - acc: 0.5918 - val_loss: 4.0713 - val_acc: 0.5934\n",
      "Epoch 2020/5000\n",
      "8692/8692 [==============================] - 0s 43us/step - loss: 4.2978 - acc: 0.5885 - val_loss: 4.0697 - val_acc: 0.5892\n",
      "Epoch 2021/5000\n",
      "8692/8692 [==============================] - 1s 115us/step - loss: 4.2986 - acc: 0.5901 - val_loss: 4.0704 - val_acc: 0.5943\n",
      "Epoch 2022/5000\n",
      "8692/8692 [==============================] - 1s 99us/step - loss: 4.2985 - acc: 0.5916 - val_loss: 4.0707 - val_acc: 0.5975\n",
      "Epoch 2023/5000\n",
      "8692/8692 [==============================] - 1s 82us/step - loss: 4.2982 - acc: 0.5900 - val_loss: 4.0710 - val_acc: 0.5929\n",
      "Epoch 2024/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 4.2980 - acc: 0.5907 - val_loss: 4.0706 - val_acc: 0.5971\n",
      "Epoch 2025/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2976 - acc: 0.5930 - val_loss: 4.0714 - val_acc: 0.5938\n",
      "Epoch 2026/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2982 - acc: 0.5897 - val_loss: 4.0714 - val_acc: 0.5888\n",
      "Epoch 2027/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2979 - acc: 0.5909 - val_loss: 4.0704 - val_acc: 0.5934\n",
      "Epoch 2028/5000\n",
      "8692/8692 [==============================] - 1s 88us/step - loss: 4.2980 - acc: 0.5920 - val_loss: 4.0727 - val_acc: 0.5957\n",
      "Epoch 2029/5000\n",
      "8692/8692 [==============================] - 1s 84us/step - loss: 4.2981 - acc: 0.5923 - val_loss: 4.0723 - val_acc: 0.5943\n",
      "Epoch 2030/5000\n",
      "8692/8692 [==============================] - 1s 66us/step - loss: 4.2978 - acc: 0.5909 - val_loss: 4.0705 - val_acc: 0.5938\n",
      "Epoch 2031/5000\n",
      "8692/8692 [==============================] - 1s 90us/step - loss: 4.2985 - acc: 0.5897 - val_loss: 4.0704 - val_acc: 0.5920\n",
      "Epoch 2032/5000\n",
      "8692/8692 [==============================] - 1s 60us/step - loss: 4.2975 - acc: 0.5922 - val_loss: 4.0715 - val_acc: 0.5957\n",
      "Epoch 2033/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2977 - acc: 0.5911 - val_loss: 4.0733 - val_acc: 0.5856\n",
      "Epoch 2034/5000\n",
      "8692/8692 [==============================] - 0s 53us/step - loss: 4.2972 - acc: 0.5910 - val_loss: 4.0715 - val_acc: 0.5989\n",
      "Epoch 2035/5000\n",
      "8692/8692 [==============================] - 1s 58us/step - loss: 4.2982 - acc: 0.5912 - val_loss: 4.0820 - val_acc: 0.5791\n",
      "Epoch 2036/5000\n",
      "8692/8692 [==============================] - 1s 72us/step - loss: 4.2985 - acc: 0.5887 - val_loss: 4.0719 - val_acc: 0.5906\n",
      "Epoch 2037/5000\n",
      "8692/8692 [==============================] - 0s 45us/step - loss: 4.2978 - acc: 0.5919 - val_loss: 4.0708 - val_acc: 0.5888\n",
      "Epoch 2038/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2975 - acc: 0.5902 - val_loss: 4.0711 - val_acc: 0.5961\n",
      "Epoch 2039/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2972 - acc: 0.5904 - val_loss: 4.0751 - val_acc: 0.5860\n",
      "Epoch 2040/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2978 - acc: 0.5909 - val_loss: 4.0735 - val_acc: 0.5902\n",
      "Epoch 2041/5000\n",
      "8692/8692 [==============================] - 0s 44us/step - loss: 4.2986 - acc: 0.5896 - val_loss: 4.0705 - val_acc: 0.5938\n",
      "Epoch 2042/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2975 - acc: 0.5936 - val_loss: 4.0720 - val_acc: 0.5980\n",
      "Epoch 2043/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.2993 - acc: 0.5902 - val_loss: 4.0705 - val_acc: 0.5906\n",
      "Epoch 2044/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2969 - acc: 0.5935 - val_loss: 4.0707 - val_acc: 0.5938\n",
      "Epoch 2045/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2984 - acc: 0.5890 - val_loss: 4.0725 - val_acc: 0.5925\n",
      "Epoch 2046/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2985 - acc: 0.5888 - val_loss: 4.0754 - val_acc: 0.5865\n",
      "Epoch 2047/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8692/8692 [==============================] - 0s 54us/step - loss: 4.2981 - acc: 0.5904 - val_loss: 4.0704 - val_acc: 0.5906\n",
      "Epoch 2048/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2981 - acc: 0.5878 - val_loss: 4.0719 - val_acc: 0.5934\n",
      "Epoch 2049/5000\n",
      "8692/8692 [==============================] - 0s 49us/step - loss: 4.2990 - acc: 0.5896 - val_loss: 4.0701 - val_acc: 0.5892\n",
      "Epoch 2050/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2976 - acc: 0.5912 - val_loss: 4.0705 - val_acc: 0.5929\n",
      "Epoch 2051/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.2979 - acc: 0.5904 - val_loss: 4.0699 - val_acc: 0.5925\n",
      "Epoch 2052/5000\n",
      "8692/8692 [==============================] - 0s 48us/step - loss: 4.2973 - acc: 0.5900 - val_loss: 4.0711 - val_acc: 0.5860\n",
      "Epoch 2053/5000\n",
      "8692/8692 [==============================] - 0s 46us/step - loss: 4.2976 - acc: 0.5911 - val_loss: 4.0707 - val_acc: 0.5925\n",
      "Epoch 2054/5000\n",
      "8692/8692 [==============================] - 0s 51us/step - loss: 4.2988 - acc: 0.5899 - val_loss: 4.0704 - val_acc: 0.5952\n",
      "Epoch 2055/5000\n",
      "8692/8692 [==============================] - 0s 52us/step - loss: 4.2978 - acc: 0.5894 - val_loss: 4.0738 - val_acc: 0.5865\n",
      "Epoch 2056/5000\n",
      "8692/8692 [==============================] - 1s 62us/step - loss: 4.2980 - acc: 0.5908 - val_loss: 4.0711 - val_acc: 0.5915\n",
      "Epoch 2057/5000\n",
      "8692/8692 [==============================] - 0s 47us/step - loss: 4.3004 - acc: 0.5892 - val_loss: 4.0701 - val_acc: 0.5948\n",
      "Epoch 2058/5000\n",
      "8692/8692 [==============================] - 1s 120us/step - loss: 4.2980 - acc: 0.5894 - val_loss: 4.0698 - val_acc: 0.5911\n",
      "Epoch 2059/5000\n",
      "8692/8692 [==============================] - 1s 71us/step - loss: 4.2975 - acc: 0.5911 - val_loss: 4.0704 - val_acc: 0.5920\n",
      "Epoch 2060/5000\n",
      "8692/8692 [==============================] - 1s 65us/step - loss: 4.2994 - acc: 0.5877 - val_loss: 4.0702 - val_acc: 0.5906\n",
      "Epoch 2061/5000\n",
      "2528/8692 [=======>......................] - ETA: 0s - loss: 4.1234 - acc: 0.6009"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='./logs/')\n",
    "\n",
    "model.fit(train_data, train_labels, \n",
    "          epochs=5000, batch_size=32, \n",
    "          validation_data=(test_data, test_labels), \n",
    "          callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run:\n",
    "```\n",
    "tensorboard --logdir=./logs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vocab_size = 1000\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer.texts_to_matrix(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = \\\n",
    "    train_test_split(data, labels_binary, \n",
    "                     test_size = 0.2, \n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Embedding\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128))\n",
    "model.add(LSTM(64, input_shape=(vocab_size,)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.1),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8692 samples, validate on 2174 samples\n",
      "Epoch 1/15\n",
      "8692/8692 [==============================] - 110s 13ms/step - loss: 0.7759 - acc: 0.4879 - val_loss: 0.7277 - val_acc: 0.4857\n",
      "Epoch 2/15\n",
      "8692/8692 [==============================] - 120s 14ms/step - loss: 0.7016 - acc: 0.5181 - val_loss: 0.6938 - val_acc: 0.5143\n",
      "Epoch 3/15\n",
      "8692/8692 [==============================] - 126s 14ms/step - loss: 0.7036 - acc: 0.4909 - val_loss: 0.6932 - val_acc: 0.5143\n",
      "Epoch 4/15\n",
      "8692/8692 [==============================] - 119s 14ms/step - loss: 0.6957 - acc: 0.5045 - val_loss: 0.6975 - val_acc: 0.5143\n",
      "Epoch 5/15\n",
      "8692/8692 [==============================] - 116s 13ms/step - loss: 0.6972 - acc: 0.4934 - val_loss: 0.6955 - val_acc: 0.5143\n",
      "Epoch 6/15\n",
      "8692/8692 [==============================] - 115s 13ms/step - loss: 0.6960 - acc: 0.5010 - val_loss: 0.6951 - val_acc: 0.5143\n",
      "Epoch 7/15\n",
      "8692/8692 [==============================] - 117s 13ms/step - loss: 0.6954 - acc: 0.5070 - val_loss: 0.6932 - val_acc: 0.5143\n",
      "Epoch 8/15\n",
      "8692/8692 [==============================] - 115s 13ms/step - loss: 0.7078 - acc: 0.4900 - val_loss: 0.6932 - val_acc: 0.4857\n",
      "Epoch 9/15\n",
      "8692/8692 [==============================] - 117s 13ms/step - loss: 0.7011 - acc: 0.5084 - val_loss: 0.7061 - val_acc: 0.5143\n",
      "Epoch 10/15\n",
      "8692/8692 [==============================] - 135s 16ms/step - loss: 0.6997 - acc: 0.4997 - val_loss: 0.6962 - val_acc: 0.5143\n",
      "Epoch 11/15\n",
      "8692/8692 [==============================] - 130s 15ms/step - loss: 0.6950 - acc: 0.4994 - val_loss: 0.6929 - val_acc: 0.5143\n",
      "Epoch 12/15\n",
      "8692/8692 [==============================] - 116s 13ms/step - loss: 0.6999 - acc: 0.5123 - val_loss: 0.7081 - val_acc: 0.4857\n",
      "Epoch 13/15\n",
      "8692/8692 [==============================] - 116s 13ms/step - loss: 0.6965 - acc: 0.5047 - val_loss: 0.7033 - val_acc: 0.4857\n",
      "Epoch 14/15\n",
      "8692/8692 [==============================] - 119s 14ms/step - loss: 0.7010 - acc: 0.4951 - val_loss: 0.6952 - val_acc: 0.4857\n",
      "Epoch 15/15\n",
      "3584/8692 [===========>..................] - ETA: 1:11 - loss: 0.6939 - acc: 0.5114"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-120edafcc393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=(test_data, test_labels))\n\u001b[0m",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp-workshop/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          batch_size=512,\n",
    "          epochs=15,\n",
    "          validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-workshop",
   "language": "python",
   "name": "nlp-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
